{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlstruct.text import huggingface_tokenize, regex_sentencize, partition_spans, encode_as_tag, split_into_spans, apply_substitutions, apply_deltas\n",
    "from nlstruct.dataloaders import *\n",
    "from nlstruct.collections import Dataset, Batcher\n",
    "from nlstruct.utils import merge_with_spans, normalize_vocabularies, factorize_rows, df_to_csr, factorize, torch_global as tg\n",
    "from nlstruct.modules.crf import BIODecoder, BIOULDecoder\n",
    "from nlstruct.environment import root, cached\n",
    "from nlstruct.train import seed_all\n",
    "from itertools import chain, repeat\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger(\"nlstruct\")\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To debug the training, we can just comment the \"def run_epoch()\" and execute the function body manually without changing anything to it\n",
    "def extract_mentions(batcher, all_nets, max_depth=10):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    batcher: Batcher \n",
    "        The batcher containing the text from which we want to extract the mentions (and maybe the gold mentions)\n",
    "    ner_net: torch.nn.Module\n",
    "    max_depth: int\n",
    "        Max number of times we run the model per sample\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Batcher\n",
    "    \"\"\"\n",
    "    pred_batches = []\n",
    "    n_mentions = 0\n",
    "    ner_net = all_nets[\"ner_net\"]\n",
    "    with evaluating(all_nets):\n",
    "        with torch.no_grad():\n",
    "            for batch_i, batch in enumerate(batcher['sentence'].dataloader(batch_size=batch_size, shuffle=False, sparse_sort_on=\"token_mask\", device=tg.device)):\n",
    "\n",
    "                mask = batch[\"token_mask\"]\n",
    "\n",
    "                res = all_nets[\"ner_net\"].forward(\n",
    "                    tokens=batch[\"token\"],\n",
    "                    mask=mask,\n",
    "                    return_loss = False,\n",
    "                )\n",
    "\n",
    "                spans = res['sampled_spans']\n",
    "\n",
    "                pred_batch = Batcher({\n",
    "                    \"mention\": {\n",
    "                        \"mention_id\": torch.arange(n_mentions, n_mentions+len(spans['span_doc_id']), device=device),\n",
    "                        \"begin\": spans[\"span_begin\"],\n",
    "                        \"end\": spans[\"span_end\"],\n",
    "                        \"ner_label\": spans[\"span_label\"],\n",
    "                        \"@sentence_id\": spans[\"span_doc_id\"],\n",
    "                    },\n",
    "                    \"sentence\": dict(batch[\"sentence\", [\"sentence_id\", \"doc_id\"]]),\n",
    "                    \"doc\": dict(batch[\"doc\"])}, \n",
    "                    check=False)\n",
    "\n",
    "                pred_batches.append(pred_batch)\n",
    "            \n",
    "    return Batcher.concat(pred_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Define the training metrics\n",
    "metrics_info = defaultdict(lambda: False)\n",
    "flt_format = (5, \"{:.4f}\".format)\n",
    "metrics_info.update({\n",
    "    \"train_loss\": {\"goal\": 0, \"format\": flt_format},\n",
    "    \"train_ner_loss\": {\"goal\": 0, \"format\": flt_format},\n",
    "    #\"train_recall\": {\"goal\": 1, \"format\": flt_format, \"name\": \"train_rec\"},\n",
    "    #\"train_precision\": {\"goal\": 1, \"format\": flt_format, \"name\": \"train_prec\"},\n",
    "    \"train_f1\": {\"goal\": 1, \"format\": flt_format, \"name\": \"train_f1\"},\n",
    "    \n",
    "    \"val_loss\": {\"goal\": 0, \"format\": flt_format},\n",
    "    \"val_ner_loss\": {\"goal\": 0, \"format\": flt_format},\n",
    "    \"val_label_loss\": {\"goal\": 0, \"format\": flt_format},\n",
    "    \n",
    "    \"val_f1\": {\"goal\": 1, \"format\": flt_format, \"name\": \"val_f1\"},\n",
    "    \"val_3.1_f1\": {\"goal\": 1, \"format\": flt_format, \"name\": \"val_3.1_f1\"},\n",
    "    \"val_3.2_f1\": {\"goal\": 1, \"format\": flt_format, \"name\": \"val_3.2_f1\"},\n",
    "    \"val_macro_f1\": {\"goal\": 1, \"format\": flt_format, \"name\": \"val_macro_f1\"},\n",
    "    \"val_sosy_f1\": {\"goal\": 1, \"format\": flt_format, \"name\": \"val_sosy_f1\"},\n",
    "    \"val_pathologie_f1\": {\"goal\": 1, \"format\": flt_format, \"name\": \"val_patho_f1\"},\n",
    "    \n",
    "    \"duration\": {\"format\": flt_format, \"name\": \"   dur(s)\"},\n",
    "    \"rescale\": {\"format\": flt_format},\n",
    "    \"n_depth\": {\"format\": flt_format},\n",
    "    \"n_matched\": {\"format\": flt_format},\n",
    "    \"n_targets\": {\"format\": flt_format},\n",
    "    \"n_observed\": {\"format\": flt_format},\n",
    "    \"total_score_sum\": {\"format\": flt_format},\n",
    "    \"lr\": {\"format\": (5, \"{:.2e}\".format)},\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlstruct.utils import encode_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@cached\n",
    "def preprocess_train(\n",
    "    dataset,\n",
    "    max_sentence_length,\n",
    "    bert_name,\n",
    "    ner_labels=None,\n",
    "    unknown_labels=\"drop\",\n",
    "    vocabularies=None,\n",
    "    frag_merge=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "        dataset: Dataset\n",
    "        max_sentence_length: int\n",
    "            Max number of \"words\" as defined by the regex in regex_sentencize (so this is not the nb of wordpieces)\n",
    "        bert_name: str\n",
    "            bert path/name\n",
    "        ner_labels: list of str \n",
    "            allowed ner labels (to be dropped or filtered)\n",
    "        unknown_labels: str\n",
    "            \"drop\" or \"raise\"\n",
    "        vocabularies: dict[str; np.ndarray or list]\n",
    "    Returns\n",
    "    -------\n",
    "    (pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame, dict[str; np.ndarray or list])\n",
    "        docs:      ('split', 'text', 'doc_id')\n",
    "        sentences: ('split', 'doc_id', 'sentence_idx', 'begin', 'end', 'text', 'sentence_id')\n",
    "        mentions:  ('ner_label', 'doc_id', 'sentence_id', 'mention_id', 'depth', 'text', 'mention_idx', 'begin', 'end')\n",
    "        tokens:    ('split', 'token', 'sentence_id', 'token_id', 'token_idx', 'begin', 'end', 'doc_id', 'sentence_idx')\n",
    "        deltas:    ('doc_id', 'begin', 'end', 'delta')\n",
    "        vocs: vocabularies to be reused later for encoding more data or decoding predictions\n",
    "    \"\"\"\n",
    "    print(\"Dataset:\", dataset)\n",
    "    mentions = dataset[\"mentions\"].rename({\"label\": \"ner_label\"}, axis=1)\n",
    "    if ner_labels is not None:\n",
    "        len_before = len(mentions)\n",
    "        unknown_ner_labels = list(mentions[~mentions[\"ner_label\"].isin(ner_labels)][\"ner_label\"].drop_duplicates())\n",
    "        mentions = mentions[mentions[\"ner_label\"].isin(ner_labels)]\n",
    "        if len(unknown_ner_labels) and unknown_labels == \"raise\":\n",
    "            raise Exception(f\"Unkown labels in {len_before-len(mentions)} mentions: \", unknown_ner_labels)\n",
    "    # Check that there is no mention overlap\n",
    "    if frag_merge:\n",
    "        mentions = mentions.merge(dataset[\"fragments\"].groupby([\"doc_id\", \"mention_id\"], as_index=False, observed=True).agg({\"begin\": \"min\", \"end\": \"max\"}))\n",
    "    print(\"Transform texts...\", end=\" \")\n",
    "    docs, deltas = apply_substitutions(\n",
    "        dataset[\"docs\"], *zip(\n",
    "            #(r\"(?<=[{}\\\\])(?![ ])\".format(string.punctuation), r\" \"),\n",
    "            #(r\"(?<![ ])(?=[{}\\\\])\".format(string.punctuation), r\" \"),\n",
    "            (\"(?<=[a-zA-Z])(?=[0-9])\", r\" \"),\n",
    "            (\"(?<=[0-9])(?=[A-Za-z])\", r\" \"),\n",
    "        ), apply_unidecode=True)\n",
    "    docs = docs.astype({\"text\": str})\n",
    "    transformed_mentions = apply_deltas(mentions, deltas, on=['doc_id'])\n",
    "    print(\"done\")\n",
    "    \n",
    "    print(\"Splitting into sentences...\", end=\" \")\n",
    "    sentences = regex_sentencize(\n",
    "        docs, \n",
    "        reg_split=r\"(?<=[.])(\\s*\\n+)|(?=, [0-9]\\))\",\n",
    "        min_sentence_length=None, max_sentence_length=max_sentence_length,\n",
    "        balance_parentheses=False,\n",
    "        # balance_parentheses=True, # default is True\n",
    "    )\n",
    "    [mentions], sentences, sentence_to_docs = partition_spans([transformed_mentions], sentences, new_id_name=\"sentence_id\", overlap_policy=False)\n",
    "    \n",
    "    mentions = mentions[(mentions['begin']>0) & (mentions['end']>0)]\n",
    "    \n",
    "    n_sentences_per_mention = mentions.assign(count=1).groupby([\"doc_id\", \"mention_id\"], as_index=False).agg({\"count\": \"sum\", \"text\": tuple, \"sentence_id\": tuple})\n",
    "    if n_sentences_per_mention[\"count\"].max() > 1:\n",
    "        display(n_sentences_per_mention.query(\"count > 1\"))\n",
    "        display(sentences[sentences[\"sentence_id\"].isin(n_sentences_per_mention.query(\"count > 1\")[\"sentence_id\"].explode())][\"text\"].tolist())\n",
    "        raise Exception(\"Some mentions could be mapped to more than 1 sentences ({})\".format(n_sentences_per_mention[\"count\"].max()))\n",
    "    if sentence_to_docs is not None:\n",
    "        mentions = mentions.merge(sentence_to_docs)\n",
    "    mentions = mentions.assign(mention_idx=0).nlstruct.groupby_assign([\"doc_id\", \"sentence_id\"], {\"mention_idx\": lambda x: tuple(range(len(x)))})\n",
    "    print(\"done\")\n",
    "    \n",
    "    print(\"Tokenizing...\", end=\" \")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(bert_name)\n",
    "    sentences[\"text\"] = sentences[\"text\"].str.lower()\n",
    "    tokens = huggingface_tokenize(sentences, tokenizer, doc_id_col=\"sentence_id\")\n",
    "    \n",
    "    print(tokens)\n",
    "    \n",
    "    mentions = split_into_spans(mentions, tokens, pos_col=\"token_idx\", overlap_policy=False)\n",
    "    print(\"done\")\n",
    "    \n",
    "    print(\"Processing nestings (overlapping areas)...\", end=\" \")\n",
    "    # Extract overlapping spans\n",
    "    conflicts = (\n",
    "        merge_with_spans(mentions, mentions, on=[\"doc_id\", \"sentence_id\", (\"begin\", \"end\")], how=\"outer\", suffixes=(\"\", \"_other\"))\n",
    "    )\n",
    "    # ids1, and ids2 make the edges of the overlapping mentions of the same type (see the \"ner_label\")\n",
    "    [ids1, ids2], unique_ids = factorize_rows(\n",
    "        [conflicts[[\"doc_id\", \"sentence_id\", \"mention_id\"]], \n",
    "         conflicts[[\"doc_id\", \"sentence_id\", \"mention_id_other\"]]],\n",
    "        mentions.eval(\"size=(end-begin)\").sort_values(\"size\")[[\"doc_id\", \"sentence_id\", \"mention_id\"]]\n",
    "    )\n",
    "    g = nx.from_scipy_sparse_matrix(df_to_csr(ids1, ids2, n_rows=len(unique_ids), n_cols=len(unique_ids)))\n",
    "    colored_nodes = np.asarray(list(nx.coloring.greedy_color(g, strategy=keep_order).items()))\n",
    "    unique_ids['depth'] = colored_nodes[:, 1][colored_nodes[:, 0].argsort()]\n",
    "    mentions = mentions.merge(unique_ids)\n",
    "    print(\"done\")\n",
    "    \n",
    "    print(\"Computing vocabularies...\")\n",
    "    [docs, sentences, mentions, tokens], vocs = normalize_vocabularies(\n",
    "        [docs, sentences, mentions, tokens], \n",
    "        vocabularies={\"split\": [\"train\", \"val\", \"test\"]} if vocabularies is None else vocabularies,\n",
    "        train_vocabularies={\"source\": False, \"text\": False} if vocabularies is None else False,\n",
    "        verbose=True)\n",
    "    print(\"done\")\n",
    "    \n",
    "    prep = Dataset(docs=docs, sentences=sentences, mentions=mentions, tokens=tokens).copy()\n",
    "    \n",
    "    unique_mention_ids = encode_ids([mentions], (\"doc_id\", \"sentence_id\", \"mention_id\"))\n",
    "    unique_sentence_ids = encode_ids([sentences, mentions, tokens], (\"doc_id\", \"sentence_id\"))\n",
    "    unique_doc_ids = encode_ids([docs, sentences, mentions, tokens], (\"doc_id\",))\n",
    "    \n",
    "    batcher = Batcher({\n",
    "        \"mention\": {\n",
    "            \"mention_id\": mentions[\"mention_id\"],\n",
    "            \"sentence_id\": mentions[\"sentence_id\"],\n",
    "            \"doc_id\": mentions[\"doc_id\"],\n",
    "            \"begin\": mentions[\"begin\"],\n",
    "            \"end\": mentions[\"end\"],\n",
    "            \"depth\": mentions[\"depth\"],\n",
    "            \"ner_label\": mentions[\"ner_label\"].cat.codes,\n",
    "        },\n",
    "        \"sentence\": {\n",
    "            \"sentence_id\": sentences[\"sentence_id\"],\n",
    "            \"doc_id\": sentences[\"doc_id\"],\n",
    "            \"mention_id\": df_to_csr(mentions[\"sentence_id\"], mentions[\"mention_idx\"], mentions[\"mention_id\"], n_rows=len(unique_sentence_ids)),\n",
    "            \"mention_mask\": df_to_csr(mentions[\"sentence_id\"], mentions[\"mention_idx\"], n_rows=len(unique_sentence_ids)),\n",
    "            \"token\": df_to_csr(tokens[\"sentence_id\"], tokens[\"token_idx\"], tokens[\"token\"].cat.codes, n_rows=len(unique_sentence_ids)),\n",
    "            \"token_mask\": df_to_csr(tokens[\"sentence_id\"], tokens[\"token_idx\"], n_rows=len(unique_sentence_ids)),\n",
    "        },\n",
    "        \"doc\": {\n",
    "            \"doc_id\": np.arange(len(unique_doc_ids)),\n",
    "            \"sentence_id\": df_to_csr(sentences[\"doc_id\"], sentences[\"sentence_idx\"], sentences[\"sentence_id\"], n_rows=len(unique_doc_ids)),\n",
    "            \"sentence_mask\": df_to_csr(sentences[\"doc_id\"], sentences[\"sentence_idx\"], n_rows=len(unique_doc_ids)),\n",
    "            \"split\": docs[\"split\"].cat.codes,\n",
    "        }},\n",
    "        masks={\"sentence\": {\"token\": \"token_mask\", \"mention_id\": \"mention_mask\"}, \n",
    "               \"doc\": {\"sentence_id\": \"sentence_mask\"}}\n",
    "    )\n",
    "    \n",
    "    return batcher, prep, deltas, vocs\n",
    "\n",
    "def keep_order(G, colors):\n",
    "    \"\"\"Returns a list of the nodes of ``G`` in ordered identically to their id in the graph\n",
    "    ``G`` is a NetworkX graph. ``colors`` is ignored.\n",
    "    This is to assign a depth using the nx.coloring.greedy_color function\n",
    "    \"\"\"\n",
    "    return sorted(list(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Dataset(\n",
      "  (docs):       792 * ('doc_id', 'text', 'split')\n",
      "  (mentions):  7059 * ('doc_id', 'mention_id', 'category', 'text', 'begin', 'end', 'label_id', 'label')\n",
      "  (labels):    7059 * ('label_id', 'doc_id', 'mention_id', 'label')\n",
      "  (fragments): 6881 * ('doc_id', 'mention_id', 'begin', 'end', 'fragment_id')\n",
      ")\n",
      "Transform texts... done\n",
      "Splitting into sentences... done\n",
      "Tokenizing... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ytaille/.conda/envs/yt_nlp/lib/python3.7/site-packages/nlstruct/text/chunking/huggingface.py:11: FutureWarning: doc_id_col is not used anymore in the huggingface_tokenize function\n",
      "  warnings.warn(\"doc_id_col is not used anymore in the huggingface_tokenize function\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id  token_id  token_idx    token  begin  end  sentence_idx    doc_id  split sentence_id\n",
      "0          0         0          0    [CLS]      0    0             0  10192393  train         0/0\n",
      "1          0         1          1        a      0    1             0  10192393  train         0/0\n",
      "2          0         2          2   common      2    8             0  10192393  train         0/0\n",
      "3          0         3          3    human      9   14             0  10192393  train         0/0\n",
      "4          0         4          4     skin     15   19             0  10192393  train         0/0\n",
      "...      ...       ...        ...      ...    ...  ...           ...       ...    ...         ...\n",
      "255920  2437    255920        163    ##pop    640  643             1   8696339    dev       791/1\n",
      "255921  2437    255921        164  ##tosis    643  648             1   8696339    dev       791/1\n",
      "255922  2437    255922        165        .    648  649             1   8696339    dev       791/1\n",
      "255923  2437    255923        166        .    649  650             1   8696339    dev       791/1\n",
      "255924  2437    255924        167    [SEP]    650  650             1   8696339    dev       791/1\n",
      "\n",
      "[255925 rows x 10 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlstruct:Will train vocabulary for category\n",
      "INFO:nlstruct:Will train vocabulary for ner_label\n",
      "INFO:nlstruct:Will train vocabulary for token\n",
      "INFO:nlstruct:Discovered existing vocabulary (28996 entities) for token\n",
      "INFO:nlstruct:Normalized split, with given vocabulary and no unk\n",
      "INFO:nlstruct:Normalized split, with given vocabulary and no unk\n",
      "INFO:nlstruct:Normalized split, with given vocabulary and no unk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "Processing nestings (overlapping areas)... done\n",
      "Computing vocabularies...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "bert_name = \"bert-base-cased\"\n",
    "dataset = load_ncbi_disease()\n",
    "\n",
    "docs = dataset['docs']\n",
    "\n",
    "keep_n_first = None\n",
    "\n",
    "if keep_n_first:\n",
    "    docs = docs[:keep_n_first]\n",
    "    first_ids = docs['doc_id']\n",
    "    \n",
    "    first_mentions = dataset[\"mentions\"].loc[dataset[\"mentions\"]['doc_id'].isin(first_ids)]\n",
    "    first_fragments = dataset[\"fragments\"].loc[dataset[\"fragments\"]['doc_id'].isin(first_ids)]\n",
    "    first_attributes = dataset[\"attributes\"].loc[dataset[\"attributes\"]['doc_id'].isin(first_ids)]\n",
    "    \n",
    "    dataset[\"mentions\"] = first_mentions\n",
    "    dataset[\"fragments\"] = first_fragments\n",
    "    dataset[\"attributes\"] = first_attributes\n",
    "    \n",
    "dataset['mentions'] = dataset['mentions'].merge(dataset[\"fragments\"].groupby([\"doc_id\", \"mention_id\"], as_index=False, observed=True).agg({\"begin\": \"min\", \"end\": \"max\"}))\n",
    "\n",
    "merged = dataset['mentions'].merge(dataset['labels'], on=['doc_id', 'mention_id'])\n",
    "merged['mention_id'] = merged['label_id']\n",
    "merged['label'] = merged['category']\n",
    "    \n",
    "dataset['docs'] = docs\n",
    "\n",
    "dataset['mentions'] = merged\n",
    "\n",
    "ner_labels = list(dataset['mentions']['label'].unique())\n",
    "\n",
    "batcher, prep, deltas, vocs = preprocess_train(\n",
    "    dataset=dataset,\n",
    "    max_sentence_length=140,\n",
    "    bert_name=bert_name,\n",
    "    ner_labels= ner_labels,\n",
    "    unknown_labels=\"drop\",\n",
    "    frag_merge=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batcher(\n",
      "  [mention]:\n",
      "    (mention_id): ndarray[int64](6687,)\n",
      "    (sentence_id): ndarray[int64](6687,)\n",
      "    (doc_id): ndarray[int64](6687,)\n",
      "    (begin): ndarray[int64](6687,)\n",
      "    (end): ndarray[int64](6687,)\n",
      "    (depth): ndarray[int64](6687,)\n",
      "    (ner_label): ndarray[int8](6687,)\n",
      "  [sentence]:\n",
      "    (sentence_id): ndarray[int64](2438,)\n",
      "    (doc_id): ndarray[int64](2438,)\n",
      "    (mention_id): csr_matrix[int64](2438, 20)\n",
      "    (mention_mask): csr_matrix[bool](2438, 20)\n",
      "    (token): csr_matrix[int16](2438, 233)\n",
      "    (token_mask): csr_matrix[bool](2438, 233)\n",
      "  [doc]:\n",
      "    (doc_id): ndarray[int64](792,)\n",
      "    (sentence_id): csr_matrix[int64](792, 6)\n",
      "    (sentence_mask): csr_matrix[bool](792, 6)\n",
      "    (split): ndarray[int8](792,)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(batcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "bert, log = BertModel.from_pretrained(bert_name, output_loading_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity (L2 dist) between train and val frequencies: 0.0013780224108268146\n",
      "Frequencies\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>CompositeMention</th>\n",
       "      <th>DiseaseClass</th>\n",
       "      <th>Modifier</th>\n",
       "      <th>SpecificDisease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>0.035844</td>\n",
       "      <td>0.155054</td>\n",
       "      <td>0.259766</td>\n",
       "      <td>0.549335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>val</td>\n",
       "      <td>0.036442</td>\n",
       "      <td>0.126474</td>\n",
       "      <td>0.282958</td>\n",
       "      <td>0.554126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  CompositeMention  DiseaseClass  Modifier  SpecificDisease\n",
       "0  train          0.035844      0.155054  0.259766         0.549335\n",
       "1    val          0.036442      0.126474  0.282958         0.554126"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#all_test_doc_ids = []\n",
    "#sims = {}\n",
    "#for i in range(200):\n",
    "seed_all(1234567+137)\n",
    "\n",
    "train_batcher = batcher['doc'][batcher['doc']['split']==0]['sentence']\n",
    "test_batcher = batcher['doc'][batcher['doc']['split']==2]['sentence']\n",
    "\n",
    "splits = np.zeros(len(train_batcher['doc']), dtype=int)\n",
    "\n",
    "val_perc = 0.1\n",
    "splits[np.random.choice(np.arange(len(splits)), size=int(val_perc * len(splits)))] = 1\n",
    "\n",
    "val_batcher = test_batcher#batcher['sentence'][splits == 1]\n",
    "\n",
    "# train_val_split = np.random.permutation(len(train_batcher))\n",
    "# test_batcher = train_batcher[train_val_split[:int(0.1*len(train_val_split))]]['sentence']\n",
    "# train_batcher = train_batcher[train_val_split[int(0.1*len(train_val_split)):]]['sentence']\n",
    "sim = ((np.bincount(val_batcher['mention', 'ner_label'], minlength=len(vocs[\"ner_label\"]))/len(val_batcher['mention']) -\n",
    "np.bincount(train_batcher['mention', 'ner_label'], minlength=len(vocs[\"ner_label\"]))/len(train_batcher['mention']))**2).sum()\n",
    "print(\"Similarity (L2 dist) between train and val frequencies:\", sim)\n",
    "print(\"Frequencies\")\n",
    "#all_test_doc_ids.append((test_doc_ids, sim))\n",
    "display(pd.DataFrame([\n",
    "    {\"index\": \"train\", **dict(zip(vocs[\"ner_label\"], np.bincount(train_batcher['mention', 'ner_label'], minlength=len(vocs[\"ner_label\"]))/len(train_batcher['mention'])))},\n",
    "    {\"index\": \"val\", **dict(zip(vocs[\"ner_label\"], np.bincount(val_batcher['mention', 'ner_label'], minlength=len(vocs[\"ner_label\"]))/len(val_batcher['mention'])))},\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def torch_f1(actions, target_tags, is_training=True):\n",
    "    f1 = torch.from_numpy(np.array((f1_score(target_tags.reshape(-1).cpu(), actions.reshape(-1).cpu(), average=\"micro\"))))\n",
    "    f1.requires_grad = is_training\n",
    "    return f1\n",
    "\n",
    "class NERNet(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_labels,\n",
    "                 hidden_dim,\n",
    "                 dropout,\n",
    "                 n_tokens=None,\n",
    "                 token_dim=None,\n",
    "                 embeddings=None,\n",
    "                 tag_scheme=\"bio\",\n",
    "                 max_depth=10,\n",
    "                 lstm_size=100,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        \n",
    "        if embeddings is not None:\n",
    "            self.embeddings = embeddings\n",
    "            if n_tokens is None or token_dim is None:\n",
    "                if hasattr(embeddings, 'weight'):\n",
    "                    n_tokens, token_dim = embeddings.weight.shape\n",
    "                else:\n",
    "                    n_tokens, token_dim = embeddings.embeddings.weight.shape\n",
    "        else:\n",
    "            self.embeddings = torch.nn.Embedding(n_tokens, token_dim) if n_tokens > 0 else None\n",
    "        assert token_dim is not None, \"Provide token_dim or embeddings\"\n",
    "        assert self.embeddings is not None\n",
    "\n",
    "        dim = (token_dim if n_tokens > 0 else 0)\n",
    "        \n",
    "        self.ner_labels_subset = list(range(n_labels))\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        \n",
    "#         if tag_scheme == \"bio\":\n",
    "#             self.crf = BIODecoder(n_labels)\n",
    "#         elif tag_scheme == \"bioul\":\n",
    "#             self.crf = BIOULDecoder(n_labels)\n",
    "        if tag_scheme == \"bio\":\n",
    "            self.crf_list = torch.nn.ModuleList([BIODecoder(1, with_start_end_transitions=False) for _ in self.ner_labels_subset])\n",
    "        elif tag_scheme == \"bioul\":\n",
    "            self.crf_list = torch.nn.ModuleList([BIOULDecoder(1, with_start_end_transitions=False) for _ in self.ner_labels_subset])\n",
    "        else:\n",
    "            raise Exception()\n",
    "        if hidden_dim is None:\n",
    "            hidden_dim = dim\n",
    "        self.linear = torch.nn.Linear(dim, hidden_dim)\n",
    "        self.batch_norm = torch.nn.BatchNorm1d(dim)\n",
    "\n",
    "        n_tags = self.crf_list[0].num_tags\n",
    "        \n",
    "        self.metric_fc = torch.nn.Linear(dim, sum(crf.num_tags for crf in self.crf_list))\n",
    "        \n",
    "#         self.max_depth = max_depth\n",
    "        \n",
    "#         self.embed_size = dim\n",
    "#         self.summary_size = n_tags\n",
    "#         self.lstm_size = n_tags\n",
    "        \n",
    "#         self.tag_fc = torch.nn.Linear(dim, dim)\n",
    "#         self.cell = torch.nn.LSTMCell(self.summary_size, self.lstm_size)\n",
    "        \n",
    "#         self.combined_fc = torch.nn.Linear(self.lstm_size + self.embed_size, n_tags)\n",
    "        \n",
    "    def forward(self, \n",
    "                tokens, \n",
    "                mask,\n",
    "                tags=None,\n",
    "                return_loss=False,):\n",
    "        # Embed the tokens\n",
    "        scores = None\n",
    "        # shape: n_batch * sequence * 768\n",
    "        embeds = self.embeddings(tokens)[0]\n",
    "        \n",
    "        state = embeds.masked_fill(~mask.unsqueeze(-1), 0)\n",
    "        state = torch.relu(state)#self.linear(self.dropout(state)))# + state\n",
    "        state = self.batch_norm(state.view(-1, state.shape[-1])).view(state.shape)\n",
    "        \n",
    "        scores = self.metric_fc(state)\n",
    "        \n",
    "#         summary_pred = scores.mean(1)\n",
    "        \n",
    "#         lstm_hidden = torch.zeros(summary_pred.shape[0], self.lstm_size).to(summary_pred.device)\n",
    "#         lstm_mem = torch.zeros(summary_pred.shape[0], self.lstm_size).to(summary_pred.device)\n",
    "        \n",
    "#         sampled_spans = []\n",
    "        \n",
    "#         all_final_scores = []\n",
    "#         for i_depth in range(self.max_depth):\n",
    "            \n",
    "#             lstm_hidden, lstm_mem = self.cell(summary_pred, (lstm_hidden, lstm_mem))\n",
    "            \n",
    "#             final_scores = torch.einsum(\"ijk,ik->ijk\", scores,lstm_hidden)\n",
    "            \n",
    "#             tags = self.crf.decode(final_scores, mask)\n",
    "#             sampled_spans.append(self.crf.tags_to_spans(tags, mask))\n",
    "            \n",
    "#             all_final_scores.append(final_scores)\n",
    "            \n",
    "#         if len(sampled_spans)>0:\n",
    "#             sampled_spans = {\n",
    "#                 k: torch.cat([gm[k] for gm in sampled_spans], -1) for k in sampled_spans[0].keys() \n",
    "#             }\n",
    "            \n",
    "#         all_final_scores = torch.mean(torch.stack(all_final_scores), 0)\n",
    "        \n",
    "        scores = scores.reshape((*scores.shape[:-1], -1, len(self.crf_list))).permute(3, 0, 1, 2)\n",
    "        \n",
    "        sampled_spans = []\n",
    "        sampled_tags = []\n",
    "        baseline_tags = []\n",
    "            \n",
    "        for i, (ner_label_idx, crf) in enumerate(zip(self.ner_labels_subset, self.crf_list)):\n",
    "            sample_tags = crf.sample(scores[i], mask, n=1)\n",
    "            argmax_tags = crf.decode(scores[i], mask)\n",
    "            extracted = crf.tags_to_spans(sample_tags[0], mask)\n",
    "            \n",
    "            extracted['span_label'] = torch.full_like(extracted[\"span_label\"], ner_label_idx)\n",
    "        \n",
    "            sampled_spans.append(extracted)\n",
    "            sampled_tags.append(sample_tags)\n",
    "            baseline_tags.append(argmax_tags)\n",
    "        \n",
    "        if return_loss:\n",
    "            loss = -torch.stack([crf(scores[i], mask, tags[0][..., ner_label_idx], reduction=\"none\") \n",
    "                                for i, (ner_label_idx, crf) in enumerate(zip(self.ner_labels_subset, self.crf_list))]).mean()\n",
    "            \n",
    "        if len(sampled_spans)>0:\n",
    "            sampled_spans = {\n",
    "                k: torch.cat([sm[k] for sm in sampled_spans], -1) for k in sampled_spans[0].keys() \n",
    "            }\n",
    "    \n",
    "        return {\n",
    "            \"scores\": scores,\n",
    "            \"sampled_spans\": sampled_spans,\n",
    "            \"loss\": loss if return_loss else None,\n",
    "            \"sampled_tags\": sampled_tags,\n",
    "            \"baseline_tags\": sampled_tags,\n",
    "        }\n",
    "    \n",
    "    def init_lstm_state(self, seq_len):\n",
    "        return (torch.autograd.Variable(torch.zeros(1, seq_len, self.lstm_dim)),\n",
    "                torch.autograd.Variable(torch.zeros(1, seq_len, self.lstm_dim)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlstruct:Available CUDA devices: 1\n",
      "INFO:nlstruct:Current device: cuda:0\n",
      "100%|██████████| 29/29 [00:24<00:00,  1.16it/s, loss=61.3]\n",
      "INFO:nlstruct:epoch | train_ner_loss | train_f1 | \u001b[31mval_f1\u001b[0m | n_matched |    dur(s)\n",
      "INFO:nlstruct:    1 |       \u001b[32m154.5636\u001b[0m |   \u001b[32m0.0032\u001b[0m | \u001b[32m0.0071\u001b[0m |    0.0000 |   26.8717\n",
      "100%|██████████| 29/29 [00:24<00:00,  1.16it/s, loss=15.8]\n",
      "INFO:nlstruct:    2 |        \u001b[32m92.5503\u001b[0m |   \u001b[32m0.0042\u001b[0m | \u001b[32m0.0136\u001b[0m |    0.0000 |   26.7806\n",
      "100%|██████████| 29/29 [00:25<00:00,  1.16it/s, loss=4.47]\n",
      "INFO:nlstruct:    3 |        \u001b[32m47.3702\u001b[0m |   \u001b[32m0.0044\u001b[0m | \u001b[32m0.0239\u001b[0m |    0.0000 |   26.9177\n",
      "100%|██████████| 29/29 [00:25<00:00,  1.16it/s, loss=6.21]\n",
      "INFO:nlstruct:    4 |        \u001b[32m24.2289\u001b[0m |   \u001b[32m0.0122\u001b[0m | \u001b[32m0.0640\u001b[0m |    0.0000 |   26.7759\n",
      "100%|██████████| 29/29 [00:24<00:00,  1.16it/s, loss=2.83]\n",
      "INFO:nlstruct:    5 |        \u001b[32m16.3060\u001b[0m |   \u001b[32m0.0415\u001b[0m | \u001b[32m0.1853\u001b[0m |    0.0000 |   26.7482\n",
      "100%|██████████| 29/29 [00:25<00:00,  1.16it/s, loss=27.5]\n",
      "INFO:nlstruct:    6 |        \u001b[32m13.1493\u001b[0m |   \u001b[32m0.1163\u001b[0m | \u001b[32m0.2460\u001b[0m |    0.0000 |   26.7692\n",
      "100%|██████████| 29/29 [00:25<00:00,  1.16it/s, loss=9.06]\n",
      "INFO:nlstruct:    7 |        \u001b[32m11.2243\u001b[0m |   \u001b[32m0.1557\u001b[0m | \u001b[32m0.3293\u001b[0m |    0.0000 |   26.8026\n",
      "100%|██████████| 29/29 [00:25<00:00,  1.16it/s, loss=8.08]\n",
      "INFO:nlstruct:    8 |         \u001b[32m9.9604\u001b[0m |   \u001b[32m0.2489\u001b[0m | \u001b[32m0.3857\u001b[0m |    0.0000 |   26.8003\n",
      "100%|██████████| 29/29 [00:25<00:00,  1.16it/s, loss=2.66]\n",
      "INFO:nlstruct:    9 |         \u001b[32m8.7262\u001b[0m |   \u001b[32m0.3113\u001b[0m | \u001b[32m0.3880\u001b[0m |    0.0000 |   26.9174\n",
      "100%|██████████| 29/29 [00:24<00:00,  1.16it/s, loss=17.2]\n",
      "INFO:nlstruct:   10 |         \u001b[32m7.6608\u001b[0m |   \u001b[32m0.3742\u001b[0m | \u001b[32m0.4517\u001b[0m |    0.0000 |   26.7333\n",
      "100%|██████████| 29/29 [00:25<00:00,  1.16it/s, loss=5.78]\n",
      "INFO:nlstruct:   11 |         \u001b[32m6.8034\u001b[0m |   \u001b[32m0.4294\u001b[0m | \u001b[32m0.4921\u001b[0m |    0.0000 |   26.7716\n",
      "100%|██████████| 29/29 [00:24<00:00,  1.16it/s, loss=15]  \n",
      "INFO:nlstruct:   12 |         \u001b[32m6.1555\u001b[0m |   \u001b[32m0.4821\u001b[0m | \u001b[32m0.5103\u001b[0m |    0.0000 |   26.7122\n",
      "100%|██████████| 29/29 [00:24<00:00,  1.16it/s, loss=1.27] \n",
      "INFO:nlstruct:   13 |         \u001b[32m5.4079\u001b[0m |   \u001b[32m0.5327\u001b[0m | \u001b[32m0.5233\u001b[0m |    0.0000 |   26.7498\n",
      "100%|██████████| 29/29 [00:24<00:00,  1.16it/s, loss=3.86]\n",
      "INFO:nlstruct:   14 |         \u001b[32m4.9541\u001b[0m |   \u001b[32m0.5615\u001b[0m | \u001b[32m0.5520\u001b[0m |    0.0000 |   26.7650\n",
      "100%|██████████| 29/29 [00:25<00:00,  1.16it/s, loss=0.659]\n",
      "INFO:nlstruct:   15 |         \u001b[32m4.3912\u001b[0m |   \u001b[32m0.6152\u001b[0m | \u001b[32m0.5742\u001b[0m |    0.0000 |   26.7671\n",
      "100%|██████████| 29/29 [00:25<00:00,  1.16it/s, loss=0.793]\n",
      "INFO:nlstruct:   16 |         \u001b[32m3.9283\u001b[0m |   \u001b[32m0.6399\u001b[0m | \u001b[32m0.6017\u001b[0m |    0.0000 |   26.8684\n",
      "100%|██████████| 29/29 [00:24<00:00,  1.16it/s, loss=0.945]\n",
      "INFO:nlstruct:   17 |         \u001b[32m3.5949\u001b[0m |   \u001b[32m0.6672\u001b[0m | \u001b[32m0.6044\u001b[0m |    0.0000 |   26.7274\n",
      "100%|██████████| 29/29 [00:24<00:00,  1.16it/s, loss=0.806]\n",
      "INFO:nlstruct:   18 |         \u001b[32m3.2360\u001b[0m |   \u001b[32m0.7036\u001b[0m | \u001b[31m0.5950\u001b[0m |    0.0000 |   26.7676\n",
      "100%|██████████| 29/29 [00:24<00:00,  1.16it/s, loss=0.36] \n",
      "INFO:nlstruct:   19 |         \u001b[32m2.9346\u001b[0m |   \u001b[32m0.7210\u001b[0m | \u001b[32m0.6066\u001b[0m |    0.0000 |   26.7678\n",
      "100%|██████████| 29/29 [00:25<00:00,  1.16it/s, loss=0.656]\n",
      "INFO:nlstruct:   20 |         \u001b[32m2.6371\u001b[0m |   \u001b[32m0.7399\u001b[0m | \u001b[31m0.6038\u001b[0m |    0.0000 |   26.7729\n",
      "100%|██████████| 29/29 [00:24<00:00,  1.16it/s, loss=3.7]  \n",
      "INFO:nlstruct:   21 |         \u001b[32m2.4152\u001b[0m |   \u001b[32m0.7608\u001b[0m | \u001b[32m0.6186\u001b[0m |    0.0000 |   26.7640\n",
      "100%|██████████| 29/29 [00:24<00:00,  1.16it/s, loss=0.652]\n",
      "INFO:nlstruct:   22 |         \u001b[32m2.1040\u001b[0m |   \u001b[32m0.7823\u001b[0m | \u001b[32m0.6200\u001b[0m |    0.0000 |   26.7609\n",
      "100%|██████████| 29/29 [00:25<00:00,  1.16it/s, loss=0.509]\n",
      "INFO:nlstruct:   23 |         \u001b[32m2.0366\u001b[0m |   \u001b[32m0.7924\u001b[0m | \u001b[32m0.6285\u001b[0m |    0.0000 |   26.8238\n",
      "100%|██████████| 29/29 [00:25<00:00,  1.16it/s, loss=2.68] \n",
      "INFO:nlstruct:   24 |         \u001b[32m1.8431\u001b[0m |   \u001b[32m0.8136\u001b[0m | \u001b[32m0.6395\u001b[0m |    0.0000 |   26.8738\n",
      "100%|██████████| 29/29 [00:24<00:00,  1.16it/s, loss=0.474]\n",
      "INFO:nlstruct:   25 |         \u001b[32m1.7117\u001b[0m |   \u001b[32m0.8221\u001b[0m | \u001b[31m0.6390\u001b[0m |    0.0000 |   26.7117\n",
      "100%|██████████| 29/29 [00:24<00:00,  1.16it/s, loss=1.87] \n",
      "INFO:nlstruct:   26 |         \u001b[32m1.5635\u001b[0m |   \u001b[32m0.8416\u001b[0m | \u001b[32m0.6508\u001b[0m |    0.0000 |   26.7406\n",
      "100%|██████████| 29/29 [00:24<00:00,  1.16it/s, loss=4.05] \n",
      "INFO:nlstruct:   27 |         \u001b[32m1.4659\u001b[0m |   \u001b[32m0.8498\u001b[0m | \u001b[31m0.6273\u001b[0m |    0.0000 |   26.7384\n",
      "100%|██████████| 29/29 [00:24<00:00,  1.16it/s, loss=4.41] \n",
      "INFO:nlstruct:   28 |         \u001b[32m1.3435\u001b[0m |   \u001b[32m0.8664\u001b[0m | \u001b[31m0.6468\u001b[0m |    0.0000 |   26.7346\n",
      "100%|██████████| 29/29 [00:25<00:00,  1.16it/s, loss=0.794]\n",
      "INFO:nlstruct:   29 |         \u001b[32m1.2413\u001b[0m |   \u001b[32m0.8708\u001b[0m | \u001b[31m0.6425\u001b[0m |    0.0000 |   26.7725\n",
      "100%|██████████| 29/29 [00:25<00:00,  1.16it/s, loss=1.9]  \n",
      "INFO:nlstruct:   30 |         \u001b[32m1.1648\u001b[0m |   \u001b[32m0.8785\u001b[0m | \u001b[31m0.6507\u001b[0m |    0.0000 |   26.7782\n",
      "100%|██████████| 29/29 [00:25<00:00,  1.16it/s, loss=2.46] \n",
      "INFO:nlstruct:   31 |         \u001b[32m1.1135\u001b[0m |   \u001b[32m0.8877\u001b[0m | \u001b[32m0.6694\u001b[0m |    0.0000 |   26.8840\n",
      "100%|██████████| 29/29 [00:24<00:00,  1.16it/s, loss=1.35]  \n",
      "INFO:nlstruct:   32 |         \u001b[32m1.0198\u001b[0m |   \u001b[32m0.8928\u001b[0m | \u001b[31m0.6501\u001b[0m |    0.0000 |   26.7126\n",
      "100%|██████████| 29/29 [00:24<00:00,  1.16it/s, loss=0.564]\n",
      "INFO:nlstruct:   33 |         \u001b[32m0.9300\u001b[0m |   \u001b[32m0.9066\u001b[0m | \u001b[31m0.6488\u001b[0m |    0.0000 |   26.7663\n",
      "100%|██████████| 29/29 [00:24<00:00,  1.16it/s, loss=1.72]  \n",
      "INFO:nlstruct:   34 |         \u001b[32m0.8838\u001b[0m |   \u001b[32m0.9066\u001b[0m | \u001b[31m0.6486\u001b[0m |    0.0000 |   26.7273\n",
      "100%|██████████| 29/29 [00:24<00:00,  1.16it/s, loss=2.18] \n",
      "INFO:nlstruct:   35 |         \u001b[32m0.8261\u001b[0m |   \u001b[32m0.9130\u001b[0m | \u001b[31m0.6355\u001b[0m |    0.0000 |   26.7354\n",
      "100%|██████████| 29/29 [00:25<00:00,  1.15it/s, loss=2.12]  \n",
      "INFO:nlstruct:   36 |         \u001b[32m0.7980\u001b[0m |   \u001b[32m0.9143\u001b[0m | \u001b[31m0.6477\u001b[0m |    0.0000 |   26.8999\n",
      "100%|██████████| 29/29 [00:27<00:00,  1.05it/s, loss=0.599] \n",
      "INFO:nlstruct:   37 |         \u001b[32m0.7308\u001b[0m |   \u001b[32m0.9233\u001b[0m | \u001b[31m0.6594\u001b[0m |    0.0000 |   29.3588\n",
      "100%|██████████| 29/29 [00:27<00:00,  1.06it/s, loss=0.197]\n",
      "INFO:nlstruct:   38 |         \u001b[32m0.7020\u001b[0m |   \u001b[31m0.9207\u001b[0m | \u001b[31m0.6585\u001b[0m |    0.0000 |   29.2479\n",
      "100%|██████████| 29/29 [00:27<00:00,  1.06it/s, loss=0.392] \n",
      "INFO:nlstruct:   39 |         \u001b[32m0.6638\u001b[0m |   \u001b[32m0.9343\u001b[0m | \u001b[32m0.6722\u001b[0m |    0.0000 |   29.2211\n",
      "100%|██████████| 29/29 [00:27<00:00,  1.06it/s, loss=1.5]   \n",
      "INFO:nlstruct:   40 |         \u001b[32m0.6077\u001b[0m |   \u001b[32m0.9355\u001b[0m | \u001b[31m0.6486\u001b[0m |    0.0000 |   29.2358\n",
      "100%|██████████| 29/29 [00:27<00:00,  1.05it/s, loss=0.341] \n",
      "INFO:nlstruct:   41 |         \u001b[32m0.5809\u001b[0m |   \u001b[32m0.9410\u001b[0m | \u001b[31m0.6588\u001b[0m |    0.0000 |   29.2837\n",
      "100%|██████████| 29/29 [00:27<00:00,  1.05it/s, loss=0.399] \n",
      "INFO:nlstruct:   42 |         \u001b[32m0.5341\u001b[0m |   \u001b[32m0.9432\u001b[0m | \u001b[31m0.6566\u001b[0m |    0.0000 |   29.3620\n",
      "100%|██████████| 29/29 [00:27<00:00,  1.05it/s, loss=0.159] \n",
      "INFO:nlstruct:   43 |         \u001b[32m0.5339\u001b[0m |   \u001b[32m0.9489\u001b[0m | \u001b[31m0.6663\u001b[0m |    0.0000 |   29.3114\n",
      "100%|██████████| 29/29 [00:25<00:00,  1.15it/s, loss=0.145] \n",
      "INFO:nlstruct:   44 |         \u001b[32m0.5214\u001b[0m |   \u001b[31m0.9485\u001b[0m | \u001b[31m0.6657\u001b[0m |    0.0000 |   27.0115\n",
      "100%|██████████| 29/29 [00:24<00:00,  1.18it/s, loss=0.844] \n",
      "INFO:nlstruct:   45 |         \u001b[32m0.4765\u001b[0m |   \u001b[31m0.9489\u001b[0m | \u001b[31m0.6468\u001b[0m |    0.0000 |   26.2644\n",
      "100%|██████████| 29/29 [00:24<00:00,  1.18it/s, loss=0.431] \n",
      "INFO:nlstruct:   46 |         \u001b[32m0.4503\u001b[0m |   \u001b[32m0.9584\u001b[0m | \u001b[31m0.6687\u001b[0m |    0.0000 |   26.2663\n",
      "100%|██████████| 29/29 [00:24<00:00,  1.18it/s, loss=0.558] \n",
      "INFO:nlstruct:   47 |         \u001b[32m0.4360\u001b[0m |   \u001b[31m0.9536\u001b[0m | \u001b[31m0.6550\u001b[0m |    0.0000 |   26.2783\n",
      "100%|██████████| 29/29 [00:24<00:00,  1.18it/s, loss=1.15]  \n",
      "INFO:nlstruct:   48 |         \u001b[32m0.4360\u001b[0m |   \u001b[32m0.9585\u001b[0m | \u001b[31m0.6677\u001b[0m |    0.0000 |   26.2822\n",
      "100%|██████████| 29/29 [00:24<00:00,  1.18it/s, loss=1.02]  \n",
      "INFO:nlstruct:   49 |         \u001b[32m0.3810\u001b[0m |   \u001b[32m0.9618\u001b[0m | \u001b[31m0.6647\u001b[0m |    0.0000 |   26.3019\n",
      "100%|██████████| 29/29 [00:24<00:00,  1.18it/s, loss=1.01]  \n",
      "INFO:nlstruct:   50 |         \u001b[32m0.3778\u001b[0m |   \u001b[32m0.9622\u001b[0m | \u001b[31m0.6576\u001b[0m |    0.0000 |   26.3215\n"
     ]
    }
   ],
   "source": [
    "def select_mention_level(batch_mentions, depth_level):\n",
    "    tag_mask = batch_mentions[\"mention\", \"depth\"]==depth_level\n",
    "    return batch_mentions[\"mention\"][tag_mask]\n",
    "\n",
    "import traceback\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import AdamW, BertModel\n",
    "\n",
    "from tqdm import tqdm\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from nlstruct.environment import get_cache\n",
    "from nlstruct.utils import evaluating, torch_global as tg, freeze\n",
    "from nlstruct.scoring import compute_metrics, merge_pred_and_gold\n",
    "from nlstruct.train import make_optimizer_and_schedules, iter_optimization, seed_all\n",
    "from nlstruct.train.schedule import ScaleOnPlateauSchedule, LinearSchedule, ConstantSchedule\n",
    "\n",
    "from nlstruct.utils import torch_clone\n",
    "    \n",
    "device = torch.device('cuda:0')\n",
    "tg.set_device(device)\n",
    "all_preds = []\n",
    "histories = []\n",
    "\n",
    "# To release gpu memory before allocating new parameters for a new model\n",
    "# A better idea would be to run xp in a function, so that all variables are released when exiting the fn\n",
    "# but this way we can debug after this cell if something goes wrong\n",
    "if \"all_nets\" in globals(): del all_nets\n",
    "if \"optim\" in globals(): del optim, \n",
    "if \"schedules\" in globals(): del schedules\n",
    "if \"final_schedule\" in globals(): del final_schedule\n",
    "if \"state\" in globals(): del state\n",
    "    \n",
    "# Hyperparameter search\n",
    "layer = 2\n",
    "hidden_dim = 1024 \n",
    "scheme = 'bioul' \n",
    "seed = 12\n",
    "lr = 7e-4\n",
    "bert_lr = 6e-5\n",
    "dropout = 0.1\n",
    "\n",
    "seed_all(seed) # /!\\ Super important to enable reproducibility\n",
    "\n",
    "max_grad_norm = 5.\n",
    "bert_weight_decay = 0.0000\n",
    "batch_size = 64\n",
    "random_perm=True\n",
    "n_freeze = layer + 2\n",
    "bert_dropout = 0.2\n",
    "\n",
    "ner_net = NERNet(\n",
    "        n_tokens=len(vocs[\"token\"]),\n",
    "        token_dim=1024 if \"large\" in bert_name else 768,#768,\n",
    "        embeddings=BertModel.from_pretrained(bert_name),#, custom_embeds_layer_index=custom_embeds_layer_index),\n",
    "        n_labels = len(vocs['ner_label']),\n",
    "        dropout=dropout,\n",
    "        hidden_dim=hidden_dim,\n",
    "        tag_scheme=scheme,\n",
    ")\n",
    "all_nets = torch.nn.ModuleDict({\n",
    "    \"ner_net\": ner_net,\n",
    "}).to(device=tg.device)\n",
    "del ner_net\n",
    "\n",
    "for module in all_nets[\"ner_net\"].embeddings.modules():\n",
    "    if isinstance(module, torch.nn.Dropout):\n",
    "        module.p = bert_dropout\n",
    "all_nets.train()\n",
    "\n",
    "# Define the optimizer, maybe multiple learning rate / schedules per parameters groups\n",
    "optim = AdamW(params=all_nets['ner_net'].parameters(), lr=lr)\n",
    "\n",
    "# Freeze some bert layers \n",
    "# - n_freeze = 0 to freeze nothing\n",
    "# - n_freeze = 1 to freeze word embeddings / position embeddings / ...\n",
    "# - n_freeze = 2..13 to freeze the first, second ... 12th layer of bert\n",
    "for name, param in all_nets.named_parameters():\n",
    "    match = re.search(\"\\.(\\d+)\\.\", name)\n",
    "    if (match and int(match.group(1)) < n_freeze - 1) and ('embeddings' in name):\n",
    "        freeze([param])\n",
    "        \n",
    "# if n_freeze > 0:\n",
    "#     if hasattr(all_nets['ner_net'].embeddings, 'embeddings'):\n",
    "#         freeze(all_nets['ner_net'].embeddings.embeddings)\n",
    "#     else:\n",
    "#         freeze(all_nets['ner_net'].embeddings)\n",
    "\n",
    "with_tqdm = True\n",
    "state = {\"all_nets\": all_nets, \"optim\": optim}  # all we need to restart the training from a given epoch\n",
    "\n",
    "cache = get_cache(\"genia_rl_tests\", {\n",
    "    \"seed\": seed, \n",
    "    \"train_batcher\": train_batcher, \n",
    "    \"val_batcher\": None, \n",
    "    \"random_perm\": random_perm,\n",
    "    \"batch_size\": batch_size, \n",
    "    \"max_grad_norm\": max_grad_norm, \n",
    "    **state,\n",
    "}, loader=torch.load, dumper=torch.save)\n",
    "\n",
    "!rm -rf $cache\n",
    "\n",
    "cache = get_cache(\"genia_rl_tests\", {\n",
    "    \"seed\": seed, \n",
    "    \"train_batcher\": train_batcher, \n",
    "    \"val_batcher\": None, \n",
    "    \"random_perm\": random_perm,\n",
    "    \"batch_size\": batch_size, \n",
    "    \"max_grad_norm\": max_grad_norm, \n",
    "    **state\n",
    "}, loader=torch.load, dumper=torch.save)\n",
    "\n",
    "#batch = next(iter(train_batcher['sentence'].dataloader(batch_size=batch_size, shuffle=True, sparse_sort_on=[\"token_mask\"], device=device)))\n",
    "\n",
    "level = 0\n",
    "\n",
    "level_train_batcher = train_batcher['mention'].set_join_order(('mention',))[train_batcher['mention','depth']==level]\n",
    "level_val_batcher = val_batcher['mention'].set_join_order(('mention',))[val_batcher['mention','depth']==level]\n",
    "\n",
    "for epoch_before, state, history, record in iter_optimization(\n",
    "    main_score = \"val_f1\", # do not earlystop based on validation\n",
    "    metrics_info=metrics_info,\n",
    "    max_epoch=50,\n",
    "    patience=50,\n",
    "    state=state, \n",
    "    cache_policy=\"all\", \n",
    "    #cache=cache,\n",
    "    n_save_checkpoints=2,\n",
    "#             exit_on_score=0.92,\n",
    "):\n",
    "    pred_batches = []\n",
    "    gold_batches = []\n",
    "\n",
    "    total_train_ner_loss = 0\n",
    "    total_train_acc = 0\n",
    "    total_train_ner_size = 0\n",
    "\n",
    "    n_mentions = len(train_batcher[\"mention\"])\n",
    "    n_matched_mentions = 0\n",
    "    n_target_mentions = 0\n",
    "    n_observed_mentions = 0\n",
    "\n",
    "    #with tqdm(repeat(batch, 1000), disable=not with_tqdm) as bar:\n",
    "    with tqdm(train_batcher['sentence'].dataloader(batch_size=batch_size, shuffle=True, sparse_sort_on=[\"token_mask\"], device=device), disable=not with_tqdm) as bar:\n",
    "        for batch_i, batch in enumerate(bar):\n",
    "            \n",
    "            #seed_all(seed)\n",
    "            \n",
    "            optim.zero_grad()\n",
    "\n",
    "            n_samples, sentence_size = batch[\"sentence\", \"token\"].shape\n",
    "            n_labels = len(vocs[\"ner_label\"])\n",
    "            n_depth = batch[\"mention\", \"depth\"].max() + 1\n",
    "            \n",
    "            mask = batch[\"token_mask\"]\n",
    "\n",
    "            # Compute the tokens label tag of the selected non-overlapping gold mentions to infer from the model\n",
    "            #target_tags = {}\n",
    "\n",
    "            #for depth_level in range(3):\n",
    "\n",
    "            #bm = select_mention_level(batch, depth_level)\n",
    "\n",
    "            target_tags = BIOULDecoder.spans_to_tags(\n",
    "                batch[\"mention\", \"depth\"] * n_labels * n_samples + (batch[\"mention\", \"@sentence_id\"] * n_labels + batch[\"mention\", \"ner_label\"]),\n",
    "                batch[\"mention\", \"begin\"],\n",
    "                batch[\"mention\", \"end\"], \n",
    "                torch.zeros_like(batch[\"mention\", \"ner_label\"]),\n",
    "                n_tokens=sentence_size,\n",
    "                n_samples=n_samples * n_labels * n_depth,\n",
    "            )\n",
    "            target_tags = target_tags.view(n_depth, n_samples, n_labels, sentence_size)\n",
    "            target_tags = target_tags.transpose(-1, -2)\n",
    "            \n",
    "            #if depth_level==0:\n",
    "            #    gold_batches.append(bm)\n",
    "\n",
    "            # WITH DEPTH\n",
    "            \n",
    "#             # Compute the tokens label tag of the selected non-overlapping gold mentions to infer from the model\n",
    "#             n_depth = batch[\"mention\", \"depth\"].max().item() + 2\n",
    "#             target_tags = all_nets[\"ner_net\"].crf_list1[0].spans_to_tags(\n",
    "#                 batch[\"mention\", \"@sentence_id\"] + batch[\"mention\", \"depth\"] * n_samples,\n",
    "#                 batch[\"mention\", \"begin\"],\n",
    "#                 batch[\"mention\", \"end\"], \n",
    "#                 batch[\"mention\", \"ner_label\"], \n",
    "#                 n_tokens=sentence_size,\n",
    "#                 n_samples=n_samples * n_depth,\n",
    "#             ) # [n_samples * n_labels] * sentence_size\n",
    "#             target_tags = target_tags.view(n_depth, n_samples, sentence_size)\n",
    "\n",
    "            res = all_nets[\"ner_net\"].forward(\n",
    "                tokens=batch[\"token\"],\n",
    "                mask=mask,\n",
    "                tags=target_tags,\n",
    "                return_loss = True,\n",
    "            )\n",
    "            \n",
    "            ner_loss = res['loss']\n",
    "            scores = res['scores']\n",
    "            spans = res['sampled_spans']\n",
    "            sampled_tags = res['sampled_tags']\n",
    "            baseline_tags = res['baseline_tags']\n",
    "            \n",
    "            pred_batch = Batcher({\n",
    "                \"mention\": {\n",
    "                    \"mention_id\": torch.arange(n_mentions, n_mentions+len(spans['span_doc_id']), device=device),\n",
    "                    \"begin\": spans[\"span_begin\"],\n",
    "                    \"end\": spans[\"span_end\"],\n",
    "                    \"ner_label\": spans[\"span_label\"],\n",
    "                    \"@sentence_id\": spans[\"span_doc_id\"],\n",
    "                },\n",
    "                \"sentence\": dict(batch[\"sentence\", [\"sentence_id\", \"doc_id\"]]),\n",
    "                \"doc\": dict(batch[\"doc\"])}, \n",
    "                check=False)\n",
    "            pred_batches.append(pred_batch)\n",
    "            n_mentions += len(spans['span_doc_id'])\n",
    "            \n",
    "            sampled_f1 = torch_f1(target_tags[0], torch.stack(sampled_tags).squeeze().permute(1,2,0))\n",
    "            baseline_f1 = torch_f1(target_tags[0], torch.stack(baseline_tags).squeeze().permute(1,2,0))\n",
    "            \n",
    "            total_train_ner_loss += float(ner_loss) * len(batch[\"sentence\"])\n",
    "            total_train_ner_size += len(batch[\"sentence\"])\n",
    "            \n",
    "            loss = ner_loss * ((sampled_f1 - baseline_f1) or 1)\n",
    "            \n",
    "            if (sampled_f1 - baseline_f1 )!= 0:\n",
    "                print(\"AY\")\n",
    "            \n",
    "            # Perform optimization step\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(all_nets.parameters(), max_grad_norm)\n",
    "            optim.step()\n",
    "            \n",
    "            bar.set_postfix(loss=loss.item())\n",
    "            \n",
    "    from nlstruct.scoring import compute_metrics, merge_pred_and_gold\n",
    "    \n",
    "    train_pred = Batcher.concat(pred_batches)\n",
    "    val_pred = extract_mentions(val_batcher, all_nets=all_nets)\n",
    "    \n",
    "    train_metrics = compute_metrics(merge_pred_and_gold(\n",
    "        pred=pd.DataFrame(dict(train_pred[\"mention\", [\"sentence_id\", \"begin\", \"end\", \"ner_label\"]])), #extract_mentions(val_batcher, all_nets=all_nets)\n",
    "        gold=pd.DataFrame(dict(level_train_batcher[\"mention\", [\"sentence_id\", \"begin\", \"end\", \"ner_label\"]])), \n",
    "        span_policy='exact',  # only partially match spans with strict bounds, we could also eval with 'exact' or 'partial'\n",
    "        on=[\"sentence_id\", (\"begin\", \"end\"), \"ner_label\"]), prefix='train_')[[\"train_recall\", \"train_precision\", \"train_f1\"]].to_dict()\n",
    "\n",
    "    val_metrics = compute_metrics(merge_pred_and_gold(\n",
    "        pred=pd.DataFrame(dict(val_pred[\"mention\", [\"sentence_id\", \"begin\", \"end\", \"ner_label\"]])), #extract_mentions(val_batcher, all_nets=all_nets)\n",
    "        gold=pd.DataFrame(dict(level_val_batcher[\"mention\", [\"sentence_id\", \"begin\", \"end\", \"ner_label\"]])), \n",
    "        span_policy='exact',  # only partially match spans with strict bounds, we could also eval with 'exact' or 'partial'\n",
    "        on=[\"sentence_id\", (\"begin\", \"end\"), \"ner_label\"]), prefix='val_')[[\"val_recall\", \"val_precision\", \"val_f1\"]].to_dict()\n",
    "    \n",
    "    # Compute precision, recall and f1 on train set\n",
    "#     train_pred = Batcher.concat(pred_batches)\n",
    "#     train_gold = Batcher.concat(gold_batches)\n",
    "#     train_metrics    = compute_scores(train_pred, train_gold, prefix='train_')\n",
    "    \n",
    "#     val_pred = extract_mentions(val_batcher, all_nets=all_nets)\n",
    "#     val_gold = select_mention_level(val_batcher, 0)\n",
    "#     val_metrics     = compute_scores(val_pred, val_gold, prefix='val_')\n",
    "    \n",
    "#     test_pred = extract_mentions(test_batcher, all_nets=all_nets)\n",
    "#     test_gold = select_mention_level(test_batcher, 0)\n",
    "#     test_metrics = compute_scores(test_pred, test_gold, prefix='test_')\n",
    "    \n",
    "    record(\n",
    "    {\n",
    "        \"train_ner_loss\": total_train_ner_loss / max(total_train_ner_size, 1),\n",
    "        **train_metrics,\n",
    "        **val_metrics,\n",
    "        \"n_matched\": n_matched_mentions,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test \n",
    "(to be fair, avoid executing this part of the notebook to often, or use the training set instead)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yt_nlp",
   "language": "python",
   "name": "yt_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
