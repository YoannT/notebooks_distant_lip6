{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MRCONSO COL DESCRIPTION\n",
    "\n",
    "Col.\tDescription\n",
    "\n",
    "CUI\tUnique identifier for concept\n",
    "\n",
    "LAT\tLanguage of term\n",
    "\n",
    "TS\tTerm status\n",
    "\n",
    "LUI\tUnique identifier for term\n",
    "\n",
    "STT\tString type\n",
    "\n",
    "SUI\tUnique identifier for string\n",
    "\n",
    "ISPREF\tAtom status - preferred (Y) or not (N) for this string within this concept\n",
    "\n",
    "AUI\tUnique identifier for atom - variable length field, 8 or 9 characters\n",
    "\n",
    "SAUI\tSource asserted atom identifier [optional]\n",
    "\n",
    "SCUI\tSource asserted concept identifier [optional]\n",
    "\n",
    "SDUI\tSource asserted descriptor identifier [optional]\n",
    "\n",
    "SAB\tAbbreviated source name (SAB). Maximum field length is 20 alphanumeric characters. Two source abbreviations are assigned:\n",
    "Root Source Abbreviation (RSAB) — short form, no version information, for example, AI/RHEUM, 1993, has an RSAB of \"AIR\"\n",
    "Versioned Source Abbreviation (VSAB) — includes version information, for example, AI/RHEUM, 1993, has an VSAB of \"AIR93\"\n",
    "Official source names, RSABs, and VSABs are included on the UMLS Source Vocabulary Documentation page.\n",
    "\n",
    "TTY\tAbbreviation for term type in source vocabulary, for example PN (Metathesaurus Preferred Name) or CD (Clinical Drug). Possible values are listed on the Abbreviations Used in Data Elements page.\n",
    "\n",
    "CODE\tMost useful source asserted identifier (if the source vocabulary has more than one identifier), or a Metathesaurus-generated source entry identifier (if the source vocabulary has none)\n",
    "\n",
    "STR\tString\n",
    "\n",
    "SRL\tSource restriction level\n",
    "\n",
    "SUPPRESS\tSuppressible flag. Values = O, E, Y, or N\n",
    "O: All obsolete content, whether they are obsolesced by the source or by NLM. These will include all atoms having obsolete TTYs, and other atoms becoming obsolete that have not acquired an obsolete TTY (e.g. RxNorm SCDs no longer associated with current drugs, LNC atoms derived from obsolete LNC concepts).\n",
    "E: Non-obsolete content marked suppressible by an editor. These do not have a suppressible SAB/TTY combination.\n",
    "Y: Non-obsolete content deemed suppressible during inversion. These can be determined by a specific SAB/TTY combination explicitly listed in MRRANK.\n",
    "N: None of the above\n",
    "Default suppressibility as determined by NLM (i.e., no changes at the Suppressibility tab in MetamorphoSys) should be used by most users, but may not be suitable in some specialized applications. See the MetamorphoSys Help page for information on how to change the SAB/TTY suppressibility to suit your requirements. NLM strongly recommends that users not alter editor-assigned suppressibility, and MetamorphoSys cannot be used for this purpose.\n",
    "\n",
    "CVF\tContent View Flag. Bit field used to flag rows included in Content View. This field is a varchar field to maximize the number of bits available for use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ytaille/.conda/envs/yt_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:17: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "/home/ytaille/.conda/envs/yt_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:19: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "mrsty_file = '/home/ytaille/data/resources/umls/2017AB/MRSTY.RRF'\n",
    "sgr_file = '/home/ytaille/data/resources/umls/semantic_groups_2018.txt'\n",
    "# mrconso_file = '/home/ytaille/data/resources/umls/2014AB/MRCONSO.RRF'\n",
    "\n",
    "# from glob import glob\n",
    "# n2c2_path = '/home/ytaille/data/resources/n2c2/train_norm/*.norm'\n",
    "# full_n2c2_df = pd.concat(\n",
    "#     [pd.read_csv(f, sep='\\|\\|', names=['mention_id', 'CUI', 'begin', 'end'], index_col=False) for f in glob(n2c2_path)]\n",
    "# )\n",
    "\n",
    "mrsty_cols = ['CUI', 'TUI', 'STN', 'STY', 'ATUI', 'CVF']\n",
    "# mrconso_cols = ['CUI', 'LAT', 'TS', 'LUI', 'STT', 'SUI', 'ISPREF', 'AUI', 'SAUI', 'SCUI', 'SDUI', 'SAB', 'TTY', 'CODE', 'STR', 'SRL', 'SUPPRESS', 'CVF']\n",
    "\n",
    "# n2c2_df = pd.read_csv(n2c2_file, sep='\\|\\|', names=['mention_id', 'CUI', 'begin', 'end'], index_col=False)\n",
    "mrsty_df = pd.read_csv(mrsty_file, sep='\\|', names=mrsty_cols, index_col=False)\n",
    "mrsty_df.set_index('CUI', inplace=True)\n",
    "sgr_df = pd.read_csv(sgr_file, sep='\\|', names=['abbrev', 'class', 'TUI', 'description'], index_col=False)\n",
    "sgr_df.set_index('TUI', inplace=True)\n",
    "# mrconso_df = pd.read_csv(mrconso_file, sep='\\|', names=mrconso_cols, index_col=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ytaille/.conda/envs/yt_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:18: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of fails:  0 , number of successes:  6533\n"
     ]
    }
   ],
   "source": [
    "# read train_file_list.txt\n",
    "# for each file: conv to brat, keep CUI in annotatornotes \n",
    "# Example:\n",
    "#2\tAnnotatorNotes T2\tC1530575\n",
    "\n",
    "split = 'train'\n",
    "\n",
    "with open(f'/home/ytaille/data/resources/n2c2/{split}_file_list.txt', 'r') as f :\n",
    "    file_names = [fn.strip('\\n') for fn in f.readlines()]\n",
    "    \n",
    "fail_cpt = 0\n",
    "success_cpt = 0\n",
    "\n",
    "for fn in file_names:\n",
    "    norm_path = f'/home/ytaille/data/resources/n2c2/{split}_norm/{fn}.norm'\n",
    "    note_path = f'/home/ytaille/data/resources/n2c2/{split}_note/{fn}.txt'\n",
    "    \n",
    "    norm_df = pd.read_csv(norm_path, sep='\\|\\|', names=['mention_id', 'CUI', 'begin', 'end'], index_col=False)\n",
    "    \n",
    "    with open(note_path, 'r') as f:\n",
    "        note_txt = f.read()\n",
    "        \n",
    "    ann_str = ''\n",
    "    mention_id = 0\n",
    "        \n",
    "    for _, mention in norm_df.iterrows():\n",
    "        try:\n",
    "            TUI = mrsty_df.loc[mention.CUI].TUI\n",
    "            ann_label = sgr_df.loc[TUI].abbrev\n",
    "            \n",
    "            if isinstance(ann_label, pd.Series):\n",
    "                ann_label = ann_label[0]\n",
    "                \n",
    "            ann_str += f'T{mention_id}\\t{ann_label} {mention.begin} {mention.end}\\t{note_txt[mention.begin:mention.end]}\\n'\n",
    "            ann_str += f'#{mention_id}\\tAnnotatorNotes T{mention_id}\\t{mention.CUI}\\n'\n",
    "            mention_id += 1\n",
    "            success_cpt += 1\n",
    "        except:\n",
    "            if mention.CUI != 'CUI-less':\n",
    "                print(\"TUI:\", TUI)\n",
    "                print(\"MENTION:\", mention)\n",
    "                print(\"#########\")\n",
    "                fail_cpt += 1\n",
    "            \n",
    "    with open(f'/home/ytaille/data/resources/n2c2/brat_files/{split}/{fn}.ann', 'w') as f:\n",
    "        f.write(ann_str)\n",
    "    with open(f'/home/ytaille/data/resources/n2c2/brat_files/{split}/{fn}.txt', 'w') as f:\n",
    "        f.write(note_txt)\n",
    "\n",
    "print(\"number of fails: \", fail_cpt, \", number of successes: \", success_cpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yt_nlp",
   "language": "python",
   "name": "yt_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
