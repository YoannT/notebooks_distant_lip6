{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ\n",
    "environ[\"CUDA_NON_BLOCKING\"] = \"1\"\n",
    "environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlstruct.text import huggingface_tokenize, regex_sentencize, partition_spans, encode_as_tag, split_into_spans, apply_substitutions, apply_deltas\n",
    "from nlstruct.dataloaders import load_from_brat, load_genia_ner\n",
    "from nlstruct.collections import Dataset, Batcher\n",
    "from nlstruct.utils import merge_with_spans, normalize_vocabularies, factorize_rows, df_to_csr, factorize, torch_global as tg\n",
    "from nlstruct.modules.crf import BIODecoder, BIOULDecoder\n",
    "from nlstruct.environment import root, cached\n",
    "from nlstruct.train import seed_all\n",
    "from itertools import chain, repeat\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "def select_closest_non_overlapping_gold_mentions(\n",
    "    gold_ids,\n",
    "    gold_sentence_ids,\n",
    "    gold_begins,\n",
    "    gold_ends,\n",
    "    \n",
    "    pred_sentence_ids,\n",
    "    pred_begins,\n",
    "    pred_ends,\n",
    "    \n",
    "    zone_mention_id,\n",
    "    zone_mask,\n",
    "    gold_conflicts,\n",
    "    gold_conflicts_mask,\n",
    "):\n",
    "    \"\"\"\n",
    "    Select non overlapping gold mentions (in gold_ids) that are the closest to those found by the model\n",
    "    Gold mentions are described by gold_* tensors, predicted mentions are described by pred_* tensors\n",
    "    We select at most one gold mention per zone (zone_mention_id + zone_mask) and each time a gold mention\n",
    "    is selected, its overlaps are removed according to the gold_conflicts + gold_conflicts_mask tensors\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        Selected gold ids, included in \"gold_ids\"\n",
    "    \"\"\"\n",
    "\n",
    "    device = gold_begins.device\n",
    "    \n",
    "    if len(gold_ids) == 0:\n",
    "        return torch.as_tensor([], dtype=torch.long, device=device)\n",
    "\n",
    "    [rel], [remaining_mask], _ = factorize([zone_mention_id], [zone_mask], reference_values=gold_ids)\n",
    "    remaining_mentions = zone_mention_id[remaining_mask.any(1)]\n",
    "    rel = rel[remaining_mask.any(1)]\n",
    "    remaining_mask = remaining_mask[remaining_mask.any(1)]\n",
    "        \n",
    "    keep_mask = torch.zeros(gold_ids.max()+1, device=device, dtype=torch.bool)\n",
    "    zone_scores = torch.full(remaining_mask.shape, fill_value=-1, device=device, dtype=torch.float)\n",
    "    \n",
    "    if len(pred_begins):\n",
    "        PRED, GOLD = 0, 1\n",
    "        SENTENCE_ID, BEGIN, END = 0, 1, 2\n",
    "        p = torch.stack([pred_sentence_ids, pred_begins, pred_ends], dim=0).unsqueeze(GOLD+1)\n",
    "        g = torch.stack([gold_sentence_ids, gold_begins, gold_ends], dim=0).unsqueeze(PRED+1)\n",
    "\n",
    "        overlap = (torch.min(p[END], g[END]) - torch.max(p[BEGIN], g[BEGIN])).float().clamp(0)\n",
    "        overlap = overlap * 2 / (p[END] - p[BEGIN] + g[END] - g[BEGIN])\n",
    "        score = (p[SENTENCE_ID] == g[SENTENCE_ID]) * overlap\n",
    "        \n",
    "        zone_scores = score.max(0).values[rel]\n",
    "        zone_scores[~remaining_mask] = -1\n",
    "    else:\n",
    "        zone_scores[remaining_mask] = 0\n",
    "    while len(remaining_mask):\n",
    "        best_indexer = torch.arange(zone_scores.shape[0], device=device), zone_scores.argmax(1)\n",
    "        best_mentions = remaining_mentions[best_indexer]\n",
    "        conflicts = gold_conflicts[best_mentions][gold_conflicts_mask[best_mentions]]    \n",
    "        keep_mask[best_mentions] = True\n",
    "        remaining_mask[best_indexer] = False\n",
    "        remaining_mask &= ~(remaining_mentions.unsqueeze(-1) == conflicts).any(-1)\n",
    "        zone_scores[~remaining_mask] = -1\n",
    "        zone_scores = zone_scores[remaining_mask.any(1)]\n",
    "        remaining_mentions = remaining_mentions[remaining_mask.any(1)]\n",
    "        remaining_mask = remaining_mask[remaining_mask.any(1)]\n",
    "    return keep_mask.nonzero()[:, 0]\n",
    "\n",
    "def split_zone_mentions(batch, random_perm=True, observed_zone_sizes=None):\n",
    "    \"\"\"\n",
    "    In a batch, splits mentions between \n",
    "    - those that we will consider as being observed\n",
    "    - and those that we will ask the model to recover\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    random_perm: bool\n",
    "        Shuffle the mentions before splitting them\n",
    "    observed_zone_sizes: int\n",
    "        If not None, selects exactly this number of mentions per zone (=overlapping group of mentions)\n",
    "        Otherwise, any random number from 0 to the maximum of mentions can be observed in each group\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    (torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor)\n",
    "        - observed_mentions: flat observed mentions (@mention_id)\n",
    "        - target_mentions: flat target mentions (@mention_id)\n",
    "        - zone_target_mentions: mentions to recover, grouped by zone (n_zones * n_mentions_per_zone)\n",
    "        - target_mask: mask of zone_target_mentions, since every zone can have a different number of picked target mentions\n",
    "    \"\"\"\n",
    "    zone_mention_id = batch[\"zone\", \"@mention_id\"]\n",
    "    zone_mention_mask = batch[\"zone\", \"mention_mask\"]\n",
    "    n_sentences = len(batch[\"sentence\"])\n",
    "    device = zone_mention_id.device\n",
    "    if random_perm:\n",
    "        perm = torch.rand(zone_mention_id.shape, device=device)\n",
    "    else:\n",
    "        perm = torch.zeros(zone_mention_id.shape, device=device, dtype=torch.float)\n",
    "    perm[~zone_mention_mask] = 2\n",
    "    perm = perm.argsort(1)\n",
    "\n",
    "    if observed_zone_sizes is None:\n",
    "        observed_zone_size = ((zone_mention_mask.sum(-1) + 1) * torch.rand(zone_mention_mask.shape[0], dtype=torch.float, device=device)).long()\n",
    "    else:\n",
    "        observed_zone_size = torch.full((zone_mention_mask.shape[0],), fill_value=observed_zone_sizes, device=device, dtype=torch.long)\n",
    "\n",
    "    # Select mentions that will become features\n",
    "    zone_observed_mentions = zone_mention_id[torch.arange(perm.shape[0], device=device).unsqueeze(1), perm]\n",
    "    observed_mask = (torch.arange(zone_mention_mask.shape[1], device=device).unsqueeze(0) < observed_zone_size.unsqueeze(1)) & zone_mention_mask\n",
    "    observed_mentions = zone_observed_mentions[observed_mask]\n",
    "\n",
    "    # Select mentions that will be hidden from the model (ie to recover)\n",
    "    zone_target_mentions = zone_mention_id[torch.arange(perm.shape[0], device=device).unsqueeze(1), perm]\n",
    "    target_mask = (torch.arange(zone_mention_mask.shape[1], device=device).unsqueeze(0) >= observed_zone_size.unsqueeze(1)) & zone_mention_mask\n",
    "    zone_target_mentions = zone_target_mentions[target_mask.any(1)]\n",
    "    target_mask = target_mask[target_mask.any(1)]\n",
    "    target_mentions = zone_target_mentions[target_mask]\n",
    "    return target_mentions, observed_mentions, zone_target_mentions, target_mask\n",
    "\n",
    "def compute_scores(pred_batcher, gold_batcher, queries={}, prefix='val_', verbose=0):\n",
    "    pred=pd.DataFrame(dict(pred_batcher[\"mention\", [\"sentence_id\", \"begin\", \"end\", \"ner_label\", \"mention_id\"]]))\n",
    "    gold=pd.DataFrame(dict(gold_batcher[\"mention\", [\"@zone_id\", \"begin\", \"end\", \"ner_label\", \"mention_id\"]]))\n",
    "    gold[\"sentence_id\"] = gold_batcher[\"zone\", \"sentence_id\"][gold[\"@zone_id\"]]\n",
    "\n",
    "    # Merge on spans and ner_label\n",
    "    merged = merge_pred_and_gold(\n",
    "        pred, gold, span_policy='exact',  # only partially match spans with strict bounds, we could also eval with 'exact' or 'partial'\n",
    "        on=[\"sentence_id\", (\"begin\", \"end\"), \"ner_label\"], atom_gold_level=[\"mention_id\"], atom_pred_level=[\"mention_id\"])\n",
    "    \n",
    "    merged[\"ner_label\"] = np.asarray(vocs[\"ner_label\"])[merged[\"ner_label\"]].astype(str)\n",
    "    metrics = {\n",
    "        **compute_metrics(merged, prefix=prefix),\n",
    "        #**compute_metrics(merged.query(\"ner_label == {}\".format(list(vocs[\"ner_label\"]).index(c[\"sosy\"]))), prefix=prefix+\"sosy_\"),\n",
    "        #**compute_metrics(merged.query(\"ner_label == {}\".format(list(vocs[\"ner_label\"]).index(c[\"pathologie\"]))), prefix=prefix+\"pathologie_\"),\n",
    "    }\n",
    "    for name, query in queries.items():\n",
    "        metrics.update(compute_metrics(merged.query(query), prefix=prefix+name+\"_\"))\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To debug the training, we can just comment the \"def run_epoch()\" and execute the function body manually without changing anything to it\n",
    "def extract_mentions(batcher, all_nets, max_depth=10):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    batcher: Batcher \n",
    "        The batcher containing the text from which we want to extract the mentions (and maybe the gold mentions)\n",
    "    ner_net: torch.nn.Module\n",
    "    max_depth: int\n",
    "        Max number of times we run the model per sample\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Batcher\n",
    "    \"\"\"\n",
    "    pred_batches = []\n",
    "    n_mentions = 0\n",
    "    ner_net = all_nets[\"ner_net\"]\n",
    "    tag_embeddings = all_nets[\"tag_embeddings\"]\n",
    "    with evaluating(all_nets):\n",
    "        with torch.no_grad():\n",
    "            for batch_i, batch in enumerate(batcher['sentence'].dataloader(batch_size=batch_size, shuffle=False, sparse_sort_on=\"token_mask\", device=tg.device)):\n",
    "\n",
    "                tag_embeds = torch.zeros(*batch[\"sentence\", \"token\"].shape[:2], tag_dim, device=tg.device)\n",
    "                current_sentences_idx = torch.arange(len(batch), device=tg.device)\n",
    "                mask = batch[\"token_mask\"]\n",
    "                tokens = batch[\"token\"]\n",
    "\n",
    "                for i in range(max_depth):\n",
    "                    # Run the model argmax here\n",
    "                    ner_res = ner_net(\n",
    "                        tokens = tokens,\n",
    "                        mask = mask,\n",
    "                        tag_embeds = tag_embeds,\n",
    "                        return_embeddings=True\n",
    "                    )\n",
    "\n",
    "                    # Run the linear CRF Viterbi algorithm to compute the most likely sequence\n",
    "                    pred_tags = ner_net.crf.decode(ner_res[\"scores\"], mask)\n",
    "                    spans = ner_net.crf.tags_to_spans(pred_tags, mask)\n",
    "\n",
    "                    # Save predicted mentions\n",
    "                    pred_batch = Batcher({\n",
    "                        \"mention\": {\n",
    "                            \"mention_id\": torch.arange(n_mentions, n_mentions+len(spans[\"span_doc_id\"]), device=tg.device),\n",
    "                            \"begin\": spans[\"span_begin\"],\n",
    "                            \"end\": spans[\"span_end\"],\n",
    "                            \"ner_label\": spans[\"span_label\"],\n",
    "                            \"@sentence_id\": current_sentences_idx[spans[\"span_doc_id\"]],\n",
    "                            \"depth\": torch.full_like(spans[\"span_begin\"], fill_value=i),\n",
    "                        },\n",
    "                        \"sentence\": dict(batch[\"sentence\", [\"sentence_id\", \"doc_id\"]]),\n",
    "                        \"doc\": dict(batch[\"doc\"])}, \n",
    "                        check=False).sparsify()\n",
    "                    pred_batches.append(pred_batch)\n",
    "                    n_mentions += len(spans[\"span_doc_id\"])\n",
    "\n",
    "                    non_empty_sentences = torch.unique(spans[\"span_doc_id\"])\n",
    "\n",
    "                    if len(non_empty_sentences) == 0:\n",
    "                        break\n",
    "\n",
    "                    # Convert the predicted spans to tags using the same encoding scheme as the one used to decode predicted tags\n",
    "                    # (We could use a different one: BIODecoder/BIOULDecoder.spans_to_tags is a static function)\n",
    "                    feature_tags = ner_net.crf.spans_to_tags(\n",
    "                        torch.arange(len(spans[\"span_begin\"]), device=spans[\"span_begin\"].device),\n",
    "                        spans[\"span_begin\"], \n",
    "                        spans[\"span_end\"],\n",
    "                        spans[\"span_label\"], \n",
    "                        n_tokens=batch[\"sentence\", \"token\"].shape[1],\n",
    "                        n_samples=len(spans[\"span_begin\"]),\n",
    "                    )\n",
    "                    tag_mention, tag_positions = feature_tags.nonzero(as_tuple=True)\n",
    "                    tag_sentence = spans[\"span_doc_id\"][tag_mention]\n",
    "                    tag_values = feature_tags[tag_mention, tag_positions]\n",
    "\n",
    "                    tag_embeds = tag_embeds.view(-1, tag_dim).index_add_(\n",
    "                        dim=0,\n",
    "                        index=tag_sentence * batch[\"sentence\", \"token\"].shape[1] + tag_positions, \n",
    "                        source=tag_embeddings.weight[tag_values-1]).view(len(current_sentences_idx), batch[\"sentence\", \"token\"].shape[1], tag_dim)[non_empty_sentences]\n",
    "\n",
    "                    # Compute the tokens label tag embeddings of the observed (maybe overlapping) mentions\n",
    "                    tokens = tokens[non_empty_sentences]\n",
    "                    mask = mask[non_empty_sentences]\n",
    "                    current_sentences_idx = current_sentences_idx[non_empty_sentences]\n",
    "    return Batcher.concat(pred_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Define the training metrics\n",
    "metrics_info = defaultdict(lambda: False)\n",
    "flt_format = (5, \"{:.4f}\".format)\n",
    "metrics_info.update({\n",
    "    \"train_loss\": {\"goal\": 0, \"format\": flt_format},\n",
    "    \"train_ner_loss\": {\"goal\": 0, \"format\": flt_format},\n",
    "    \"train_rl_loss\": {\"goal\": 0, \"format\": flt_format},\n",
    "    #\"train_recall\": {\"goal\": 1, \"format\": flt_format, \"name\": \"train_rec\"},\n",
    "    #\"train_precision\": {\"goal\": 1, \"format\": flt_format, \"name\": \"train_prec\"},\n",
    "    \"train_f1\": {\"goal\": 1, \"format\": flt_format, \"name\": \"train_f1\"},\n",
    "    \n",
    "    \"val_loss\": {\"goal\": 0, \"format\": flt_format},\n",
    "    \"val_ner_loss\": {\"goal\": 0, \"format\": flt_format},\n",
    "    \"val_label_loss\": {\"goal\": 0, \"format\": flt_format},\n",
    "    \n",
    "    \"val_f1\": {\"goal\": 1, \"format\": flt_format, \"name\": \"val_f1\"},\n",
    "    \"val_3.1_f1\": {\"goal\": 1, \"format\": flt_format, \"name\": \"val_3.1_f1\"},\n",
    "    \"val_3.2_f1\": {\"goal\": 1, \"format\": flt_format, \"name\": \"val_3.2_f1\"},\n",
    "    \"val_macro_f1\": {\"goal\": 1, \"format\": flt_format, \"name\": \"val_macro_f1\"},\n",
    "    \"val_sosy_f1\": {\"goal\": 1, \"format\": flt_format, \"name\": \"val_sosy_f1\"},\n",
    "    \"val_pathologie_f1\": {\"goal\": 1, \"format\": flt_format, \"name\": \"val_patho_f1\"},\n",
    "    \n",
    "    \"duration\": {\"format\": flt_format, \"name\": \"   dur(s)\"},\n",
    "    \"rescale\": {\"format\": flt_format},\n",
    "    \"n_depth\": {\"format\": flt_format},\n",
    "    \"n_matched\": {\"format\": flt_format},\n",
    "    \"n_targets\": {\"format\": flt_format},\n",
    "    \"n_observed\": {\"format\": flt_format},\n",
    "    \"total_score_sum\": {\"format\": flt_format},\n",
    "    \"lr\": {\"format\": (5, \"{:.2e}\".format)},\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batcher(docs, sentences, zones, mentions, conflicts, tokens):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    ----------\n",
    "    docs: pd.DataFrame\n",
    "    sentences: pd.DataFrame\n",
    "    zones: pd.DataFrame\n",
    "    mentions: pd.DataFrame\n",
    "    conflicts: pd.DataFrame\n",
    "    tokens: pd.DataFrame\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Batcher\n",
    "    \"\"\"\n",
    "    docs = docs.copy()\n",
    "    sentences = sentences.copy()\n",
    "    zones = zones.copy()\n",
    "    mentions = mentions.copy()\n",
    "    conflicts = conflicts.copy()\n",
    "    tokens = tokens.copy()\n",
    "    \n",
    "    [tokens[\"token_id\"]], unique_token_id = factorize_rows([tokens[\"token_id\"]])\n",
    "    [mentions[\"mention_id\"], conflicts[\"mention_id\"], conflicts[\"mention_id_other\"]], unique_mention_ids = factorize_rows(\n",
    "        [mentions[[\"doc_id\", \"sentence_id\", \"mention_id\"]], conflicts[[\"doc_id\", \"sentence_id\", \"mention_id\"]], conflicts[[\"doc_id\", \"sentence_id\", \"mention_id_other\"]]])\n",
    "    [zones[\"zone_id\"], mentions[\"zone_id\"]], unique_zone_ids = factorize_rows(\n",
    "        [zones[[\"doc_id\", \"sentence_id\", \"zone_id\"]], mentions[[\"doc_id\", \"sentence_id\", \"zone_id\"]]])\n",
    "    [sentences[\"sentence_id\"], zones[\"sentence_id\"], mentions[\"sentence_id\"], tokens[\"sentence_id\"],], unique_sentence_ids = factorize_rows(\n",
    "        [sentences[[\"doc_id\", \"sentence_id\"]], zones[[\"doc_id\", \"sentence_id\"]], mentions[[\"doc_id\", \"sentence_id\"]], tokens[[\"doc_id\", \"sentence_id\"]]])\n",
    "    [docs[\"doc_id\"], sentences[\"doc_id\"], zones[\"doc_id\"], mentions[\"doc_id\"], tokens[\"doc_id\"]], unique_doc_ids = factorize_rows(\n",
    "        [docs[\"doc_id\"], sentences[\"doc_id\"], zones[\"doc_id\"], mentions[\"doc_id\"], tokens[\"doc_id\"]])\n",
    "    \n",
    "    batcher = Batcher({\n",
    "        \"mention\": {\n",
    "            \"mention_id\": mentions[\"mention_id\"],\n",
    "            \"zone_id\": mentions[\"zone_id\"],\n",
    "            \"sentence_id\": mentions[\"sentence_id\"],\n",
    "            \"doc_id\": mentions[\"doc_id\"],\n",
    "            \"begin\": mentions[\"begin\"],\n",
    "            \"end\": mentions[\"end\"],\n",
    "            \"ner_label\": mentions[\"ner_label\"].cat.codes,\n",
    "            \"conflict_mention_id\": df_to_csr(conflicts[\"mention_id\"], conflicts[\"conflict_idx\"], conflicts[\"mention_id_other\"], n_rows=len(unique_mention_ids)),\n",
    "            \"conflict_mask\": df_to_csr(conflicts[\"mention_id\"], conflicts[\"conflict_idx\"], n_rows=len(unique_mention_ids)),\n",
    "        },\n",
    "        \"zone\": {\n",
    "            \"zone_id\": zones[\"zone_id\"],\n",
    "            \"sentence_id\": zones[\"sentence_id\"],\n",
    "            \"doc_id\": zones[\"doc_id\"],\n",
    "            \"mention_id\": df_to_csr(mentions[\"zone_id\"], mentions[\"zone_mention_idx\"], mentions[\"mention_id\"], n_rows=len(unique_zone_ids)),\n",
    "            \"mention_mask\": df_to_csr(mentions[\"zone_id\"], mentions[\"zone_mention_idx\"], n_rows=len(unique_zone_ids)),\n",
    "        },\n",
    "        \"sentence\": {\n",
    "            \"sentence_id\": sentences[\"sentence_id\"],\n",
    "            \"doc_id\": sentences[\"doc_id\"],\n",
    "            \"mention_id\": df_to_csr(mentions[\"sentence_id\"], mentions[\"mention_idx\"], mentions[\"mention_id\"], n_rows=len(unique_sentence_ids)),\n",
    "            \"mention_mask\": df_to_csr(mentions[\"sentence_id\"], mentions[\"mention_idx\"], n_rows=len(unique_sentence_ids)),\n",
    "            \"token\": df_to_csr(tokens[\"sentence_id\"], tokens[\"token_idx\"], tokens[\"token\"].cat.codes, n_rows=len(unique_sentence_ids)),\n",
    "            \"token_mask\": df_to_csr(tokens[\"sentence_id\"], tokens[\"token_idx\"], n_rows=len(unique_sentence_ids)),\n",
    "            \"zone_id\": df_to_csr(zones[\"sentence_id\"], zones[\"zone_idx\"], zones[\"zone_id\"], n_rows=len(unique_sentence_ids)),\n",
    "            \"zone_mask\": df_to_csr(zones[\"sentence_id\"], zones[\"zone_idx\"], n_rows=len(unique_sentence_ids)),\n",
    "        },\n",
    "        \"doc\": {\n",
    "            \"doc_id\": np.arange(len(unique_doc_ids)),\n",
    "            \"sentence_id\": df_to_csr(sentences[\"doc_id\"], sentences[\"sentence_idx\"], sentences[\"sentence_id\"], n_rows=len(unique_doc_ids)),\n",
    "            \"sentence_mask\": df_to_csr(sentences[\"doc_id\"], sentences[\"sentence_idx\"], n_rows=len(unique_doc_ids)),\n",
    "            \"split\": docs[\"split\"].cat.codes,\n",
    "        }},\n",
    "        masks={\"sentence\": {\"token\": \"token_mask\", \"zone_id\": \"zone_mask\", \"mention_id\": \"mention_mask\"}, \n",
    "               \"mention\": {\"conflict_mention_id\": \"conflict_mask\"},\n",
    "               \"zone\": {\"mention_id\": \"mention_mask\"}, \n",
    "               \"doc\": {\"sentence_id\": \"sentence_mask\"}}\n",
    "    )\n",
    "    return (\n",
    "        batcher, \n",
    "        dict(docs=docs, sentences=sentences, zones=zones, mentions=mentions, tokens=tokens),\n",
    "        dict(token_id=unique_token_id, mention_id=unique_mention_ids, zone_id=unique_zone_ids, sentence_id=unique_sentence_ids, doc_id=unique_doc_ids)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERNet(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_labels,\n",
    "                 hidden_dim,\n",
    "                 dropout,\n",
    "                 n_tokens=None,\n",
    "                 token_dim=None,\n",
    "                 embeddings=None,\n",
    "                 tag_scheme=\"bio\",\n",
    "                 metric='linear',\n",
    "                 metric_fc_kwargs=None,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        if embeddings is not None:\n",
    "            self.embeddings = embeddings\n",
    "            if n_tokens is None or token_dim is None:\n",
    "                if hasattr(embeddings, 'weight'):\n",
    "                    n_tokens, token_dim = embeddings.weight.shape\n",
    "                else:\n",
    "                    n_tokens, token_dim = embeddings.embeddings.weight.shape\n",
    "        else:\n",
    "            self.embeddings = torch.nn.Embedding(n_tokens, token_dim) if n_tokens > 0 else None\n",
    "        assert token_dim is not None, \"Provide token_dim or embeddings\"\n",
    "        assert self.embeddings is not None\n",
    "\n",
    "        dim = (token_dim if n_tokens > 0 else 0)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        if tag_scheme == \"bio\":\n",
    "            self.crf = BIODecoder(n_labels)\n",
    "        elif tag_scheme == \"bioul\":\n",
    "            self.crf = BIOULDecoder(n_labels)\n",
    "        else:\n",
    "            raise Exception()\n",
    "        if hidden_dim is None:\n",
    "            hidden_dim = dim\n",
    "        self.linear = torch.nn.Linear(dim, hidden_dim)\n",
    "        self.batch_norm = torch.nn.BatchNorm1d(dim)\n",
    "\n",
    "        n_tags = self.crf.num_tags\n",
    "        metric_fc_kwargs = metric_fc_kwargs if metric_fc_kwargs is not None else {}\n",
    "        if metric == \"linear\":\n",
    "            self.metric_fc = torch.nn.Linear(dim, n_tags)\n",
    "        elif metric == \"cosine\":\n",
    "            self.metric_fc = CosineSimilarity(dim, n_tags, rescale=rescale, **metric_fc_kwargs)\n",
    "        elif metric == \"ema_cosine\":\n",
    "            self.metric_fc = EMACosineSimilarity(dim, n_tags, rescale=rescale, **metric_fc_kwargs)\n",
    "        else:\n",
    "            raise Exception()\n",
    "    \n",
    "    def extended_embeddings(self, tokens, mask, **kwargs):\n",
    "        # Default case here, size <= 512\n",
    "        # Small ugly check to see if self.embeddings is Bert-like, then we need to pass a mask\n",
    "        if hasattr(self.embeddings, 'encoder') or hasattr(self.embeddings, 'transformer'):\n",
    "            return self.embeddings(tokens, mask, **kwargs)\n",
    "        else:\n",
    "            return self.embeddings(tokens)\n",
    "\n",
    "    def forward(self, tokens, mask, tag_embeds=None, return_embeddings=False):\n",
    "        # Embed the tokens\n",
    "        scores = None\n",
    "        # shape: n_batch * sequence * 768\n",
    "        embeds = self.extended_embeddings(tokens, mask, custom_embeds=tag_embeds)\n",
    "        if len(embeds) > 1:\n",
    "            embeds, _, attentions = embeds\n",
    "        else:\n",
    "            embeds = embeds[0]\n",
    "        state = embeds.masked_fill(~mask.unsqueeze(-1), 0)\n",
    "        state = torch.relu(self.linear(self.dropout(state)))# + state\n",
    "        state = self.batch_norm(state.view(-1, state.shape[-1])).view(state.shape)\n",
    "        scores = self.metric_fc(state)\n",
    "        return {\n",
    "            \"scores\": scores,\n",
    "            \"embeddings\": embeds if return_embeddings else None,\n",
    "            **({\"attentions\": attentions} if \"attentions\" in locals() else {})}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cached\n",
    "def preprocess(\n",
    "    dataset,\n",
    "    max_sentence_length,\n",
    "    bert_name,\n",
    "    ner_labels=None,\n",
    "    unknown_labels=\"drop\",\n",
    "    vocabularies=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "        dataset: Dataset\n",
    "        max_sentence_length: int\n",
    "            Max number of \"words\" as defined by the regex in regex_sentencize (so this is not the nb of wordpieces)\n",
    "        bert_name: str\n",
    "            bert path/name\n",
    "        ner_labels: list of str \n",
    "            allowed ner labels (to be dropped or filtered)\n",
    "        unknown_labels: str\n",
    "            \"drop\" or \"raise\"\n",
    "        vocabularies: dict[str; np.ndarray or list]\n",
    "    Returns\n",
    "    -------\n",
    "    (pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame, dict[str; np.ndarray or list])\n",
    "        docs:      ('split', 'text', 'doc_id')\n",
    "        sentences: ('split', 'doc_id', 'sentence_idx', 'begin', 'end', 'text', 'sentence_id')\n",
    "        zones:     ('doc_id', 'sentence_id', 'zone_id', 'zone_idx')\n",
    "        mentions:  ('ner_label', 'doc_id', 'sentence_id', 'mention_id', 'depth', 'zone_id', 'text', 'mention_idx', 'begin', 'end', 'zone_mention_idx')\n",
    "        conflicts: ('doc_id', 'sentence_id', 'mention_id', 'mention_id_other', 'conflict_idx')\n",
    "        tokens:    ('split', 'token', 'sentence_id', 'token_id', 'token_idx', 'begin', 'end', 'doc_id', 'sentence_idx')\n",
    "        deltas:    ('doc_id', 'begin', 'end', 'delta')\n",
    "        vocs: vocabularies to be reused later for encoding more data or decoding predictions\n",
    "    \"\"\"\n",
    "    print(\"Dataset:\", dataset)\n",
    "    mentions = dataset[\"mentions\"].rename({\"label\": \"ner_label\"}, axis=1)\n",
    "    if ner_labels is not None:\n",
    "        len_before = len(mentions)\n",
    "        unknown_ner_labels = list(mentions[~mentions[\"ner_label\"].isin(ner_labels)][\"ner_label\"].drop_duplicates())\n",
    "        mentions = mentions[mentions[\"ner_label\"].isin(ner_labels)]\n",
    "        if len(unknown_ner_labels) and unknown_labels == \"raise\":\n",
    "            raise Exception(f\"Unkown labels in {len_before-len(mentions)} mentions: \", unknown_ner_labels)\n",
    "    # Check that there is no mention overlap\n",
    "    mentions = mentions.merge(dataset[\"fragments\"].groupby([\"doc_id\", \"mention_id\"], as_index=False, observed=True).agg({\"begin\": \"min\", \"end\": \"max\"}))\n",
    "    print(\"Transform texts...\", end=\" \")\n",
    "    transformed_docs, deltas = apply_substitutions(\n",
    "        dataset[\"docs\"], *zip(\n",
    "            #(r\"(?<=[{}\\\\])(?![ ])\".format(string.punctuation), r\" \"),\n",
    "            #(r\"(?<![ ])(?=[{}\\\\])\".format(string.punctuation), r\" \"),\n",
    "            (\"(?<=[a-zA-Z])(?=[0-9])\", r\" \"),\n",
    "            (\"(?<=[0-9])(?=[A-Za-z])\", r\" \"),\n",
    "        ), apply_unidecode=True)\n",
    "    transformed_docs = transformed_docs.astype({\"text\": str})\n",
    "    transformed_mentions = apply_deltas(mentions, deltas, on=['doc_id'])\n",
    "    print(\"done\")\n",
    "    print(\"Splitting into sentences...\", end=\" \")\n",
    "    sentences = regex_sentencize(\n",
    "        transformed_docs, \n",
    "        reg_split=r\"(?<=[.])(\\s*\\n+)|(?=, [0-9]\\))\",\n",
    "        min_sentence_length=None, max_sentence_length=max_sentence_length,\n",
    "        balance_parentheses=False,\n",
    "        # balance_parentheses=True, # default is True\n",
    "    )\n",
    "    [sentence_mentions], sentences, sentence_to_docs = partition_spans([transformed_mentions], sentences, new_id_name=\"sentence_id\", overlap_policy=False)\n",
    "    n_sentences_per_mention = sentence_mentions.assign(count=1).groupby([\"doc_id\", \"mention_id\"], as_index=False).agg({\"count\": \"sum\", \"text\": tuple, \"sentence_id\": tuple})\n",
    "    if n_sentences_per_mention[\"count\"].max() > 1:\n",
    "        display(n_sentences_per_mention.query(\"count > 1\"))\n",
    "        display(sentences[sentences[\"sentence_id\"].isin(n_sentences_per_mention.query(\"count > 1\")[\"sentence_id\"].explode())][\"text\"].tolist())\n",
    "        raise Exception(\"Some mentions could be mapped to more than 1 sentences ({})\".format(n_sentences_per_mention[\"count\"].max()))\n",
    "    if sentence_to_docs is not None:\n",
    "        sentence_mentions = sentence_mentions.merge(sentence_to_docs)\n",
    "    sentence_mentions = sentence_mentions.assign(mention_idx=0).nlstruct.groupby_assign([\"doc_id\", \"sentence_id\"], {\"mention_idx\": lambda x: tuple(range(len(x)))})\n",
    "    print(\"done\")\n",
    "    print(\"Tokenizing...\", end=\" \")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(bert_name)\n",
    "    sentences[\"text\"] = sentences[\"text\"].str.lower()\n",
    "    tokens = huggingface_tokenize(sentences, tokenizer, doc_id_col=\"sentence_id\")\n",
    "    sentence_mentions = split_into_spans(sentence_mentions, tokens, pos_col=\"token_idx\", overlap_policy=False)\n",
    "    print(\"done\")\n",
    "    print(\"Processing zones (overlapping areas)...\", end=\" \")\n",
    "    # Extract overlapping spans\n",
    "    conflicts = (\n",
    "        merge_with_spans(sentence_mentions, sentence_mentions, on=[\"doc_id\", \"sentence_id\", (\"begin\", \"end\")], how=\"outer\", suffixes=(\"\", \"_other\"))\n",
    "    )\n",
    "    # ids1, and ids2 make the edges of the overlapping mentions of the same type (see the \"ner_label\")\n",
    "    [ids1, ids2], unique_ids = factorize_rows(\n",
    "        [conflicts[[\"doc_id\", \"sentence_id\", \"mention_id\"]], \n",
    "         conflicts[[\"doc_id\", \"sentence_id\", \"mention_id_other\"]]],\n",
    "        sentence_mentions.eval(\"size=(end-begin)\").sort_values(\"size\")[[\"doc_id\", \"sentence_id\", \"mention_id\"]]\n",
    "    )\n",
    "    g = nx.from_scipy_sparse_matrix(df_to_csr(ids1, ids2, n_rows=len(unique_ids), n_cols=len(unique_ids)))\n",
    "    colored_nodes = np.asarray(list(nx.coloring.greedy_color(g, strategy=keep_order).items()))\n",
    "    unique_ids['depth'] = colored_nodes[:, 1][colored_nodes[:, 0].argsort()]\n",
    "    zone_indices, mention_indices = zip(*chain.from_iterable(zip(repeat(zone_idx), zone) for zone_idx, zone in enumerate(nx.connected_components(g))))\n",
    "    conflicts = conflicts[[\"doc_id\", \"sentence_id\", \"mention_id\", \"mention_id_other\"]].assign(conflict_idx=0).nlstruct.groupby_assign([\"doc_id\", \"sentence_id\", \"mention_id\"], {\"conflict_idx\": lambda x: tuple(range(len(x)))})\n",
    "    zone_mentions = pd.DataFrame({\n",
    "        **unique_ids.iloc[list(mention_indices)],\n",
    "        \"zone_id\": zone_indices,\n",
    "    }).merge(sentence_mentions, on=[\"doc_id\", \"sentence_id\", \"mention_id\"]).sort_values([\"doc_id\", \"sentence_id\", \"zone_id\", \"mention_id\"])\n",
    "    zone_mentions = zone_mentions.assign(zone_mention_idx=0).nlstruct.groupby_assign(['doc_id', 'sentence_id', 'zone_id'], {\"zone_mention_idx\": lambda vec: tuple(np.arange(len(vec)))})\n",
    "    sentence_zones = zone_mentions[[\"doc_id\", \"sentence_id\", \"zone_id\"]].drop_duplicates()\n",
    "    sentence_zones = sentence_zones.assign(zone_idx=0).nlstruct.groupby_assign(['doc_id', 'sentence_id'], {\"zone_idx\": lambda vec: tuple(np.arange(len(vec)))})\n",
    "    sentence_mentions = sentence_mentions.merge(zone_mentions.drop_duplicates([\"doc_id\", \"sentence_id\", \"mention_id\", \"depth\"]))\n",
    "    print(\"done\")\n",
    "    print(\"Computing vocabularies...\")\n",
    "    [transformed_docs, sentences, sentence_zones, zone_mentions, tokens], vocs = normalize_vocabularies(\n",
    "        [transformed_docs, sentences, sentence_zones, zone_mentions, tokens], \n",
    "        vocabularies={\"split\": [\"train\", \"val\", \"test\"]} if vocabularies is None else vocabularies,\n",
    "        train_vocabularies={\"source\": False, \"text\": False} if vocabularies is None else False,\n",
    "        verbose=True)\n",
    "    print(\"done\")\n",
    "    return transformed_docs, sentences, sentence_zones, zone_mentions, conflicts, tokens, deltas, vocs\n",
    "def keep_order(G, colors):\n",
    "    \"\"\"Returns a list of the nodes of ``G`` in ordered identically to their id in the graph\n",
    "    ``G`` is a NetworkX graph. ``colors`` is ignored.\n",
    "    This is to assign a depth using the nx.coloring.greedy_color function\n",
    "    \"\"\"\n",
    "    return sorted(list(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Dataset(\n",
      "  (docs):        2000 * ('doc_id', 'text', 'split')\n",
      "  (mentions):   57096 * ('doc_id', 'mention_id', 'label', 'text')\n",
      "  (fragments):  57096 * ('doc_id', 'mention_id', 'fragment_id', 'begin', 'end')\n",
      "  (attributes):     0 * ('doc_id', 'mention_id', 'attribute_id', 'label', 'value')\n",
      ")\n",
      "Transform texts... done\n",
      "Splitting into sentences... done\n",
      "Tokenizing... "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc70f9b97c994d7a9a32852be02fcf0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=433.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "057532ae6de84422ad60290264d22b6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=213450.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c20bb4196af41bf966432beea7cff10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=112.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e29fb3d01b334f128d6659ad144f123c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=51.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ytaille/.conda/envs/yt_nlp/lib/python3.7/site-packages/nlstruct/text/chunking/huggingface.py:11: FutureWarning: doc_id_col is not used anymore in the huggingface_tokenize function\n",
      "  warnings.warn(\"doc_id_col is not used anymore in the huggingface_tokenize function\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "Processing zones (overlapping areas)... done\n",
      "Computing vocabularies...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# bert_name = \"bert-base-cased\"\n",
    "# bert_name = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
    "# bert_name = \"gsarti/biobert-nli\" \n",
    "bert_name = \"monologg/biobert_v1.1_pubmed\"\n",
    "dataset = load_genia_ner()\n",
    "docs = dataset['docs']\n",
    "\n",
    "keep_n_first = None\n",
    "\n",
    "if keep_n_first:\n",
    "    docs = docs[:keep_n_first]\n",
    "    first_ids = docs['doc_id']\n",
    "    \n",
    "    first_mentions = dataset[\"mentions\"].loc[dataset[\"mentions\"]['doc_id'].isin(first_ids)]\n",
    "    first_fragments = dataset[\"fragments\"].loc[dataset[\"fragments\"]['doc_id'].isin(first_ids)]\n",
    "    first_attributes = dataset[\"attributes\"].loc[dataset[\"attributes\"]['doc_id'].isin(first_ids)]\n",
    "    \n",
    "    dataset[\"mentions\"] = first_mentions\n",
    "    dataset[\"fragments\"] = first_fragments\n",
    "    dataset[\"attributes\"] = first_attributes\n",
    "\n",
    "docs[\"split\"] = [\"train\"] * (len(docs) - int(len(docs) * 0.1)) + [\"test\"] * int(len(docs) * 0.1)\n",
    "dataset['docs'] = docs\n",
    "docs, sentences, zones, mentions, conflicts, tokens, deltas, vocs = preprocess(\n",
    "    dataset=dataset,\n",
    "    max_sentence_length=140,\n",
    "    bert_name=bert_name,\n",
    "    ner_labels= ['DNA', 'protein', 'cell_type', 'cell_line', 'RNA'],\n",
    "    unknown_labels=\"drop\",\n",
    ")\n",
    "batcher, encoded, ids = make_batcher(docs, sentences, zones, mentions, conflicts, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity (L2 dist) between train and val frequencies: 0.004900437003164877\n",
      "Frequencies\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>DNA</th>\n",
       "      <th>RNA</th>\n",
       "      <th>cell_line</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>protein</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>0.176332</td>\n",
       "      <td>0.016980</td>\n",
       "      <td>0.068440</td>\n",
       "      <td>0.128091</td>\n",
       "      <td>0.610157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>val</td>\n",
       "      <td>0.222606</td>\n",
       "      <td>0.021301</td>\n",
       "      <td>0.081558</td>\n",
       "      <td>0.112646</td>\n",
       "      <td>0.561888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index       DNA       RNA  cell_line  cell_type   protein\n",
       "0  train  0.176332  0.016980   0.068440   0.128091  0.610157\n",
       "1    val  0.222606  0.021301   0.081558   0.112646  0.561888"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#all_test_doc_ids = []\n",
    "#sims = {}\n",
    "#for i in range(200):\n",
    "seed_all(1234567+137)\n",
    "\n",
    "TRAIN_MODE = \"test\"\n",
    "\n",
    "train_batcher = batcher['doc'][batcher['doc']['split']==0]['sentence']\n",
    "test_batcher = batcher['doc'][batcher['doc']['split']==2]['sentence']\n",
    "\n",
    "if TRAIN_MODE != 'test':\n",
    "    splits = np.zeros(len(train_batcher['doc']), dtype=int)\n",
    "\n",
    "    val_perc = 0.1\n",
    "    splits[np.random.choice(np.arange(len(splits)), size=int(val_perc * len(splits)))] = 1\n",
    "\n",
    "    train_batcher = batcher['sentence'][splits == 0]\n",
    "    val_batcher = batcher['sentence'][splits == 1]\n",
    "else:\n",
    "    val_batcher = test_batcher\n",
    "\n",
    "# train_val_split = np.random.permutation(len(train_batcher))\n",
    "# test_batcher = train_batcher[train_val_split[:int(0.1*len(train_val_split))]]['sentence']\n",
    "# train_batcher = train_batcher[train_val_split[int(0.1*len(train_val_split)):]]['sentence']\n",
    "sim = ((np.bincount(val_batcher['mention', 'ner_label'], minlength=len(vocs[\"ner_label\"]))/len(val_batcher['mention']) -\n",
    "np.bincount(train_batcher['mention', 'ner_label'], minlength=len(vocs[\"ner_label\"]))/len(train_batcher['mention']))**2).sum()\n",
    "print(\"Similarity (L2 dist) between train and val frequencies:\", sim)\n",
    "print(\"Frequencies\")\n",
    "#all_test_doc_ids.append((test_doc_ids, sim))\n",
    "display(pd.DataFrame([\n",
    "    {\"index\": \"train\", **dict(zip(vocs[\"ner_label\"], np.bincount(train_batcher['mention', 'ner_label'], minlength=len(vocs[\"ner_label\"]))/len(train_batcher['mention'])))},\n",
    "    {\"index\": \"val\", **dict(zip(vocs[\"ner_label\"], np.bincount(val_batcher['mention', 'ner_label'], minlength=len(vocs[\"ner_label\"]))/len(val_batcher['mention'])))},\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install /home/yoann/these/DEFT/nlstruct/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Categorical\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def torch_f1(actions, target_tags):\n",
    "    return torch.from_numpy(np.array((-f1_score(actions.view(-1).cpu(), target_tags.view(-1).cpu(), average=\"micro\"))))\n",
    "\n",
    "def sample(probs):\n",
    "    m = Categorical(probs)\n",
    "    sampled_actions = m.sample()\n",
    "    sampled_log_probs = m.log_prob(sampled_actions)\n",
    "    return sampled_actions, sampled_log_probs\n",
    "\n",
    "def baseline(probs):\n",
    "    _, baseline_actions = torch.max(probs, dim=-1)\n",
    "    return baseline_actions\n",
    "\n",
    "def RL_loss(probs, target_tags):\n",
    "    sampled_actions, sampled_log_probs = sample(probs)\n",
    "    baseline_actions = baseline(probs)\n",
    "    \n",
    "    loss = - (torch_f1(sampled_actions, target_tags) - torch_f1(baseline_actions, target_tags)) * sampled_log_probs\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'custom_bert'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-50996743ba32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcustom_bert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCustomBertModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdamW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBertModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'custom_bert'"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "from tqdm import tqdm\n",
    "\n",
    "from custom_bert import CustomBertModel\n",
    "from transformers import AdamW, BertModel\n",
    "\n",
    "from tqdm import tqdm\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from nlstruct.environment import get_cache\n",
    "from nlstruct.utils import evaluating, torch_global as tg, freeze\n",
    "from nlstruct.scoring import compute_metrics, merge_pred_and_gold\n",
    "from nlstruct.train import make_optimizer_and_schedules, iter_optimization, seed_all\n",
    "from nlstruct.train.schedule import ScaleOnPlateauSchedule, LinearSchedule, ConstantSchedule\n",
    "    \n",
    "device = torch.device('cpu')\n",
    "tg.set_device(device)\n",
    "all_preds = []\n",
    "histories = []\n",
    "\n",
    "# To release gpu memory before allocating new parameters for a new model\n",
    "# A better idea would be to run xp in a function, so that all variables are released when exiting the fn\n",
    "# but this way we can debug after this cell if something goes wrong\n",
    "if \"all_nets\" in globals(): del all_nets\n",
    "if \"optim\" in globals(): del optim, \n",
    "if \"schedules\" in globals(): del schedules\n",
    "if \"final_schedule\" in globals(): del final_schedule\n",
    "if \"state\" in globals(): del state\n",
    "    \n",
    "# Hyperparameter search\n",
    "layer, hidden_dim, scheme, seed, lr, bert_lr, n_schedules, dropout = 2, 1024 if \"large\" in bert_name else 768, \"bioul\", 12,  9e-3, 4e-5, 4, 0.1\n",
    "#seed = 123456\n",
    "seed_all(seed) # /!\\ Super important to enable reproducibility\n",
    "\n",
    "tag_dim = 1024 if \"large\" in bert_name else 768#768\n",
    "max_grad_norm = 5.\n",
    "#lr = 1e-3\n",
    "#bert_lr = 6e-5\n",
    "tags_lr = bert_lr\n",
    "bert_weight_decay = 0.0000\n",
    "batch_size = 128\n",
    "random_perm=True\n",
    "observed_zone_sizes=None\n",
    "n_per_zone = \"uniform\"\n",
    "n_freeze = layer \n",
    "custom_embeds_layer_index = 19 if \"large\" in bert_name else 11 # 19 or 5?\n",
    "#hidden_dim = 256\n",
    "bert_dropout = 0.1\n",
    "top_dropout = dropout\n",
    "\n",
    "ner_net = NERNet(\n",
    "        n_tokens=len(vocs[\"token\"]),\n",
    "        token_dim=1024 if \"large\" in bert_name else 768,#768,\n",
    "        n_labels=len(vocs[\"ner_label\"]),\n",
    "        embeddings=CustomBertModel.from_pretrained(bert_name, custom_embeds_layer_index=custom_embeds_layer_index, output_attentions=True),\n",
    "        dropout=top_dropout,\n",
    "        hidden_dim=hidden_dim,\n",
    "        tag_scheme=scheme,\n",
    "        metric='linear') # cosine might be better but looks less stable, oddly,\n",
    "\n",
    "multihead_attn = torch.nn.MultiheadAttention(\n",
    "    embed_dim=len(vocs[\"ner_label\"])*4+1, \n",
    "    num_heads=1, \n",
    "    dropout=0.0, \n",
    "    bias=True, \n",
    "    add_bias_kv=False, \n",
    "    add_zero_attn=False, \n",
    "    kdim=None, \n",
    "    vdim=None,\n",
    ")\n",
    "\n",
    "rl_decoder = torch.nn.LSTM(len(vocs[\"ner_label\"])*4+1, len(vocs[\"ner_label\"])*4+1)\n",
    "\n",
    "softmax = torch.nn.Softmax(-1)\n",
    "\n",
    "all_nets = torch.nn.ModuleDict({\n",
    "    \"ner_net\": ner_net,\n",
    "    \"tag_embeddings\": torch.nn.Embedding(ner_net.crf.num_tags - 1, tag_dim),\n",
    "    \"rl_attention\": multihead_attn,\n",
    "    \"rl_decoder\": rl_decoder,\n",
    "}).to(device=tg.device)\n",
    "del ner_net\n",
    "del multihead_attn\n",
    "del rl_decoder\n",
    "\n",
    "for module in all_nets[\"ner_net\"].embeddings.modules():\n",
    "    if isinstance(module, torch.nn.Dropout):\n",
    "        module.p = bert_dropout\n",
    "all_nets.train()\n",
    "\n",
    "# Define the optimizer, maybe multiple learning rate / schedules per parameters groups\n",
    "optim, schedules = make_optimizer_and_schedules(all_nets, AdamW, {\n",
    "    \"lr\": [\n",
    "                           (lr,    bert_lr,    bert_lr,    tags_lr),\n",
    "        (ConstantSchedule, (lr,    bert_lr,    bert_lr,    tags_lr),    15),\n",
    "        (ConstantSchedule, (lr/4,  bert_lr/4,  bert_lr/4,  tags_lr/4),  15),\n",
    "        (ConstantSchedule, (lr/16, bert_lr/16, bert_lr/16, tags_lr/16), 10),\n",
    "        (ConstantSchedule, (lr/64, bert_lr/64, bert_lr/64, tags_lr/64), 10),\n",
    "    ][:n_schedules+1],\n",
    "}, [\n",
    "    \"(?!ner_net\\.embeddings\\.|tag_embeddings\\.).*\", \n",
    "    \"ner_net\\.embeddings\\..*(bias|LayerNorm\\.weight)\",\n",
    "    \"ner_net\\.embeddings\\..*(?!bias|LayerNorm\\.weight)\",\n",
    "    \"tag_embeddings\\..*\"\n",
    "], num_iter_per_epoch=(len(train_batcher) + 1) / batch_size)\n",
    "final_schedule = ScaleOnPlateauSchedule('lr', optim, patience=4, factor=0.25, verbose=True, mode='max')\n",
    "\n",
    "# Freeze some bert layers \n",
    "# - n_freeze = 0 to freeze nothing\n",
    "# - n_freeze = 1 to freeze word embeddings / position embeddings / ...\n",
    "# - n_freeze = 2..13 to freeze the first, second ... 12th layer of bert\n",
    "for name, param in all_nets.named_parameters():\n",
    "    match = re.search(\"\\.(\\d+)\\.\", name)\n",
    "    if match and int(match.group(1)) < n_freeze - 1:\n",
    "        freeze([param])\n",
    "if n_freeze > 0:\n",
    "    if hasattr(all_nets['ner_net'].embeddings, 'embeddings'):\n",
    "        freeze(all_nets['ner_net'].embeddings.embeddings)\n",
    "    else:\n",
    "        freeze(all_nets['ner_net'].embeddings)\n",
    "\n",
    "with_tqdm = True\n",
    "state = {\"all_nets\": all_nets, \"optim\": optim, \"schedules\": schedules, \"final_schedule\": final_schedule}  # all we need to restart the training from a given epoch\n",
    "\n",
    "cache = get_cache(\"genia_rl\", {\n",
    "    \"seed\": seed, \n",
    "    \"train_batcher\": train_batcher, \n",
    "    \"val_batcher\": None, \n",
    "    \"random_perm\": random_perm,\n",
    "    \"observed_zone_sizes\": observed_zone_sizes, \n",
    "    \"batch_size\": batch_size, \n",
    "    \"max_grad_norm\": max_grad_norm, \n",
    "    **state\n",
    "}, loader=torch.load, dumper=torch.save)  # where to store the model (main name + hashed parameters)\n",
    "\n",
    "for epoch_before, state, history, record in iter_optimization(\n",
    "    main_score = \"val_f1\", # do not earlystop based on validation\n",
    "    metrics_info=metrics_info,\n",
    "    max_epoch=81,\n",
    "    patience=50,\n",
    "    state=state, \n",
    "    cache_policy=\"all\", # only store metrics, not checkpoints\n",
    "    cache=cache,\n",
    "    n_save_checkpoints=2,\n",
    "#             exit_on_score=0.92,\n",
    "):\n",
    "    \n",
    "    \n",
    "    pred_batches = []\n",
    "    gold_batches = []\n",
    "\n",
    "    total_train_ner_loss = 0\n",
    "    total_train_acc = 0\n",
    "    total_train_ner_size = 0\n",
    "    \n",
    "    total_train_rl_loss = 0\n",
    "    total_train_rl_size = 0\n",
    "\n",
    "    n_mentions = len(train_batcher[\"mention\"])\n",
    "    n_matched_mentions = 0\n",
    "    n_target_mentions = 0\n",
    "    n_observed_mentions = 0\n",
    "\n",
    "    with tqdm(train_batcher['sentence'].dataloader(batch_size=batch_size, shuffle=True, sparse_sort_on=\"token_mask\", device=device), disable=not with_tqdm) as bar:\n",
    "        for batch_i, batch in enumerate(bar):\n",
    "            optim.zero_grad()\n",
    "\n",
    "            # Shuffle and split mentions in each zone between observed and target\n",
    "            target_mentions, observed_mentions, zone_target_mentions, target_mask = split_zone_mentions(\n",
    "                batch,\n",
    "                random_perm=random_perm,\n",
    "                observed_zone_sizes=observed_zone_sizes,\n",
    "            )\n",
    "            n_target_mentions += len(target_mentions)\n",
    "            n_observed_mentions += len(observed_mentions)\n",
    "\n",
    "            # Compute the tokens label tag embeddings of the observed (maybe overlapping) mentions\n",
    "            feature_tags = all_nets[\"ner_net\"].crf.spans_to_tags(\n",
    "                torch.arange(len(observed_mentions), device=observed_mentions.device),\n",
    "                batch[\"mention\", \"begin\"][observed_mentions], \n",
    "                batch[\"mention\", \"end\"][observed_mentions], \n",
    "                batch[\"mention\", \"ner_label\"][observed_mentions], \n",
    "                n_tokens=batch[\"sentence\", \"token\"].shape[1],\n",
    "                n_samples=len(observed_mentions),\n",
    "            )\n",
    "            tag_mention, tag_positions = feature_tags.nonzero(as_tuple=True)\n",
    "            tag_sentence = batch[\"zone\", \"@sentence_id\"][batch[\"mention\", \"@zone_id\"]][observed_mentions][tag_mention]\n",
    "            tag_values = feature_tags[tag_mention, tag_positions]\n",
    "            tag_embeds = torch.zeros(*batch[\"sentence\", \"token\"].shape[:2], tag_dim, device=tg.device).view(-1, tag_dim).index_add_(\n",
    "                dim=0,\n",
    "                index=tag_sentence * batch[\"sentence\", \"token\"].shape[1] + tag_positions, \n",
    "                source=all_nets[\"tag_embeddings\"].weight[tag_values-1]).view(*batch[\"sentence\", \"token\"].shape[:2], tag_dim)\n",
    "\n",
    "            ##################################\n",
    "            #       RUN THE NER MODEL        #\n",
    "            ##################################\n",
    "            # Run the model argmax here, we compute tag scores and embeddings\n",
    "            mask = batch[\"token_mask\"]\n",
    "            \n",
    "            ner_res = all_nets[\"ner_net\"](\n",
    "                tokens = batch[\"token\"],\n",
    "                mask = mask,\n",
    "                tag_embeds = tag_embeds,\n",
    "                return_embeddings=True,\n",
    "            )\n",
    "            \n",
    "            scores = ner_res[\"scores\"]\n",
    "            embeds = ner_res[\"embeddings\"]\n",
    "            \n",
    "            # RL SCORES COMPUTATION\n",
    "            \n",
    "            # QUERY is decoder part\n",
    "            # KEY is encoder part\n",
    "            # VALUE is what we apply attention weights to\n",
    "            \n",
    "            key = scores.permute(1,0,2)#ner_res['attentions'][-1]\n",
    "            \n",
    "            query, _ = all_nets[\"rl_decoder\"](key)\n",
    "            value = key\n",
    "\n",
    "            attn_output, attn_weights = all_nets[\"rl_attention\"](query, key, value, key_padding_mask=None, need_weights=True, attn_mask=None)\n",
    "            \n",
    "            rl_scores = attn_output.permute(1,0,2)\n",
    "\n",
    "            # Run the linear CRF Viterbi algorithm to compute the most likely sequence\n",
    "            spans = all_nets[\"ner_net\"].crf.tags_to_spans(all_nets[\"ner_net\"].crf.decode(rl_scores, mask), mask)\n",
    "\n",
    "            # Save predicted mentions\n",
    "            pred_batch = Batcher({\n",
    "                \"mention\": {\n",
    "                    \"mention_id\": torch.arange(n_mentions, n_mentions+len(spans[\"span_doc_id\"]), device=device),\n",
    "                    \"begin\": spans[\"span_begin\"],\n",
    "                    \"end\": spans[\"span_end\"],\n",
    "                    \"ner_label\": spans[\"span_label\"],\n",
    "                    \"@sentence_id\": spans[\"span_doc_id\"],\n",
    "                },\n",
    "                \"sentence\": dict(batch[\"sentence\", [\"sentence_id\", \"doc_id\"]]),\n",
    "                \"doc\": dict(batch[\"doc\"])}, \n",
    "                check=False)\n",
    "            pred_batches.append(pred_batch)\n",
    "            n_mentions += len(spans[\"span_doc_id\"])\n",
    "\n",
    "            ##################################\n",
    "            #      NER LOSS COMPUTATION      #\n",
    "            ##################################\n",
    "            matched_mentions = select_closest_non_overlapping_gold_mentions(\n",
    "                gold_ids=target_mentions,\n",
    "                gold_sentence_ids=batch[\"zone\", \"@sentence_id\"][batch[\"mention\", \"@zone_id\"]][target_mentions],\n",
    "                gold_begins=batch[\"mention\", \"begin\"][target_mentions],\n",
    "                gold_ends=batch[\"mention\", \"end\"][target_mentions],\n",
    "\n",
    "                pred_sentence_ids=spans[\"span_doc_id\"],\n",
    "                pred_begins=spans[\"span_begin\"],\n",
    "                pred_ends=spans[\"span_end\"],\n",
    "\n",
    "                zone_mention_id=batch[\"zone\", \"@mention_id\"],\n",
    "                zone_mask=batch[\"zone\", \"mention_mask\"],\n",
    "\n",
    "                gold_conflicts=batch[\"mention\", \"@conflict_mention_id\"],\n",
    "                gold_conflicts_mask=batch[\"mention\", \"conflict_mask\"],\n",
    "            )\n",
    "            n_matched_mentions += len(matched_mentions)\n",
    "            gold_batches.append(batch[\"mention\", matched_mentions].sparsify())\n",
    "\n",
    "            # Compute the tokens label tag of the selected non-overlapping gold mentions to infer from the model\n",
    "            target_tags = all_nets[\"ner_net\"].crf.spans_to_tags(\n",
    "                batch[\"zone\", \"@sentence_id\"][batch[\"mention\", \"@zone_id\"][matched_mentions]],\n",
    "                batch[\"mention\", \"begin\"][matched_mentions], \n",
    "                batch[\"mention\", \"end\"][matched_mentions], \n",
    "                batch[\"mention\", \"ner_label\"][matched_mentions], \n",
    "                n_tokens=batch[\"sentence\", \"token\"].shape[1],\n",
    "                n_samples=batch[\"sentence\", \"token\"].shape[0],\n",
    "            )\n",
    "            # Run the linear CRF forward algorithm on the tokens to compute the loglikelihood of the targets\n",
    "            ner_loss = -all_nets[\"ner_net\"].crf(scores, mask, target_tags, reduction=\"mean\")\n",
    "            \n",
    "            total_train_ner_loss += float(ner_loss) * len(batch[\"sentence\"])\n",
    "            total_train_ner_size += len(batch[\"sentence\"])\n",
    "            \n",
    "            # RL LOSS COMPUTATION\n",
    "            \n",
    "            # - Initialize a state\n",
    "            # - Establish a list of possible actions\n",
    "            # - Compute rewards for each action -> Maybe sample which actions to pick to not be exhaustive (for example top k actions ranked by prob) (may not be necessary here)\n",
    "            # - Choose action with best reward ?\n",
    "            # - Reward is F1 BUT loss function is -E(F1(y,y*)) knowing probs\n",
    "            # ---- For a number of samples drawn with Monte Carlo, compute F1 and multiply by probs\n",
    "            # ---- Baseline is greedy search algorithm -> only sort pobs / take max ?\n",
    "            probs = softmax(rl_scores)#.cpu().detach().numpy()\n",
    "#             actions = torch.Tensor([[np.random.choice(np.arange(len(prob)), p=prob) for prob in b] for b in probs]).to(tg.device)\n",
    "#             rl_loss = RL_loss(actions, target_tags)\n",
    "\n",
    "#             save_probs = probs.cpu()\n",
    "#             save_target_tags = target_tags.cpu()\n",
    "            rl_loss = RL_loss(probs, target_tags).mean()\n",
    "            \n",
    "            total_train_rl_loss += float(rl_loss) * len(batch[\"sentence\"])\n",
    "            total_train_rl_size += len(batch[\"sentence\"])\n",
    "            \n",
    "            loss = ner_loss + rl_loss\n",
    "            \n",
    "            # Perform optimization step\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(all_nets.parameters(), max_grad_norm)\n",
    "            optim.step()\n",
    "            for schedule_name, schedule in schedules.items():\n",
    "                schedule.step()\n",
    "\n",
    "    # Compute precision, recall and f1 on train set\n",
    "    ner_pred = Batcher.concat(pred_batches)\n",
    "    ner_gold = Batcher.concat(gold_batches)\n",
    "\n",
    "    train_metrics    = compute_scores(ner_pred, ner_gold, prefix='train_')\n",
    "    val_metrics     = compute_scores(extract_mentions(val_batcher, all_nets=all_nets), val_batcher, prefix='val_',\n",
    "        queries={\n",
    "#                 \"3.1\": \"ner_label in ['sosy', 'pathologie']\",\n",
    "#                 \"3.2\": \"ner_label in ['anatomie', 'dose', 'examen', 'mode', 'moment', 'substance', 'traitement', 'valeur']\",\n",
    "        }\n",
    "                                    )\n",
    "    # final_schedule.step(val_f1, state[\"epoch\"])\n",
    "\n",
    "    record(\n",
    "    {\n",
    "        \"train_ner_loss\": total_train_ner_loss / max(total_train_ner_size, 1),\n",
    "        \"train_rl_loss\": total_train_rl_loss / max(total_train_rl_size, 1),\n",
    "        **train_metrics,\n",
    "        # **val_metrics,\n",
    "        **val_metrics,\n",
    "        \"n_matched\": n_matched_mentions,\n",
    "        \"lr\": schedules['lr'].get_val()[0],\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['scores', 'embeddings', 'attentions'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_res.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([23, 100, 768])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([23, 100, 21])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.3084, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rl_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add attention layer after bert\n",
    "# Key / (context?) is bert attention output (or bert output ?)\n",
    "# Query is LSTM state\n",
    "\n",
    "# ner_res['attentions'][-1].shape\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yt_nlp",
   "language": "python",
   "name": "yt_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
