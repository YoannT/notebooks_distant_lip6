{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(\"nlstruct\")\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlstruct.text import huggingface_tokenize, regex_sentencize, partition_spans, encode_as_tag, split_into_spans, apply_substitutions, apply_deltas\n",
    "from nlstruct.dataloaders import load_from_brat, load_genia_ner\n",
    "from nlstruct.collections import Dataset, Batcher\n",
    "from nlstruct.utils import merge_with_spans, normalize_vocabularies, factorize_rows, df_to_csr, factorize, torch_global as tg\n",
    "from nlstruct.modules.crf import BIODecoder, BIOULDecoder\n",
    "from nlstruct.environment import root, cached\n",
    "from nlstruct.train import seed_all\n",
    "from itertools import chain, repeat\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "def select_closest_non_overlapping_gold_mentions(\n",
    "    gold_ids,\n",
    "    gold_sentence_ids,\n",
    "    gold_begins,\n",
    "    gold_ends,\n",
    "    \n",
    "    pred_sentence_ids,\n",
    "    pred_begins,\n",
    "    pred_ends,\n",
    "    \n",
    "    zone_mention_id,\n",
    "    zone_mask,\n",
    "    gold_conflicts,\n",
    "    gold_conflicts_mask,\n",
    "):\n",
    "    \"\"\"\n",
    "    Select non overlapping gold mentions (in gold_ids) that are the closest to those found by the model\n",
    "    Gold mentions are described by gold_* tensors, predicted mentions are described by pred_* tensors\n",
    "    We select at most one gold mention per zone (zone_mention_id + zone_mask) and each time a gold mention\n",
    "    is selected, its overlaps are removed according to the gold_conflicts + gold_conflicts_mask tensors\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        Selected gold ids, included in \"gold_ids\"\n",
    "    \"\"\"\n",
    "\n",
    "    device = gold_begins.device\n",
    "    \n",
    "    if len(gold_ids) == 0:\n",
    "        return torch.as_tensor([], dtype=torch.long, device=device)\n",
    "\n",
    "    [rel], [remaining_mask], _ = factorize([zone_mention_id], [zone_mask], reference_values=gold_ids)\n",
    "    remaining_mentions = zone_mention_id[remaining_mask.any(1)]\n",
    "    rel = rel[remaining_mask.any(1)]\n",
    "    remaining_mask = remaining_mask[remaining_mask.any(1)]\n",
    "        \n",
    "    keep_mask = torch.zeros(gold_ids.max()+1, device=device, dtype=torch.bool)\n",
    "    zone_scores = torch.full(remaining_mask.shape, fill_value=-1, device=device, dtype=torch.float)\n",
    "    \n",
    "    if len(pred_begins):\n",
    "        PRED, GOLD = 0, 1\n",
    "        SENTENCE_ID, BEGIN, END = 0, 1, 2\n",
    "        p = torch.stack([pred_sentence_ids, pred_begins, pred_ends], dim=0).unsqueeze(GOLD+1)\n",
    "        g = torch.stack([gold_sentence_ids, gold_begins, gold_ends], dim=0).unsqueeze(PRED+1)\n",
    "\n",
    "        overlap = (torch.min(p[END], g[END]) - torch.max(p[BEGIN], g[BEGIN])).float().clamp(0)\n",
    "        overlap = overlap * 2 / (p[END] - p[BEGIN] + g[END] - g[BEGIN])\n",
    "        score = (p[SENTENCE_ID] == g[SENTENCE_ID]) * overlap\n",
    "        \n",
    "        zone_scores = score.max(0).values[rel]\n",
    "        zone_scores[~remaining_mask] = -1\n",
    "    else:\n",
    "        zone_scores[remaining_mask] = 0\n",
    "    while len(remaining_mask):\n",
    "        best_indexer = torch.arange(zone_scores.shape[0], device=device), zone_scores.argmax(1)\n",
    "        best_mentions = remaining_mentions[best_indexer]\n",
    "        conflicts = gold_conflicts[best_mentions][gold_conflicts_mask[best_mentions]]    \n",
    "        keep_mask[best_mentions] = True\n",
    "        remaining_mask[best_indexer] = False\n",
    "        remaining_mask &= ~(remaining_mentions.unsqueeze(-1) == conflicts).any(-1)\n",
    "        zone_scores[~remaining_mask] = -1\n",
    "        zone_scores = zone_scores[remaining_mask.any(1)]\n",
    "        remaining_mentions = remaining_mentions[remaining_mask.any(1)]\n",
    "        remaining_mask = remaining_mask[remaining_mask.any(1)]\n",
    "    return keep_mask.nonzero()[:, 0]\n",
    "\n",
    "def split_zone_mentions(batch, random_perm=True, observed_zone_sizes=None):\n",
    "    \"\"\"\n",
    "    In a batch, splits mentions between \n",
    "    - those that we will consider as being observed\n",
    "    - and those that we will ask the model to recover\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    random_perm: bool\n",
    "        Shuffle the mentions before splitting them\n",
    "    observed_zone_sizes: int\n",
    "        If not None, selects exactly this number of mentions per zone (=overlapping group of mentions)\n",
    "        Otherwise, any random number from 0 to the maximum of mentions can be observed in each group\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    (torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor)\n",
    "        - observed_mentions: flat observed mentions (@mention_id)\n",
    "        - target_mentions: flat target mentions (@mention_id)\n",
    "        - zone_target_mentions: mentions to recover, grouped by zone (n_zones * n_mentions_per_zone)\n",
    "        - target_mask: mask of zone_target_mentions, since every zone can have a different number of picked target mentions\n",
    "    \"\"\"\n",
    "    zone_mention_id = batch[\"zone\", \"@mention_id\"]\n",
    "    zone_mention_mask = batch[\"zone\", \"mention_mask\"]\n",
    "    n_sentences = len(batch[\"sentence\"])\n",
    "    device = zone_mention_id.device\n",
    "    if random_perm:\n",
    "        perm = torch.rand(zone_mention_id.shape, device=device)\n",
    "    else:\n",
    "        perm = torch.zeros(zone_mention_id.shape, device=device, dtype=torch.float)\n",
    "    perm[~zone_mention_mask] = 2\n",
    "    perm = perm.argsort(1)\n",
    "\n",
    "    if observed_zone_sizes is None:\n",
    "        observed_zone_size = ((zone_mention_mask.sum(-1) + 1) * torch.rand(zone_mention_mask.shape[0], dtype=torch.float, device=device)).long()\n",
    "    else:\n",
    "        observed_zone_size = torch.full((zone_mention_mask.shape[0],), fill_value=observed_zone_sizes, device=device, dtype=torch.long)\n",
    "\n",
    "    # Select mentions that will become features\n",
    "    zone_observed_mentions = zone_mention_id[torch.arange(perm.shape[0], device=device).unsqueeze(1), perm]\n",
    "    observed_mask = (torch.arange(zone_mention_mask.shape[1], device=device).unsqueeze(0) < observed_zone_size.unsqueeze(1)) & zone_mention_mask\n",
    "    observed_mentions = zone_observed_mentions[observed_mask]\n",
    "\n",
    "    # Select mentions that will be hidden from the model (ie to recover)\n",
    "    zone_target_mentions = zone_mention_id[torch.arange(perm.shape[0], device=device).unsqueeze(1), perm]\n",
    "    target_mask = (torch.arange(zone_mention_mask.shape[1], device=device).unsqueeze(0) >= observed_zone_size.unsqueeze(1)) & zone_mention_mask\n",
    "    zone_target_mentions = zone_target_mentions[target_mask.any(1)]\n",
    "    target_mask = target_mask[target_mask.any(1)]\n",
    "    target_mentions = zone_target_mentions[target_mask]\n",
    "    return target_mentions, observed_mentions, zone_target_mentions, target_mask\n",
    "\n",
    "def compute_scores(pred_batcher, gold_batcher, queries={}, prefix='val_', verbose=0):\n",
    "    pred=pd.DataFrame(dict(pred_batcher[\"mention\", [\"sentence_id\", \"begin\", \"end\", \"ner_label\", \"mention_id\"]]))\n",
    "    gold=pd.DataFrame(dict(gold_batcher[\"mention\", [\"@zone_id\", \"begin\", \"end\", \"ner_label\", \"mention_id\"]]))\n",
    "    gold[\"sentence_id\"] = gold_batcher[\"zone\", \"sentence_id\"][gold[\"@zone_id\"]]\n",
    "\n",
    "    # Merge on spans and ner_label\n",
    "    merged = merge_pred_and_gold(\n",
    "        pred, gold, span_policy='exact',  # only partially match spans with strict bounds, we could also eval with 'exact' or 'partial'\n",
    "        on=[\"sentence_id\", (\"begin\", \"end\"), \"ner_label\"], atom_gold_level=[\"mention_id\"], atom_pred_level=[\"mention_id\"])\n",
    "    \n",
    "    merged[\"ner_label\"] = np.asarray(vocs[\"ner_label\"])[merged[\"ner_label\"]].astype(str)\n",
    "    metrics = {\n",
    "        **compute_metrics(merged, prefix=prefix),\n",
    "        #**compute_metrics(merged.query(\"ner_label == {}\".format(list(vocs[\"ner_label\"]).index(c[\"sosy\"]))), prefix=prefix+\"sosy_\"),\n",
    "        #**compute_metrics(merged.query(\"ner_label == {}\".format(list(vocs[\"ner_label\"]).index(c[\"pathologie\"]))), prefix=prefix+\"pathologie_\"),\n",
    "    }\n",
    "    for name, query in queries.items():\n",
    "        metrics.update(compute_metrics(merged.query(query), prefix=prefix+name+\"_\"))\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To debug the training, we can just comment the \"def run_epoch()\" and execute the function body manually without changing anything to it\n",
    "def extract_mentions(batcher, all_nets, max_depth=10):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    batcher: Batcher \n",
    "        The batcher containing the text from which we want to extract the mentions (and maybe the gold mentions)\n",
    "    ner_net: torch.nn.Module\n",
    "    max_depth: int\n",
    "        Max number of times we run the model per sample\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Batcher\n",
    "    \"\"\"\n",
    "    pred_batches = []\n",
    "    n_mentions = 0\n",
    "    ner_net = all_nets[\"ner_net\"]\n",
    "    tag_embeddings = all_nets[\"tag_embeddings\"]\n",
    "    with evaluating(all_nets):\n",
    "        with torch.no_grad():\n",
    "            for batch_i, batch in enumerate(batcher['sentence'].dataloader(batch_size=batch_size, shuffle=False, sparse_sort_on=\"token_mask\", device=tg.device)):\n",
    "\n",
    "                tag_embeds = torch.zeros(*batch[\"sentence\", \"token\"].shape[:2], tag_dim, device=tg.device)\n",
    "                current_sentences_idx = torch.arange(len(batch), device=tg.device)\n",
    "                mask = batch[\"token_mask\"]\n",
    "                tokens = batch[\"token\"]\n",
    "\n",
    "                for i in range(max_depth):\n",
    "                    # Run the model argmax here\n",
    "                    ner_res = ner_net(\n",
    "                        tokens = tokens,\n",
    "                        mask = mask,\n",
    "                        tag_embeds = tag_embeds,\n",
    "                        return_embeddings=True\n",
    "                    )\n",
    "\n",
    "                    # Run the linear CRF Viterbi algorithm to compute the most likely sequence\n",
    "                    pred_tags = ner_net.crf.decode(ner_res[\"scores\"], mask)\n",
    "                    spans = ner_net.crf.tags_to_spans(pred_tags, mask)\n",
    "\n",
    "                    # Save predicted mentions\n",
    "                    pred_batch = Batcher({\n",
    "                        \"mention\": {\n",
    "                            \"mention_id\": torch.arange(n_mentions, n_mentions+len(spans[\"span_doc_id\"]), device=tg.device),\n",
    "                            \"begin\": spans[\"span_begin\"],\n",
    "                            \"end\": spans[\"span_end\"],\n",
    "                            \"ner_label\": spans[\"span_label\"],\n",
    "                            \"@sentence_id\": current_sentences_idx[spans[\"span_doc_id\"]],\n",
    "                            \"depth\": torch.full_like(spans[\"span_begin\"], fill_value=i),\n",
    "                        },\n",
    "                        \"sentence\": dict(batch[\"sentence\", [\"sentence_id\", \"doc_id\"]]),\n",
    "                        \"doc\": dict(batch[\"doc\"])}, \n",
    "                        check=False).sparsify()\n",
    "                    pred_batches.append(pred_batch)\n",
    "                    n_mentions += len(spans[\"span_doc_id\"])\n",
    "\n",
    "                    non_empty_sentences = torch.unique(spans[\"span_doc_id\"])\n",
    "\n",
    "                    if len(non_empty_sentences) == 0:\n",
    "                        break\n",
    "\n",
    "                    # Convert the predicted spans to tags using the same encoding scheme as the one used to decode predicted tags\n",
    "                    # (We could use a different one: BIODecoder/BIOULDecoder.spans_to_tags is a static function)\n",
    "                    feature_tags = ner_net.crf.spans_to_tags(\n",
    "                        torch.arange(len(spans[\"span_begin\"]), device=spans[\"span_begin\"].device),\n",
    "                        spans[\"span_begin\"], \n",
    "                        spans[\"span_end\"],\n",
    "                        spans[\"span_label\"], \n",
    "                        n_tokens=batch[\"sentence\", \"token\"].shape[1],\n",
    "                        n_samples=len(spans[\"span_begin\"]),\n",
    "                    )\n",
    "                    tag_mention, tag_positions = feature_tags.nonzero(as_tuple=True)\n",
    "                    tag_sentence = spans[\"span_doc_id\"][tag_mention]\n",
    "                    tag_values = feature_tags[tag_mention, tag_positions]\n",
    "\n",
    "                    tag_embeds = tag_embeds.view(-1, tag_dim).index_add_(\n",
    "                        dim=0,\n",
    "                        index=tag_sentence * batch[\"sentence\", \"token\"].shape[1] + tag_positions, \n",
    "                        source=tag_embeddings.weight[tag_values-1]).view(len(current_sentences_idx), batch[\"sentence\", \"token\"].shape[1], tag_dim)[non_empty_sentences]\n",
    "\n",
    "                    # Compute the tokens label tag embeddings of the observed (maybe overlapping) mentions\n",
    "                    tokens = tokens[non_empty_sentences]\n",
    "                    mask = mask[non_empty_sentences]\n",
    "                    current_sentences_idx = current_sentences_idx[non_empty_sentences]\n",
    "    return Batcher.concat(pred_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Define the training metrics\n",
    "metrics_info = defaultdict(lambda: False)\n",
    "flt_format = (5, \"{:.4f}\".format)\n",
    "metrics_info.update({\n",
    "    \"train_loss\": {\"goal\": 0, \"format\": flt_format},\n",
    "    \"train_ner_loss\": {\"goal\": 0, \"format\": flt_format},\n",
    "    #\"train_recall\": {\"goal\": 1, \"format\": flt_format, \"name\": \"train_rec\"},\n",
    "    #\"train_precision\": {\"goal\": 1, \"format\": flt_format, \"name\": \"train_prec\"},\n",
    "    \"train_f1\": {\"goal\": 1, \"format\": flt_format, \"name\": \"train_f1\"},\n",
    "    \n",
    "    \"val_loss\": {\"goal\": 0, \"format\": flt_format},\n",
    "    \"val_ner_loss\": {\"goal\": 0, \"format\": flt_format},\n",
    "    \"val_label_loss\": {\"goal\": 0, \"format\": flt_format},\n",
    "    \n",
    "    \"val_f1\": {\"goal\": 1, \"format\": flt_format, \"name\": \"val_f1\"},\n",
    "    \"val_3.1_f1\": {\"goal\": 1, \"format\": flt_format, \"name\": \"val_3.1_f1\"},\n",
    "    \"val_3.2_f1\": {\"goal\": 1, \"format\": flt_format, \"name\": \"val_3.2_f1\"},\n",
    "    \"val_macro_f1\": {\"goal\": 1, \"format\": flt_format, \"name\": \"val_macro_f1\"},\n",
    "    \"val_sosy_f1\": {\"goal\": 1, \"format\": flt_format, \"name\": \"val_sosy_f1\"},\n",
    "    \"val_pathologie_f1\": {\"goal\": 1, \"format\": flt_format, \"name\": \"val_patho_f1\"},\n",
    "    \n",
    "    \"duration\": {\"format\": flt_format, \"name\": \"   dur(s)\"},\n",
    "    \"rescale\": {\"format\": flt_format},\n",
    "    \"n_depth\": {\"format\": flt_format},\n",
    "    \"n_matched\": {\"format\": flt_format},\n",
    "    \"n_targets\": {\"format\": flt_format},\n",
    "    \"n_observed\": {\"format\": flt_format},\n",
    "    \"total_score_sum\": {\"format\": flt_format},\n",
    "    \"lr\": {\"format\": (5, \"{:.2e}\".format)},\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batcher(docs, sentences, zones, mentions, conflicts, tokens):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    ----------\n",
    "    docs: pd.DataFrame\n",
    "    sentences: pd.DataFrame\n",
    "    zones: pd.DataFrame\n",
    "    mentions: pd.DataFrame\n",
    "    conflicts: pd.DataFrame\n",
    "    tokens: pd.DataFrame\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Batcher\n",
    "    \"\"\"\n",
    "    docs = docs.copy()\n",
    "    sentences = sentences.copy()\n",
    "    zones = zones.copy()\n",
    "    mentions = mentions.copy()\n",
    "    conflicts = conflicts.copy()\n",
    "    tokens = tokens.copy()\n",
    "    \n",
    "    [tokens[\"token_id\"]], unique_token_id = factorize_rows([tokens[\"token_id\"]])\n",
    "    [mentions[\"mention_id\"], conflicts[\"mention_id\"], conflicts[\"mention_id_other\"]], unique_mention_ids = factorize_rows(\n",
    "        [mentions[[\"doc_id\", \"sentence_id\", \"mention_id\"]], conflicts[[\"doc_id\", \"sentence_id\", \"mention_id\"]], conflicts[[\"doc_id\", \"sentence_id\", \"mention_id_other\"]]])\n",
    "    [zones[\"zone_id\"], mentions[\"zone_id\"]], unique_zone_ids = factorize_rows(\n",
    "        [zones[[\"doc_id\", \"sentence_id\", \"zone_id\"]], mentions[[\"doc_id\", \"sentence_id\", \"zone_id\"]]])\n",
    "    [sentences[\"sentence_id\"], zones[\"sentence_id\"], mentions[\"sentence_id\"], tokens[\"sentence_id\"],], unique_sentence_ids = factorize_rows(\n",
    "        [sentences[[\"doc_id\", \"sentence_id\"]], zones[[\"doc_id\", \"sentence_id\"]], mentions[[\"doc_id\", \"sentence_id\"]], tokens[[\"doc_id\", \"sentence_id\"]]])\n",
    "    [docs[\"doc_id\"], sentences[\"doc_id\"], zones[\"doc_id\"], mentions[\"doc_id\"], tokens[\"doc_id\"]], unique_doc_ids = factorize_rows(\n",
    "        [docs[\"doc_id\"], sentences[\"doc_id\"], zones[\"doc_id\"], mentions[\"doc_id\"], tokens[\"doc_id\"]])\n",
    "    \n",
    "    batcher = Batcher({\n",
    "        \"mention\": {\n",
    "            \"mention_id\": mentions[\"mention_id\"],\n",
    "            \"zone_id\": mentions[\"zone_id\"],\n",
    "            \"sentence_id\": mentions[\"sentence_id\"],\n",
    "            \"doc_id\": mentions[\"doc_id\"],\n",
    "            \"begin\": mentions[\"begin\"],\n",
    "            \"end\": mentions[\"end\"],\n",
    "            \"ner_label\": mentions[\"ner_label\"].cat.codes,\n",
    "            \"conflict_mention_id\": df_to_csr(conflicts[\"mention_id\"], conflicts[\"conflict_idx\"], conflicts[\"mention_id_other\"], n_rows=len(unique_mention_ids)),\n",
    "            \"conflict_mask\": df_to_csr(conflicts[\"mention_id\"], conflicts[\"conflict_idx\"], n_rows=len(unique_mention_ids)),\n",
    "        },\n",
    "        \"zone\": {\n",
    "            \"zone_id\": zones[\"zone_id\"],\n",
    "            \"sentence_id\": zones[\"sentence_id\"],\n",
    "            \"doc_id\": zones[\"doc_id\"],\n",
    "            \"mention_id\": df_to_csr(mentions[\"zone_id\"], mentions[\"zone_mention_idx\"], mentions[\"mention_id\"], n_rows=len(unique_zone_ids)),\n",
    "            \"mention_mask\": df_to_csr(mentions[\"zone_id\"], mentions[\"zone_mention_idx\"], n_rows=len(unique_zone_ids)),\n",
    "        },\n",
    "        \"sentence\": {\n",
    "            \"sentence_id\": sentences[\"sentence_id\"],\n",
    "            \"doc_id\": sentences[\"doc_id\"],\n",
    "            \"mention_id\": df_to_csr(mentions[\"sentence_id\"], mentions[\"mention_idx\"], mentions[\"mention_id\"], n_rows=len(unique_sentence_ids)),\n",
    "            \"mention_mask\": df_to_csr(mentions[\"sentence_id\"], mentions[\"mention_idx\"], n_rows=len(unique_sentence_ids)),\n",
    "            \"token\": df_to_csr(tokens[\"sentence_id\"], tokens[\"token_idx\"], tokens[\"token\"].cat.codes, n_rows=len(unique_sentence_ids)),\n",
    "            \"token_mask\": df_to_csr(tokens[\"sentence_id\"], tokens[\"token_idx\"], n_rows=len(unique_sentence_ids)),\n",
    "            \"zone_id\": df_to_csr(zones[\"sentence_id\"], zones[\"zone_idx\"], zones[\"zone_id\"], n_rows=len(unique_sentence_ids)),\n",
    "            \"zone_mask\": df_to_csr(zones[\"sentence_id\"], zones[\"zone_idx\"], n_rows=len(unique_sentence_ids)),\n",
    "        },\n",
    "        \"doc\": {\n",
    "            \"doc_id\": np.arange(len(unique_doc_ids)),\n",
    "            \"sentence_id\": df_to_csr(sentences[\"doc_id\"], sentences[\"sentence_idx\"], sentences[\"sentence_id\"], n_rows=len(unique_doc_ids)),\n",
    "            \"sentence_mask\": df_to_csr(sentences[\"doc_id\"], sentences[\"sentence_idx\"], n_rows=len(unique_doc_ids)),\n",
    "            \"split\": docs[\"split\"].cat.codes,\n",
    "        }},\n",
    "        masks={\"sentence\": {\"token\": \"token_mask\", \"zone_id\": \"zone_mask\", \"mention_id\": \"mention_mask\"}, \n",
    "               \"mention\": {\"conflict_mention_id\": \"conflict_mask\"},\n",
    "               \"zone\": {\"mention_id\": \"mention_mask\"}, \n",
    "               \"doc\": {\"sentence_id\": \"sentence_mask\"}}\n",
    "    )\n",
    "    return (\n",
    "        batcher, \n",
    "        dict(docs=docs, sentences=sentences, zones=zones, mentions=mentions, tokens=tokens),\n",
    "        dict(token_id=unique_token_id, mention_id=unique_mention_ids, zone_id=unique_zone_ids, sentence_id=unique_sentence_ids, doc_id=unique_doc_ids)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERNet(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_labels,\n",
    "                 hidden_dim,\n",
    "                 dropout,\n",
    "                 n_tokens=None,\n",
    "                 token_dim=None,\n",
    "                 embeddings=None,\n",
    "                 tag_scheme=\"bio\",\n",
    "                 metric='linear',\n",
    "                 metric_fc_kwargs=None,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        if embeddings is not None:\n",
    "            self.embeddings = embeddings\n",
    "            if n_tokens is None or token_dim is None:\n",
    "                if hasattr(embeddings, 'weight'):\n",
    "                    n_tokens, token_dim = embeddings.weight.shape\n",
    "                else:\n",
    "                    n_tokens, token_dim = embeddings.embeddings.weight.shape\n",
    "        else:\n",
    "            self.embeddings = torch.nn.Embedding(n_tokens, token_dim) if n_tokens > 0 else None\n",
    "        assert token_dim is not None, \"Provide token_dim or embeddings\"\n",
    "        assert self.embeddings is not None\n",
    "\n",
    "        dim = (token_dim if n_tokens > 0 else 0)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        if tag_scheme == \"bio\":\n",
    "            self.crf = BIODecoder(n_labels)\n",
    "        elif tag_scheme == \"bioul\":\n",
    "            self.crf = BIOULDecoder(n_labels)\n",
    "        else:\n",
    "            raise Exception()\n",
    "        if hidden_dim is None:\n",
    "            hidden_dim = dim\n",
    "        self.linear = torch.nn.Linear(dim, hidden_dim)\n",
    "        self.batch_norm = torch.nn.BatchNorm1d(dim)\n",
    "\n",
    "        n_tags = self.crf.num_tags\n",
    "        metric_fc_kwargs = metric_fc_kwargs if metric_fc_kwargs is not None else {}\n",
    "        if metric == \"linear\":\n",
    "            self.metric_fc = torch.nn.Linear(dim, n_tags)\n",
    "        elif metric == \"cosine\":\n",
    "            self.metric_fc = CosineSimilarity(dim, n_tags, rescale=rescale, **metric_fc_kwargs)\n",
    "        elif metric == \"ema_cosine\":\n",
    "            self.metric_fc = EMACosineSimilarity(dim, n_tags, rescale=rescale, **metric_fc_kwargs)\n",
    "        else:\n",
    "            raise Exception()\n",
    "    \n",
    "    def extended_embeddings(self, tokens, mask, **kwargs):\n",
    "        # Default case here, size <= 512\n",
    "        # Small ugly check to see if self.embeddings is Bert-like, then we need to pass a mask\n",
    "        if hasattr(self.embeddings, 'encoder') or hasattr(self.embeddings, 'transformer'):\n",
    "            return self.embeddings(tokens, mask, **kwargs)[0]\n",
    "        else:\n",
    "            return self.embeddings(tokens)\n",
    "\n",
    "    def forward(self, tokens, mask, tag_embeds=None, return_embeddings=False):\n",
    "        # Embed the tokens\n",
    "        scores = None\n",
    "        # shape: n_batch * sequence * 768\n",
    "        embeds = self.extended_embeddings(tokens, mask, custom_embeds=tag_embeds)\n",
    "        state = embeds.masked_fill(~mask.unsqueeze(-1), 0)\n",
    "        state = torch.relu(self.linear(self.dropout(state)))# + state\n",
    "        state = self.batch_norm(state.view(-1, state.shape[-1])).view(state.shape)\n",
    "        scores = self.metric_fc(state)\n",
    "        return {\n",
    "            \"scores\": scores,\n",
    "            \"embeddings\": embeds if return_embeddings else None,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMNERNet(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_labels,\n",
    "                 hidden_dim,\n",
    "                 dropout,\n",
    "                 n_tokens=None,\n",
    "                 token_dim=None,\n",
    "                 embeddings=None,\n",
    "                 tag_scheme=\"bio\",\n",
    "                 metric='linear',\n",
    "                 metric_fc_kwargs=None,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        if embeddings is not None:\n",
    "            self.embeddings = embeddings\n",
    "            if n_tokens is None or token_dim is None:\n",
    "                if hasattr(embeddings, 'weight'):\n",
    "                    n_tokens, token_dim = embeddings.weight.shape\n",
    "                else:\n",
    "                    n_tokens, token_dim = embeddings.embeddings.weight.shape\n",
    "        else:\n",
    "            self.embeddings = torch.nn.Embedding(n_tokens, token_dim) if n_tokens > 0 else None\n",
    "        assert token_dim is not None, \"Provide token_dim or embeddings\"\n",
    "        assert self.embeddings is not None\n",
    "\n",
    "        dim = (token_dim if n_tokens > 0 else 0)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        if tag_scheme == \"bio\":\n",
    "            self.crf = BIODecoder(n_labels)\n",
    "        elif tag_scheme == \"bioul\":\n",
    "            self.crf = BIOULDecoder(n_labels)\n",
    "        else:\n",
    "            raise Exception()\n",
    "        if hidden_dim is None:\n",
    "            hidden_dim = dim\n",
    "        self.linear = torch.nn.Linear(dim, hidden_dim)\n",
    "        self.batch_norm = torch.nn.BatchNorm1d(dim)\n",
    "        self.lstm = torch.nn.LSTM(hidden_dim, \n",
    "                                  hidden_dim, dropout=dropout, batch_first=True, num_layers=2, bidirectional=True)\n",
    "            \n",
    "\n",
    "        n_tags = self.crf.num_tags\n",
    "        metric_fc_kwargs = metric_fc_kwargs if metric_fc_kwargs is not None else {}\n",
    "        if metric == \"linear\":\n",
    "            self.metric_fc = torch.nn.Linear(hidden_dim*2, n_tags)\n",
    "        elif metric == \"cosine\":\n",
    "            self.metric_fc = CosineSimilarity(dim, n_tags, rescale=rescale, **metric_fc_kwargs)\n",
    "        elif metric == \"ema_cosine\":\n",
    "            self.metric_fc = EMACosineSimilarity(dim, n_tags, rescale=rescale, **metric_fc_kwargs)\n",
    "        else:\n",
    "            raise Exception()\n",
    "    \n",
    "    def extended_embeddings(self, tokens, mask, **kwargs):\n",
    "        # Default case here, size <= 512\n",
    "        # Small ugly check to see if self.embeddings is Bert-like, then we need to pass a mask\n",
    "        if hasattr(self.embeddings, 'encoder') or hasattr(self.embeddings, 'transformer'):\n",
    "            return self.embeddings(tokens, mask, **kwargs)[0]\n",
    "        else:\n",
    "            return self.embeddings(tokens)\n",
    "\n",
    "    def forward(self, tokens, mask, tag_embeds=None, return_embeddings=False):\n",
    "        # Embed the tokens\n",
    "        scores = None\n",
    "        # shape: n_batch * sequence * 768\n",
    "        embeds = self.extended_embeddings(tokens, mask, custom_embeds=tag_embeds)\n",
    "        state = embeds.masked_fill(~mask.unsqueeze(-1), 0)\n",
    "        state = torch.relu(self.linear(self.dropout(state)))# + state\n",
    "        state = self.batch_norm(state.view(-1, state.shape[-1])).view(state.shape)\n",
    "        \n",
    "        lstm_state = self.lstm(self.dropout(state))[0]\n",
    "        state = torch.relu(lstm_state)\n",
    "        scores = self.metric_fc(state)\n",
    "        return {\n",
    "            \"scores\": scores,\n",
    "            \"embeddings\": embeds if return_embeddings else None,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@cached\n",
    "def preprocess(\n",
    "    dataset,\n",
    "    max_sentence_length,\n",
    "    bert_name,\n",
    "    ner_labels=None,\n",
    "    unknown_labels=\"drop\",\n",
    "    vocabularies=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "        dataset: Dataset\n",
    "        max_sentence_length: int\n",
    "            Max number of \"words\" as defined by the regex in regex_sentencize (so this is not the nb of wordpieces)\n",
    "        bert_name: str\n",
    "            bert path/name\n",
    "        ner_labels: list of str \n",
    "            allowed ner labels (to be dropped or filtered)\n",
    "        unknown_labels: str\n",
    "            \"drop\" or \"raise\"\n",
    "        vocabularies: dict[str; np.ndarray or list]\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    (pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame, dict[str; np.ndarray or list])\n",
    "        docs:      ('split', 'text', 'doc_id')\n",
    "        sentences: ('split', 'doc_id', 'sentence_idx', 'begin', 'end', 'text', 'sentence_id')\n",
    "        zones:     ('doc_id', 'sentence_id', 'zone_id', 'zone_idx')\n",
    "        mentions:  ('ner_label', 'doc_id', 'sentence_id', 'mention_id', 'depth', 'zone_id', 'text', 'mention_idx', 'begin', 'end', 'zone_mention_idx')\n",
    "        conflicts: ('doc_id', 'sentence_id', 'mention_id', 'mention_id_other', 'conflict_idx')\n",
    "        tokens:    ('split', 'token', 'sentence_id', 'token_id', 'token_idx', 'begin', 'end', 'doc_id', 'sentence_idx')\n",
    "        deltas:    ('doc_id', 'begin', 'end', 'delta')\n",
    "        vocs: vocabularies to be reused later for encoding more data or decoding predictions\n",
    "    \"\"\"\n",
    "    print(\"Dataset:\", dataset)\n",
    "\n",
    "    mentions = dataset[\"mentions\"].rename({\"label\": \"ner_label\"}, axis=1)\n",
    "\n",
    "    \n",
    "    if ner_labels is not None:\n",
    "        len_before = len(mentions)\n",
    "        unknown_ner_labels = list(mentions[~mentions[\"ner_label\"].isin(ner_labels)][\"ner_label\"].drop_duplicates())\n",
    "        mentions = mentions[mentions[\"ner_label\"].isin(ner_labels)]\n",
    "        \n",
    "        if len(unknown_ner_labels) and unknown_labels == \"raise\":\n",
    "            raise Exception(f\"Unkown labels in {len_before-len(mentions)} mentions: \", unknown_ner_labels)\n",
    "\n",
    "    # Check that there is no mention overlap\n",
    "    mentions = mentions.merge(dataset[\"fragments\"].groupby([\"doc_id\", \"mention_id\"], as_index=False, observed=True).agg({\"begin\": \"min\", \"end\": \"max\"}))\n",
    "\n",
    "    \n",
    "    print(\"Transform texts...\", end=\" \")\n",
    "    transformed_docs, deltas = apply_substitutions(\n",
    "        dataset[\"docs\"], *zip(\n",
    "            (r\"(?<=[{}\\\\])(?![ ])\".format(string.punctuation), r\" \"),\n",
    "            (r\"(?<![ ])(?=[{}\\\\])\".format(string.punctuation), r\" \"),\n",
    "            (\"(?<=[a-zA-Z])(?=[0-9])\", r\" \"),\n",
    "            (\"(?<=[0-9])(?=[A-Za-z])\", r\" \"),\n",
    "        ), apply_unidecode=True)\n",
    "    transformed_docs = transformed_docs.astype({\"text\": str})\n",
    "    transformed_mentions = apply_deltas(mentions, deltas, on=['doc_id'])\n",
    "    print(\"done\")\n",
    "    \n",
    "    print(\"Splitting into sentences...\", end=\" \")\n",
    "    sentences = regex_sentencize(\n",
    "        transformed_docs, \n",
    "        reg_split=r\"((?:\\s*\\n\\s*\\n)+\\s*|(?:(?<=[a-z0-9)]\\n)|(?<=[a-z0-9)][ ](?:\\.|\\n))|(?<=[a-z0-9)][ ][ ](?:\\.|\\n)))\\s*(?=[A-Z]))\",\n",
    "        min_sentence_length=0, max_sentence_length=max_sentence_length,\n",
    "        # balance_parentheses=True, # default is True\n",
    "    )\n",
    "    \n",
    "    [sentence_mentions], sentences, sentence_to_docs = partition_spans([transformed_mentions], sentences, new_id_name=\"sentence_id\", overlap_policy=False)\n",
    "#     n_sentences_per_mention = sentence_mentions.assign(count=1).groupby([\"doc_id\", \"mention_id\"], as_index=False).agg({\"count\": \"sum\", \"text\": \"first\", \"sentence_id\": \"last\"})\n",
    "#     if n_sentences_per_mention[\"count\"].max() > 1:\n",
    "#         display(n_sentences_per_mention.query(\"count > 1\"))\n",
    "#         display(sentences[sentences[\"sentence_id\"].isin(n_sentences_per_mention.query(\"count > 1\")[\"sentence_id\"])][\"text\"].tolist())\n",
    "#         raise Exception(\"Some mentions could be mapped to more than 1 sentences ({})\".format(n_sentences_per_mention[\"count\"].max()))\n",
    "    if sentence_to_docs is not None:\n",
    "        sentence_mentions = sentence_mentions.merge(sentence_to_docs)\n",
    "    \n",
    "    sentence_mentions = sentence_mentions.assign(mention_idx=0).nlstruct.groupby_assign([\"doc_id\", \"sentence_id\"], {\"mention_idx\": lambda x: tuple(range(len(x)))})\n",
    "    print(\"done\")\n",
    "    \n",
    "    print(\"Tokenizing...\", end=\" \")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(bert_name)\n",
    "    sentences[\"text\"] = sentences[\"text\"].str.lower()\n",
    "    tokens = huggingface_tokenize(sentences, tokenizer, doc_id_col=\"sentence_id\")\n",
    "    sentence_mentions = split_into_spans(sentence_mentions, tokens, pos_col=\"token_idx\", overlap_policy=False)\n",
    "    print(\"done\")\n",
    "    \n",
    "    print(\"Processing zones (overlapping areas)...\", end=\" \")\n",
    "    # Extract overlapping spans\n",
    "    conflicts = (\n",
    "        merge_with_spans(sentence_mentions, sentence_mentions, on=[\"doc_id\", \"sentence_id\", (\"begin\", \"end\")], how=\"outer\", suffixes=(\"\", \"_other\"))\n",
    "    )\n",
    "\n",
    "    # ids1, and ids2 make the edges of the overlapping mentions of the same type (see the \"ner_label\")\n",
    "    [ids1, ids2], unique_ids = factorize_rows(\n",
    "        [conflicts[[\"doc_id\", \"sentence_id\", \"mention_id\"]], \n",
    "         conflicts[[\"doc_id\", \"sentence_id\", \"mention_id_other\"]]],\n",
    "        sentence_mentions.eval(\"size=(end-begin)\").sort_values(\"size\")[[\"doc_id\", \"sentence_id\", \"mention_id\"]]\n",
    "    )\n",
    "    g = nx.from_scipy_sparse_matrix(df_to_csr(ids1, ids2, n_rows=len(unique_ids), n_cols=len(unique_ids)))\n",
    "    colored_nodes = np.asarray(list(nx.coloring.greedy_color(g, strategy=keep_order).items()))\n",
    "    unique_ids['depth'] = colored_nodes[:, 1][colored_nodes[:, 0].argsort()]\n",
    "    zone_indices, mention_indices = zip(*chain.from_iterable(zip(repeat(zone_idx), zone) for zone_idx, zone in enumerate(nx.connected_components(g))))\n",
    "    conflicts = conflicts[[\"doc_id\", \"sentence_id\", \"mention_id\", \"mention_id_other\"]].assign(conflict_idx=0).nlstruct.groupby_assign([\"doc_id\", \"sentence_id\", \"mention_id\"], {\"conflict_idx\": lambda x: tuple(range(len(x)))})\n",
    "\n",
    "    zone_mentions = pd.DataFrame({\n",
    "        **unique_ids.iloc[list(mention_indices)],\n",
    "        \"zone_id\": zone_indices,\n",
    "    }).merge(sentence_mentions, on=[\"doc_id\", \"sentence_id\", \"mention_id\"]).sort_values([\"doc_id\", \"sentence_id\", \"zone_id\", \"mention_id\"])\n",
    "    zone_mentions = zone_mentions.assign(zone_mention_idx=0).nlstruct.groupby_assign(['doc_id', 'sentence_id', 'zone_id'], {\"zone_mention_idx\": lambda vec: tuple(np.arange(len(vec)))})\n",
    "    sentence_zones = zone_mentions[[\"doc_id\", \"sentence_id\", \"zone_id\"]].drop_duplicates()\n",
    "    sentence_zones = sentence_zones.assign(zone_idx=0).nlstruct.groupby_assign(['doc_id', 'sentence_id'], {\"zone_idx\": lambda vec: tuple(np.arange(len(vec)))})\n",
    "    sentence_mentions = sentence_mentions.merge(zone_mentions.drop_duplicates([\"doc_id\", \"sentence_id\", \"mention_id\", \"depth\"]))\n",
    "    print(\"done\")\n",
    "\n",
    "    print(\"Computing vocabularies...\")\n",
    "    [transformed_docs, sentences, sentence_zones, zone_mentions, tokens], vocs = normalize_vocabularies(\n",
    "        [transformed_docs, sentences, sentence_zones, zone_mentions, tokens], \n",
    "        vocabularies={\"split\": [\"train\", \"val\", \"test\"]} if vocabularies is None else vocabularies,\n",
    "        train_vocabularies={\"source\": False, \"text\": False} if vocabularies is None else False,\n",
    "        verbose=True)\n",
    "    print(\"done\")\n",
    "    return transformed_docs, sentences, sentence_zones, zone_mentions, conflicts, tokens, deltas, vocs\n",
    "\n",
    "def keep_order(G, colors):\n",
    "    \"\"\"Returns a list of the nodes of ``G`` in ordered identically to their id in the graph\n",
    "    ``G`` is a NetworkX graph. ``colors`` is ignored.\n",
    "    This is to assign a depth using the nx.coloring.greedy_color function\n",
    "    \"\"\"\n",
    "    return sorted(list(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Dataset(\n",
      "  (docs):       3790 * ('doc_id', 'text', 'split')\n",
      "  (mentions):   1023 * ('doc_id', 'mention_id', 'label', 'text')\n",
      "  (fragments):  1023 * ('doc_id', 'mention_id', 'fragment_id', 'begin', 'end')\n",
      "  (attributes):    0 * ('doc_id', 'mention_id', 'attribute_id', 'label', 'value')\n",
      "  (relations):     0 * ('doc_id', 'relation_id', 'relation_label', 'from_mention_id', 'to_mention_id')\n",
      "  (comments):      0 * ('doc_id', 'comment_id', 'mention_id', 'comment')\n",
      ")\n",
      "Transform texts... done\n",
      "Splitting into sentences... done\n",
      "Tokenizing... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ytaille/.conda/envs/deep_mult_norm/lib/python3.7/site-packages/transformers/tokenization_utils.py:831: FutureWarning: Parameter max_len is deprecated and will be removed in a future release. Use model_max_length instead.\n",
      "  category=FutureWarning,\n",
      "/home/ytaille/.conda/envs/deep_mult_norm/lib/python3.7/site-packages/nlstruct/text/chunking/huggingface.py:11: FutureWarning: doc_id_col is not used anymore in the huggingface_tokenize function\n",
      "  warnings.warn(\"doc_id_col is not used anymore in the huggingface_tokenize function\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "Processing zones (overlapping areas)... done\n",
      "Computing vocabularies...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "bert_name = \"camembert-base\"\n",
    "dataset = load_from_brat('/home/ytaille/data/resources/corpus_dalloux/CAS_neg_brat')#load_genia_ner()\n",
    "\n",
    "NEG_ONLY = False\n",
    "\n",
    "if NEG_ONLY:\n",
    "    neg_doc_ids = dataset['mentions']['doc_id'].unique()\n",
    "    neg_docs = dataset['docs'][dataset['docs']['doc_id'].isin(neg_doc_ids)]\n",
    "    neg_mentions = dataset['mentions'][dataset['mentions']['doc_id'].isin(neg_doc_ids)]\n",
    "    neg_fragments = dataset['fragments'][dataset['fragments']['doc_id'].isin(neg_doc_ids)]\n",
    "    \n",
    "    dataset = Dataset(\n",
    "        docs=neg_docs,\n",
    "        mentions=neg_mentions,\n",
    "        fragments=neg_fragments,\n",
    "        attributes=dataset['attributes'],\n",
    "        relations=dataset['relations'],\n",
    "        comments=dataset['comments'],\n",
    "    )\n",
    "\n",
    "docs, sentences, zones, mentions, conflicts, tokens, deltas, vocs = preprocess(\n",
    "    dataset=dataset,\n",
    "    max_sentence_length=120,\n",
    "    bert_name=bert_name,\n",
    "    ner_labels= ['NEG'],\n",
    "    unknown_labels=\"drop\",\n",
    ")\n",
    "batcher, encoded, ids = make_batcher(docs, sentences, zones, mentions, conflicts, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity (L2 dist) between train and val frequencies: 0.0\n",
      "Frequebncies\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>NEG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>val</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  NEG\n",
       "0  train  1.0\n",
       "1    val  1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#all_test_doc_ids = []\n",
    "#sims = {}\n",
    "#for i in range(200):\n",
    "seed_all(1234567+137)\n",
    "\n",
    "train_batcher = batcher['doc'][batcher['doc']['split']==0]['sentence']\n",
    "val_batcher = batcher['doc'][batcher['doc']['split']==1]['sentence']\n",
    "# test_batcher = batcher['doc'][batcher['doc']['split']==2]['sentence']\n",
    "\n",
    "# splits = np.zeros(len(train_batcher['doc']), dtype=int)\n",
    "\n",
    "# val_perc = 0.1\n",
    "# splits[np.random.choice(np.arange(len(splits)), size=int(val_perc * len(splits)))] = 1\n",
    "\n",
    "# val_batcher = batcher['sentence'][splits == 1]\n",
    "\n",
    "# train_val_split = np.random.permutation(len(train_batcher))\n",
    "# test_batcher = train_batcher[train_val_split[:int(0.1*len(train_val_split))]]['sentence']\n",
    "# train_batcher = train_batcher[train_val_split[int(0.1*len(train_val_split)):]]['sentence']\n",
    "sim = ((np.bincount(val_batcher['mention', 'ner_label'], minlength=len(vocs[\"ner_label\"]))/len(val_batcher['mention']) -\n",
    "np.bincount(train_batcher['mention', 'ner_label'], minlength=len(vocs[\"ner_label\"]))/len(train_batcher['mention']))**2).sum()\n",
    "print(\"Similarity (L2 dist) between train and val frequencies:\", sim)\n",
    "print(\"Frequebncies\")\n",
    "#all_test_doc_ids.append((test_doc_ids, sim))\n",
    "display(pd.DataFrame([\n",
    "    {\"index\": \"train\", **dict(zip(vocs[\"ner_label\"], np.bincount(train_batcher['mention', 'ner_label'], minlength=len(vocs[\"ner_label\"]))/len(train_batcher['mention'])))},\n",
    "    {\"index\": \"val\", **dict(zip(vocs[\"ner_label\"], np.bincount(val_batcher['mention', 'ner_label'], minlength=len(vocs[\"ner_label\"]))/len(val_batcher['mention'])))},\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install /home/yoann/these/DEFT/nlstruct/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 768 bioul 12 0.01 4e-05 1 0.1\n",
      "before layer norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ytaille/.conda/envs/deep_mult_norm/lib/python3.7/site-packages/nlstruct/train/helpers.py:141: UserWarning: Entry 'schedules' in the state seems to be mutable but has no load_state_dict/state_dict methods. This could lead to unpredictable behaviors.\n",
      "  warn(f\"Entry '{key}' in the state seems to be mutable but has no load_state_dict/state_dict methods. This could lead to unpredictable behaviors.\")\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.25it/s]\n",
      "INFO:nlstruct:epoch | train_ner_loss | train_f1 | \u001b[31mval_f1\u001b[0m | val_3.1_f1 | val_macro_f1 | n_matched |       lr |    dur(s)\n",
      "INFO:nlstruct:    1 |        \u001b[32m13.4219\u001b[0m |   \u001b[32m0.0000\u001b[0m | \u001b[32m0.0009\u001b[0m |     \u001b[32m0.0009\u001b[0m |       \u001b[32m0.0009\u001b[0m |  379.0000 | 1.00e-02 |   15.2738\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.25it/s]\n",
      "INFO:nlstruct:    2 |         \u001b[32m6.1301\u001b[0m |   \u001b[32m0.0042\u001b[0m | \u001b[31m0.0000\u001b[0m |     \u001b[31m0.0000\u001b[0m |       \u001b[31m0.0000\u001b[0m |  370.0000 | 1.00e-02 |   14.7829\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.19it/s]\n",
      "INFO:nlstruct:    3 |         \u001b[32m5.2101\u001b[0m |   \u001b[32m0.0106\u001b[0m | \u001b[31m0.0000\u001b[0m |     \u001b[31m0.0000\u001b[0m |       \u001b[31m0.0000\u001b[0m |  394.0000 | 1.00e-02 |    8.5906\n",
      "100%|██████████| 24/24 [00:06<00:00,  3.45it/s]\n",
      "INFO:nlstruct:    4 |         \u001b[32m4.1153\u001b[0m |   \u001b[32m0.0496\u001b[0m | \u001b[31m0.0000\u001b[0m |     \u001b[31m0.0000\u001b[0m |       \u001b[31m0.0000\u001b[0m |  395.0000 | 1.00e-02 |    7.9794\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.40it/s]\n",
      "INFO:nlstruct:    5 |         \u001b[32m3.0055\u001b[0m |   \u001b[32m0.0542\u001b[0m | \u001b[31m0.0000\u001b[0m |     \u001b[31m0.0000\u001b[0m |       \u001b[31m0.0000\u001b[0m |  387.0000 | 1.00e-02 |    8.0943\n",
      "100%|██████████| 24/24 [00:06<00:00,  3.44it/s]\n",
      "INFO:nlstruct:    6 |         \u001b[32m2.5055\u001b[0m |   \u001b[32m0.1154\u001b[0m | \u001b[32m0.1851\u001b[0m |     \u001b[32m0.1851\u001b[0m |       \u001b[32m0.1851\u001b[0m |  385.0000 | 1.00e-02 |    8.4045\n",
      "100%|██████████| 24/24 [00:06<00:00,  3.43it/s]\n",
      "INFO:nlstruct:    7 |         \u001b[32m1.7627\u001b[0m |   \u001b[32m0.1812\u001b[0m | \u001b[31m0.0446\u001b[0m |     \u001b[31m0.0446\u001b[0m |       \u001b[31m0.0446\u001b[0m |  371.0000 | 1.00e-02 |    8.0755\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.39it/s]\n",
      "INFO:nlstruct:    8 |         \u001b[32m1.3714\u001b[0m |   \u001b[32m0.2643\u001b[0m | \u001b[31m0.0896\u001b[0m |     \u001b[31m0.0896\u001b[0m |       \u001b[31m0.0896\u001b[0m |  379.0000 | 1.00e-02 |    8.2519\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.22it/s]\n",
      "INFO:nlstruct:    9 |         \u001b[32m1.2282\u001b[0m |   \u001b[31m0.2316\u001b[0m | \u001b[31m0.0693\u001b[0m |     \u001b[31m0.0693\u001b[0m |       \u001b[31m0.0693\u001b[0m |  358.0000 | 1.00e-02 |    8.5674\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.27it/s]\n",
      "INFO:nlstruct:   10 |         \u001b[31m1.3063\u001b[0m |   \u001b[32m0.2881\u001b[0m | \u001b[31m0.1099\u001b[0m |     \u001b[31m0.1099\u001b[0m |       \u001b[31m0.1099\u001b[0m |  375.0000 | 1.00e-02 |    8.5776\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.25it/s]\n",
      "INFO:nlstruct:   11 |         \u001b[32m1.0976\u001b[0m |   \u001b[32m0.3447\u001b[0m | \u001b[32m0.3315\u001b[0m |     \u001b[32m0.3315\u001b[0m |       \u001b[32m0.3315\u001b[0m |  388.0000 | 1.00e-02 |    8.6394\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.18it/s]\n",
      "INFO:nlstruct:   12 |         \u001b[32m0.8498\u001b[0m |   \u001b[32m0.4098\u001b[0m | \u001b[31m0.2385\u001b[0m |     \u001b[31m0.2385\u001b[0m |       \u001b[31m0.2385\u001b[0m |  369.0000 | 1.00e-02 |    8.7580\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.18it/s]\n",
      "INFO:nlstruct:   13 |         \u001b[31m1.0790\u001b[0m |   \u001b[31m0.3329\u001b[0m | \u001b[31m0.2007\u001b[0m |     \u001b[31m0.2007\u001b[0m |       \u001b[31m0.2007\u001b[0m |  392.0000 | 1.00e-02 |    9.0581\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.21it/s]\n",
      "INFO:nlstruct:   14 |         \u001b[32m0.7798\u001b[0m |   \u001b[32m0.4114\u001b[0m | \u001b[32m0.3431\u001b[0m |     \u001b[32m0.3431\u001b[0m |       \u001b[32m0.3431\u001b[0m |  376.0000 | 1.00e-02 |    8.9012\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.18it/s]\n",
      "INFO:nlstruct:   15 |         \u001b[32m0.6645\u001b[0m |   \u001b[32m0.4458\u001b[0m | \u001b[32m0.4011\u001b[0m |     \u001b[32m0.4011\u001b[0m |       \u001b[32m0.4011\u001b[0m |  371.0000 | 1.00e-02 |    8.8153\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.18it/s]\n",
      "INFO:nlstruct:   16 |         \u001b[31m0.7111\u001b[0m |   \u001b[31m0.4454\u001b[0m | \u001b[31m0.1757\u001b[0m |     \u001b[31m0.1757\u001b[0m |       \u001b[31m0.1757\u001b[0m |  382.0000 | 1.00e-02 |    8.6810\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.21it/s]\n",
      "INFO:nlstruct:   17 |         \u001b[31m0.9304\u001b[0m |   \u001b[31m0.4441\u001b[0m | \u001b[31m0.2360\u001b[0m |     \u001b[31m0.2360\u001b[0m |       \u001b[31m0.2360\u001b[0m |  387.0000 | 1.00e-02 |    8.7837\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.21it/s]\n",
      "INFO:nlstruct:   18 |         \u001b[31m2.2904\u001b[0m |   \u001b[31m0.3921\u001b[0m | \u001b[31m0.3695\u001b[0m |     \u001b[31m0.3695\u001b[0m |       \u001b[31m0.3695\u001b[0m |  407.0000 | 1.00e-02 |    8.7154\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.17it/s]\n",
      "INFO:nlstruct:   19 |         \u001b[32m0.5741\u001b[0m |   \u001b[32m0.4869\u001b[0m | \u001b[31m0.1914\u001b[0m |     \u001b[31m0.1914\u001b[0m |       \u001b[31m0.1914\u001b[0m |  382.0000 | 1.00e-02 |    8.7514\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.21it/s]\n",
      "INFO:nlstruct:   20 |         \u001b[31m0.6543\u001b[0m |   \u001b[32m0.4950\u001b[0m | \u001b[31m0.3570\u001b[0m |     \u001b[31m0.3570\u001b[0m |       \u001b[31m0.3570\u001b[0m |  387.0000 | 1.00e-02 |    8.9467\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.22it/s]\n",
      "INFO:nlstruct:   21 |         \u001b[31m0.6023\u001b[0m |   \u001b[32m0.5328\u001b[0m | \u001b[31m0.3750\u001b[0m |     \u001b[31m0.3750\u001b[0m |       \u001b[31m0.3750\u001b[0m |  377.0000 | 1.00e-02 |    8.8738\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.21it/s]\n",
      "INFO:nlstruct:   22 |         \u001b[32m0.5271\u001b[0m |   \u001b[32m0.6032\u001b[0m | \u001b[31m0.3427\u001b[0m |     \u001b[31m0.3427\u001b[0m |       \u001b[31m0.3427\u001b[0m |  378.0000 | 1.00e-02 |    8.7978\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.18it/s]\n",
      "INFO:nlstruct:   23 |         \u001b[31m1.0373\u001b[0m |   \u001b[31m0.5330\u001b[0m | \u001b[31m0.3815\u001b[0m |     \u001b[31m0.3815\u001b[0m |       \u001b[31m0.3815\u001b[0m |  394.0000 | 1.00e-02 |    8.8142\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.21it/s]\n",
      "INFO:nlstruct:   24 |         \u001b[32m0.4484\u001b[0m |   \u001b[32m0.6067\u001b[0m | \u001b[32m0.4263\u001b[0m |     \u001b[32m0.4263\u001b[0m |       \u001b[32m0.4263\u001b[0m |  388.0000 | 1.00e-02 |    8.9160\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.20it/s]\n",
      "INFO:nlstruct:   25 |         \u001b[32m0.4220\u001b[0m |   \u001b[31m0.5844\u001b[0m | \u001b[31m0.3645\u001b[0m |     \u001b[31m0.3645\u001b[0m |       \u001b[31m0.3645\u001b[0m |  368.0000 | 1.00e-02 |    8.9108\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.18it/s]\n",
      "INFO:nlstruct:   26 |         \u001b[31m0.6436\u001b[0m |   \u001b[32m0.6388\u001b[0m | \u001b[32m0.4301\u001b[0m |     \u001b[32m0.4301\u001b[0m |       \u001b[32m0.4301\u001b[0m |  406.0000 | 1.00e-02 |    8.8332\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.18it/s]\n",
      "INFO:nlstruct:   27 |         \u001b[32m0.3401\u001b[0m |   \u001b[32m0.6586\u001b[0m | \u001b[31m0.2705\u001b[0m |     \u001b[31m0.2705\u001b[0m |       \u001b[31m0.2705\u001b[0m |  385.0000 | 1.00e-02 |    8.9985\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.20it/s]\n",
      "INFO:nlstruct:   28 |         \u001b[31m0.4724\u001b[0m |   \u001b[31m0.6379\u001b[0m | \u001b[31m0.3796\u001b[0m |     \u001b[31m0.3796\u001b[0m |       \u001b[31m0.3796\u001b[0m |  366.0000 | 1.00e-02 |    8.8536\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.20it/s]\n",
      "INFO:nlstruct:   29 |         \u001b[31m0.5970\u001b[0m |   \u001b[31m0.5714\u001b[0m | \u001b[31m0.3082\u001b[0m |     \u001b[31m0.3082\u001b[0m |       \u001b[31m0.3082\u001b[0m |  370.0000 | 1.00e-02 |    8.7016\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.17it/s]\n",
      "INFO:nlstruct:   30 |         \u001b[31m0.6473\u001b[0m |   \u001b[31m0.5540\u001b[0m | \u001b[31m0.2159\u001b[0m |     \u001b[31m0.2159\u001b[0m |       \u001b[31m0.2159\u001b[0m |  397.0000 | 1.00e-02 |    8.8012\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.16it/s]\n",
      "INFO:nlstruct:   31 |         \u001b[31m0.3788\u001b[0m |   \u001b[32m0.6610\u001b[0m | \u001b[32m0.4462\u001b[0m |     \u001b[32m0.4462\u001b[0m |       \u001b[32m0.4462\u001b[0m |  357.0000 | 1.00e-02 |    8.8915\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.20it/s]\n",
      "INFO:nlstruct:   32 |         \u001b[32m0.3297\u001b[0m |   \u001b[32m0.7040\u001b[0m | \u001b[31m0.4194\u001b[0m |     \u001b[31m0.4194\u001b[0m |       \u001b[31m0.4194\u001b[0m |  381.0000 | 1.00e-02 |    8.8725\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.23it/s]\n",
      "INFO:nlstruct:   33 |         \u001b[31m0.3395\u001b[0m |   \u001b[32m0.7123\u001b[0m | \u001b[31m0.3226\u001b[0m |     \u001b[31m0.3226\u001b[0m |       \u001b[31m0.3226\u001b[0m |  384.0000 | 1.00e-02 |    9.0392\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.19it/s]\n",
      "INFO:nlstruct:   34 |         \u001b[32m0.2618\u001b[0m |   \u001b[32m0.7394\u001b[0m | \u001b[31m0.0057\u001b[0m |     \u001b[31m0.0057\u001b[0m |       \u001b[31m0.0057\u001b[0m |  404.0000 | 1.00e-02 |   14.1017\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.17it/s]\n",
      "INFO:nlstruct:   35 |         \u001b[31m0.3018\u001b[0m |   \u001b[32m0.7669\u001b[0m | \u001b[31m0.3092\u001b[0m |     \u001b[31m0.3092\u001b[0m |       \u001b[31m0.3092\u001b[0m |  404.0000 | 1.00e-02 |    8.7743\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.20it/s]\n",
      "INFO:nlstruct:   36 |         \u001b[31m0.3732\u001b[0m |   \u001b[31m0.6520\u001b[0m | \u001b[31m0.1292\u001b[0m |     \u001b[31m0.1292\u001b[0m |       \u001b[31m0.1292\u001b[0m |  377.0000 | 1.00e-02 |   10.1771\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.19it/s]\n",
      "INFO:nlstruct:   37 |         \u001b[31m0.2729\u001b[0m |   \u001b[31m0.7464\u001b[0m | \u001b[31m0.2908\u001b[0m |     \u001b[31m0.2908\u001b[0m |       \u001b[31m0.2908\u001b[0m |  397.0000 | 1.00e-02 |    8.9743\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.16it/s]\n",
      "INFO:nlstruct:   38 |         \u001b[31m0.3787\u001b[0m |   \u001b[31m0.7280\u001b[0m | \u001b[31m0.3048\u001b[0m |     \u001b[31m0.3048\u001b[0m |       \u001b[31m0.3048\u001b[0m |  393.0000 | 1.00e-02 |    8.9104\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.22it/s]\n",
      "INFO:nlstruct:   39 |         \u001b[32m0.2066\u001b[0m |   \u001b[32m0.7904\u001b[0m | \u001b[31m0.3535\u001b[0m |     \u001b[31m0.3535\u001b[0m |       \u001b[31m0.3535\u001b[0m |  366.0000 | 1.00e-02 |    8.8917\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.21it/s]\n",
      "INFO:nlstruct:   40 |         \u001b[32m0.1648\u001b[0m |   \u001b[32m0.7918\u001b[0m | \u001b[31m0.3397\u001b[0m |     \u001b[31m0.3397\u001b[0m |       \u001b[31m0.3397\u001b[0m |  372.0000 | 1.00e-02 |    8.7589\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.20it/s]\n",
      "INFO:nlstruct:   41 |         \u001b[31m0.2170\u001b[0m |   \u001b[32m0.8044\u001b[0m | \u001b[31m0.3767\u001b[0m |     \u001b[31m0.3767\u001b[0m |       \u001b[31m0.3767\u001b[0m |  416.0000 | 1.00e-02 |    8.7789\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.13it/s]\n",
      "INFO:nlstruct:   42 |         \u001b[31m0.1950\u001b[0m |   \u001b[32m0.8370\u001b[0m | \u001b[31m0.4307\u001b[0m |     \u001b[31m0.4307\u001b[0m |       \u001b[31m0.4307\u001b[0m |  379.0000 | 1.00e-02 |    9.0092\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.18it/s]\n",
      "INFO:nlstruct:   43 |         \u001b[31m0.2720\u001b[0m |   \u001b[31m0.7887\u001b[0m | \u001b[31m0.3736\u001b[0m |     \u001b[31m0.3736\u001b[0m |       \u001b[31m0.3736\u001b[0m |  379.0000 | 1.00e-02 |    8.9124\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.17it/s]\n",
      "INFO:nlstruct:   44 |         \u001b[32m0.1566\u001b[0m |   \u001b[31m0.8304\u001b[0m | \u001b[31m0.3820\u001b[0m |     \u001b[31m0.3820\u001b[0m |       \u001b[31m0.3820\u001b[0m |  381.0000 | 1.00e-02 |    9.0833\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.18it/s]\n",
      "INFO:nlstruct:   45 |         \u001b[31m0.1637\u001b[0m |   \u001b[32m0.8457\u001b[0m | \u001b[31m0.2825\u001b[0m |     \u001b[31m0.2825\u001b[0m |       \u001b[31m0.2825\u001b[0m |  395.0000 | 1.00e-02 |    8.8147\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.12it/s]\n",
      "INFO:nlstruct:   46 |         \u001b[32m0.1398\u001b[0m |   \u001b[32m0.8660\u001b[0m | \u001b[31m0.3731\u001b[0m |     \u001b[31m0.3731\u001b[0m |       \u001b[31m0.3731\u001b[0m |  372.0000 | 1.00e-02 |    9.0095\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.17it/s]\n",
      "INFO:nlstruct:   47 |         \u001b[32m0.0981\u001b[0m |   \u001b[32m0.8858\u001b[0m | \u001b[31m0.4148\u001b[0m |     \u001b[31m0.4148\u001b[0m |       \u001b[31m0.4148\u001b[0m |  365.0000 | 1.00e-02 |    8.9843\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.17it/s]\n",
      "INFO:nlstruct:   48 |         \u001b[31m0.1155\u001b[0m |   \u001b[32m0.8928\u001b[0m | \u001b[31m0.3838\u001b[0m |     \u001b[31m0.3838\u001b[0m |       \u001b[31m0.3838\u001b[0m |  376.0000 | 1.00e-02 |    8.9427\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.18it/s]\n",
      "INFO:nlstruct:   49 |         \u001b[32m0.0908\u001b[0m |   \u001b[32m0.9225\u001b[0m | \u001b[31m0.3784\u001b[0m |     \u001b[31m0.3784\u001b[0m |       \u001b[31m0.3784\u001b[0m |  383.0000 | 1.00e-02 |    8.8436\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.19it/s]\n",
      "INFO:nlstruct:   50 |         \u001b[31m0.1105\u001b[0m |   \u001b[31m0.8898\u001b[0m | \u001b[31m0.3836\u001b[0m |     \u001b[31m0.3836\u001b[0m |       \u001b[31m0.3836\u001b[0m |  379.0000 | 1.00e-02 |    8.9117\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.19it/s]\n",
      "INFO:nlstruct:   51 |         \u001b[32m0.0756\u001b[0m |   \u001b[31m0.9044\u001b[0m | \u001b[31m0.4213\u001b[0m |     \u001b[31m0.4213\u001b[0m |       \u001b[31m0.4213\u001b[0m |  369.0000 | 1.00e-02 |    8.9628\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.17it/s]\n",
      "INFO:nlstruct:   52 |         \u001b[31m0.0940\u001b[0m |   \u001b[31m0.9211\u001b[0m | \u001b[31m0.3961\u001b[0m |     \u001b[31m0.3961\u001b[0m |       \u001b[31m0.3961\u001b[0m |  397.0000 | 1.00e-02 |    8.9623\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.21it/s]\n",
      "INFO:nlstruct:   53 |         \u001b[31m0.0927\u001b[0m |   \u001b[31m0.9213\u001b[0m | \u001b[31m0.4156\u001b[0m |     \u001b[31m0.4156\u001b[0m |       \u001b[31m0.4156\u001b[0m |  402.0000 | 1.00e-02 |    8.8437\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.17it/s]\n",
      "INFO:nlstruct:   54 |         \u001b[31m0.0773\u001b[0m |   \u001b[32m0.9501\u001b[0m | \u001b[32m0.4658\u001b[0m |     \u001b[32m0.4658\u001b[0m |       \u001b[32m0.4658\u001b[0m |  394.0000 | 1.00e-02 |    8.9085\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.20it/s]\n",
      "INFO:nlstruct:   55 |         \u001b[31m0.0854\u001b[0m |   \u001b[31m0.9287\u001b[0m | \u001b[31m0.3900\u001b[0m |     \u001b[31m0.3900\u001b[0m |       \u001b[31m0.3900\u001b[0m |  405.0000 | 1.00e-02 |    8.8384\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.20it/s]\n",
      "INFO:nlstruct:   56 |         \u001b[31m0.0795\u001b[0m |   \u001b[31m0.8871\u001b[0m | \u001b[31m0.4050\u001b[0m |     \u001b[31m0.4050\u001b[0m |       \u001b[31m0.4050\u001b[0m |  370.0000 | 1.00e-02 |    8.9381\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.21it/s]\n",
      "INFO:nlstruct:   57 |         \u001b[31m0.0770\u001b[0m |   \u001b[31m0.9225\u001b[0m | \u001b[31m0.4027\u001b[0m |     \u001b[31m0.4027\u001b[0m |       \u001b[31m0.4027\u001b[0m |  380.0000 | 1.00e-02 |    8.9969\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.20it/s]\n",
      "INFO:nlstruct:   58 |         \u001b[32m0.0585\u001b[0m |   \u001b[31m0.9402\u001b[0m | \u001b[31m0.4508\u001b[0m |     \u001b[31m0.4508\u001b[0m |       \u001b[31m0.4508\u001b[0m |  381.0000 | 1.00e-02 |    8.8411\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.17it/s]\n",
      "INFO:nlstruct:   59 |         \u001b[31m0.0656\u001b[0m |   \u001b[31m0.9280\u001b[0m | \u001b[31m0.4364\u001b[0m |     \u001b[31m0.4364\u001b[0m |       \u001b[31m0.4364\u001b[0m |  381.0000 | 1.00e-02 |    8.8989\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.22it/s]\n",
      "INFO:nlstruct:   60 |         \u001b[31m0.0881\u001b[0m |   \u001b[32m0.9535\u001b[0m | \u001b[31m0.4147\u001b[0m |     \u001b[31m0.4147\u001b[0m |       \u001b[31m0.4147\u001b[0m |  402.0000 | 1.00e-02 |    8.8812\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.20it/s]\n",
      "INFO:nlstruct:   61 |         \u001b[31m0.0929\u001b[0m |   \u001b[31m0.9264\u001b[0m | \u001b[31m0.2966\u001b[0m |     \u001b[31m0.2966\u001b[0m |       \u001b[31m0.2966\u001b[0m |  395.0000 | 1.00e-02 |    9.1362\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.22it/s]\n",
      "INFO:nlstruct:   62 |         \u001b[31m0.0886\u001b[0m |   \u001b[31m0.9221\u001b[0m | \u001b[31m0.4153\u001b[0m |     \u001b[31m0.4153\u001b[0m |       \u001b[31m0.4153\u001b[0m |  381.0000 | 1.00e-02 |    8.7761\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.16it/s]\n",
      "INFO:nlstruct:   63 |         \u001b[31m0.1238\u001b[0m |   \u001b[31m0.9015\u001b[0m | \u001b[31m0.4289\u001b[0m |     \u001b[31m0.4289\u001b[0m |       \u001b[31m0.4289\u001b[0m |  368.0000 | 1.00e-02 |    8.9398\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.21it/s]\n",
      "INFO:nlstruct:   64 |         \u001b[31m0.0949\u001b[0m |   \u001b[31m0.9197\u001b[0m | \u001b[31m0.4439\u001b[0m |     \u001b[31m0.4439\u001b[0m |       \u001b[31m0.4439\u001b[0m |  369.0000 | 1.00e-02 |    8.9515\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.17it/s]\n",
      "INFO:nlstruct:   65 |         \u001b[32m0.0514\u001b[0m |   \u001b[31m0.9448\u001b[0m | \u001b[31m0.4537\u001b[0m |     \u001b[31m0.4537\u001b[0m |       \u001b[31m0.4537\u001b[0m |  389.0000 | 1.00e-02 |    9.0332\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.20it/s]\n",
      "INFO:nlstruct:   66 |         \u001b[31m0.0635\u001b[0m |   \u001b[31m0.9469\u001b[0m | \u001b[31m0.2765\u001b[0m |     \u001b[31m0.2765\u001b[0m |       \u001b[31m0.2765\u001b[0m |  353.0000 | 1.00e-02 |    8.9266\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.16it/s]\n",
      "INFO:nlstruct:   67 |         \u001b[31m0.1250\u001b[0m |   \u001b[31m0.8999\u001b[0m | \u001b[31m0.3489\u001b[0m |     \u001b[31m0.3489\u001b[0m |       \u001b[31m0.3489\u001b[0m |  370.0000 | 1.00e-02 |    8.9106\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.18it/s]\n",
      "INFO:nlstruct:   68 |         \u001b[31m0.0937\u001b[0m |   \u001b[31m0.8924\u001b[0m | \u001b[31m0.0233\u001b[0m |     \u001b[31m0.0233\u001b[0m |       \u001b[31m0.0233\u001b[0m |  354.0000 | 1.00e-02 |   14.8061\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.21it/s]\n",
      "INFO:nlstruct:   69 |         \u001b[31m0.0576\u001b[0m |   \u001b[31m0.9248\u001b[0m | \u001b[31m0.3452\u001b[0m |     \u001b[31m0.3452\u001b[0m |       \u001b[31m0.3452\u001b[0m |  362.0000 | 1.00e-02 |    8.8269\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.19it/s]\n",
      "INFO:nlstruct:   70 |         \u001b[31m0.0938\u001b[0m |   \u001b[31m0.9093\u001b[0m | \u001b[31m0.2339\u001b[0m |     \u001b[31m0.2339\u001b[0m |       \u001b[31m0.2339\u001b[0m |  391.0000 | 1.00e-02 |    9.2047\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.17it/s]\n",
      "INFO:nlstruct:   71 |         \u001b[31m0.0715\u001b[0m |   \u001b[31m0.9386\u001b[0m | \u001b[31m0.3728\u001b[0m |     \u001b[31m0.3728\u001b[0m |       \u001b[31m0.3728\u001b[0m |  369.0000 | 1.00e-02 |    8.8099\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.20it/s]\n",
      "INFO:nlstruct:   72 |         \u001b[31m0.1005\u001b[0m |   \u001b[31m0.9258\u001b[0m | \u001b[32m0.4742\u001b[0m |     \u001b[32m0.4742\u001b[0m |       \u001b[32m0.4742\u001b[0m |  377.0000 | 1.00e-02 |    8.9468\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.21it/s]\n",
      "INFO:nlstruct:   73 |         \u001b[31m0.0686\u001b[0m |   \u001b[31m0.9393\u001b[0m | \u001b[31m0.3476\u001b[0m |     \u001b[31m0.3476\u001b[0m |       \u001b[31m0.3476\u001b[0m |  384.0000 | 1.00e-02 |    8.7491\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.12it/s]\n",
      "INFO:nlstruct:   74 |         \u001b[31m0.1003\u001b[0m |   \u001b[31m0.9355\u001b[0m | \u001b[31m0.4211\u001b[0m |     \u001b[31m0.4211\u001b[0m |       \u001b[31m0.4211\u001b[0m |  406.0000 | 1.00e-02 |    9.0415\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.21it/s]\n",
      "INFO:nlstruct:   75 |         \u001b[31m0.0550\u001b[0m |   \u001b[32m0.9578\u001b[0m | \u001b[31m0.4332\u001b[0m |     \u001b[31m0.4332\u001b[0m |       \u001b[31m0.4332\u001b[0m |  410.0000 | 1.00e-02 |    8.9408\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.21it/s]\n",
      "INFO:nlstruct:   76 |         \u001b[31m0.0620\u001b[0m |   \u001b[32m0.9603\u001b[0m | \u001b[31m0.4182\u001b[0m |     \u001b[31m0.4182\u001b[0m |       \u001b[31m0.4182\u001b[0m |  404.0000 | 1.00e-02 |    8.8620\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.20it/s]\n",
      "INFO:nlstruct:   77 |         \u001b[32m0.0393\u001b[0m |   \u001b[32m0.9638\u001b[0m | \u001b[31m0.4084\u001b[0m |     \u001b[31m0.4084\u001b[0m |       \u001b[31m0.4084\u001b[0m |  375.0000 | 1.00e-02 |    8.8560\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.15it/s]\n",
      "INFO:nlstruct:   78 |         \u001b[32m0.0371\u001b[0m |   \u001b[31m0.9562\u001b[0m | \u001b[31m0.4271\u001b[0m |     \u001b[31m0.4271\u001b[0m |       \u001b[31m0.4271\u001b[0m |  391.0000 | 1.00e-02 |    8.9659\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.18it/s]\n",
      "INFO:nlstruct:   79 |         \u001b[31m0.0554\u001b[0m |   \u001b[31m0.9452\u001b[0m | \u001b[31m0.3904\u001b[0m |     \u001b[31m0.3904\u001b[0m |       \u001b[31m0.3904\u001b[0m |  383.0000 | 1.00e-02 |    8.8774\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.19it/s]\n",
      "INFO:nlstruct:   80 |         \u001b[31m0.0620\u001b[0m |   \u001b[31m0.9289\u001b[0m | \u001b[31m0.4159\u001b[0m |     \u001b[31m0.4159\u001b[0m |       \u001b[31m0.4159\u001b[0m |  377.0000 | 1.00e-02 |    9.0214\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.18it/s]\n",
      "INFO:nlstruct:   81 |         \u001b[31m0.0460\u001b[0m |   \u001b[31m0.9610\u001b[0m | \u001b[31m0.4065\u001b[0m |     \u001b[31m0.4065\u001b[0m |       \u001b[31m0.4065\u001b[0m |  364.0000 | 1.00e-02 |    8.9812\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.18it/s]\n",
      "INFO:nlstruct:   82 |         \u001b[31m0.2649\u001b[0m |   \u001b[31m0.8962\u001b[0m | \u001b[31m0.3906\u001b[0m |     \u001b[31m0.3906\u001b[0m |       \u001b[31m0.3906\u001b[0m |  402.0000 | 1.00e-02 |    8.8472\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.16it/s]\n",
      "INFO:nlstruct:   83 |         \u001b[31m0.0575\u001b[0m |   \u001b[31m0.9517\u001b[0m | \u001b[31m0.4737\u001b[0m |     \u001b[31m0.4737\u001b[0m |       \u001b[31m0.4737\u001b[0m |  396.0000 | 1.00e-02 |    9.0007\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.18it/s]\n",
      "INFO:nlstruct:   84 |         \u001b[31m0.0549\u001b[0m |   \u001b[31m0.9523\u001b[0m | \u001b[31m0.4346\u001b[0m |     \u001b[31m0.4346\u001b[0m |       \u001b[31m0.4346\u001b[0m |  401.0000 | 1.00e-02 |    8.8517\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.19it/s]\n",
      "INFO:nlstruct:   85 |         \u001b[31m0.0409\u001b[0m |   \u001b[31m0.9623\u001b[0m | \u001b[31m0.4480\u001b[0m |     \u001b[31m0.4480\u001b[0m |       \u001b[31m0.4480\u001b[0m |  384.0000 | 1.00e-02 |    8.9439\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.21it/s]\n",
      "INFO:nlstruct:   86 |         \u001b[31m0.0377\u001b[0m |   \u001b[32m0.9733\u001b[0m | \u001b[31m0.4193\u001b[0m |     \u001b[31m0.4193\u001b[0m |       \u001b[31m0.4193\u001b[0m |  397.0000 | 1.00e-02 |    8.9611\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.20it/s]\n",
      "INFO:nlstruct:   87 |         \u001b[32m0.0208\u001b[0m |   \u001b[32m0.9777\u001b[0m | \u001b[31m0.4427\u001b[0m |     \u001b[31m0.4427\u001b[0m |       \u001b[31m0.4427\u001b[0m |  383.0000 | 1.00e-02 |    8.9812\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.20it/s]\n",
      "INFO:nlstruct:   88 |         \u001b[31m0.0427\u001b[0m |   \u001b[31m0.9701\u001b[0m | \u001b[31m0.4444\u001b[0m |     \u001b[31m0.4444\u001b[0m |       \u001b[31m0.4444\u001b[0m |  387.0000 | 1.00e-02 |    8.8481\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.15it/s]\n",
      "INFO:nlstruct:   89 |         \u001b[31m0.0436\u001b[0m |   \u001b[32m0.9796\u001b[0m | \u001b[31m0.3799\u001b[0m |     \u001b[31m0.3799\u001b[0m |       \u001b[31m0.3799\u001b[0m |  369.0000 | 1.00e-02 |    8.8969\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.21it/s]\n",
      "INFO:nlstruct:   90 |         \u001b[31m0.0864\u001b[0m |   \u001b[31m0.9298\u001b[0m | \u001b[31m0.3719\u001b[0m |     \u001b[31m0.3719\u001b[0m |       \u001b[31m0.3719\u001b[0m |  367.0000 | 1.00e-02 |    8.9158\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.22it/s]\n",
      "INFO:nlstruct:   91 |         \u001b[31m0.0550\u001b[0m |   \u001b[31m0.9545\u001b[0m | \u001b[31m0.3469\u001b[0m |     \u001b[31m0.3469\u001b[0m |       \u001b[31m0.3469\u001b[0m |  389.0000 | 1.00e-02 |    9.0737\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.25it/s]\n",
      "INFO:nlstruct:   92 |         \u001b[31m0.1014\u001b[0m |   \u001b[31m0.9398\u001b[0m | \u001b[31m0.3814\u001b[0m |     \u001b[31m0.3814\u001b[0m |       \u001b[31m0.3814\u001b[0m |  395.0000 | 1.00e-02 |    9.1763\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.24it/s]\n",
      "INFO:nlstruct:   93 |         \u001b[31m0.0880\u001b[0m |   \u001b[31m0.9007\u001b[0m | \u001b[31m0.3267\u001b[0m |     \u001b[31m0.3267\u001b[0m |       \u001b[31m0.3267\u001b[0m |  367.0000 | 1.00e-02 |    8.7077\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.23it/s]\n",
      "INFO:nlstruct:   94 |         \u001b[31m0.1852\u001b[0m |   \u001b[31m0.8651\u001b[0m | \u001b[31m0.3529\u001b[0m |     \u001b[31m0.3529\u001b[0m |       \u001b[31m0.3529\u001b[0m |  396.0000 | 1.00e-02 |    8.6823\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.19it/s]\n",
      "INFO:nlstruct:   95 |         \u001b[31m0.1140\u001b[0m |   \u001b[31m0.9130\u001b[0m | \u001b[31m0.4237\u001b[0m |     \u001b[31m0.4237\u001b[0m |       \u001b[31m0.4237\u001b[0m |  370.0000 | 1.00e-02 |    8.8566\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.22it/s]\n",
      "INFO:nlstruct:   96 |         \u001b[31m0.0955\u001b[0m |   \u001b[31m0.9300\u001b[0m | \u001b[31m0.4084\u001b[0m |     \u001b[31m0.4084\u001b[0m |       \u001b[31m0.4084\u001b[0m |  358.0000 | 1.00e-02 |    8.8134\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.25it/s]\n",
      "INFO:nlstruct:   97 |         \u001b[31m0.0415\u001b[0m |   \u001b[31m0.9545\u001b[0m | \u001b[31m0.4272\u001b[0m |     \u001b[31m0.4272\u001b[0m |       \u001b[31m0.4272\u001b[0m |  356.0000 | 1.00e-02 |    8.8289\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.23it/s]\n",
      "INFO:nlstruct:   98 |         \u001b[31m0.0674\u001b[0m |   \u001b[31m0.9492\u001b[0m | \u001b[31m0.4286\u001b[0m |     \u001b[31m0.4286\u001b[0m |       \u001b[31m0.4286\u001b[0m |  399.0000 | 1.00e-02 |    8.7101\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.18it/s]\n",
      "INFO:nlstruct:   99 |         \u001b[31m0.0315\u001b[0m |   \u001b[31m0.9633\u001b[0m | \u001b[31m0.4439\u001b[0m |     \u001b[31m0.4439\u001b[0m |       \u001b[31m0.4439\u001b[0m |  369.0000 | 1.00e-02 |    8.8448\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.18it/s]\n",
      "INFO:nlstruct:  100 |         \u001b[31m0.0289\u001b[0m |   \u001b[31m0.9755\u001b[0m | \u001b[31m0.3781\u001b[0m |     \u001b[31m0.3781\u001b[0m |       \u001b[31m0.3781\u001b[0m |  369.0000 | 1.00e-02 |    8.9445\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.24it/s]\n",
      "INFO:nlstruct:  101 |         \u001b[31m0.0420\u001b[0m |   \u001b[31m0.9739\u001b[0m | \u001b[31m0.4370\u001b[0m |     \u001b[31m0.4370\u001b[0m |       \u001b[31m0.4370\u001b[0m |  384.0000 | 1.00e-02 |    8.7791\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.23it/s]\n",
      "INFO:nlstruct:  102 |         \u001b[31m0.0335\u001b[0m |   \u001b[31m0.9687\u001b[0m | \u001b[31m0.4133\u001b[0m |     \u001b[31m0.4133\u001b[0m |       \u001b[31m0.4133\u001b[0m |  355.0000 | 1.00e-02 |    8.9066\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.23it/s]\n",
      "INFO:nlstruct:  103 |         \u001b[31m0.0536\u001b[0m |   \u001b[31m0.9668\u001b[0m | \u001b[31m0.4278\u001b[0m |     \u001b[31m0.4278\u001b[0m |       \u001b[31m0.4278\u001b[0m |  392.0000 | 1.00e-02 |    8.7044\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.18it/s]\n",
      "INFO:nlstruct:  104 |         \u001b[31m0.0307\u001b[0m |   \u001b[32m0.9827\u001b[0m | \u001b[31m0.4187\u001b[0m |     \u001b[31m0.4187\u001b[0m |       \u001b[31m0.4187\u001b[0m |  378.0000 | 1.00e-02 |    8.9370\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.19it/s]\n",
      "INFO:nlstruct:  105 |         \u001b[32m0.0201\u001b[0m |   \u001b[31m0.9821\u001b[0m | \u001b[31m0.3841\u001b[0m |     \u001b[31m0.3841\u001b[0m |       \u001b[31m0.3841\u001b[0m |  394.0000 | 1.00e-02 |    8.9384\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.18it/s]\n",
      "INFO:nlstruct:  106 |         \u001b[31m0.0440\u001b[0m |   \u001b[31m0.9572\u001b[0m | \u001b[31m0.4427\u001b[0m |     \u001b[31m0.4427\u001b[0m |       \u001b[31m0.4427\u001b[0m |  377.0000 | 1.00e-02 |    8.9329\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.17it/s]\n",
      "INFO:nlstruct:  107 |         \u001b[31m0.0436\u001b[0m |   \u001b[31m0.9529\u001b[0m | \u001b[31m0.4560\u001b[0m |     \u001b[31m0.4560\u001b[0m |       \u001b[31m0.4560\u001b[0m |  363.0000 | 1.00e-02 |    8.9813\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.18it/s]\n",
      "INFO:nlstruct:  108 |         \u001b[32m0.0187\u001b[0m |   \u001b[31m0.9800\u001b[0m | \u001b[31m0.4607\u001b[0m |     \u001b[31m0.4607\u001b[0m |       \u001b[31m0.4607\u001b[0m |  401.0000 | 1.00e-02 |    8.9271\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.17it/s]\n",
      "INFO:nlstruct:  109 |         \u001b[32m0.0118\u001b[0m |   \u001b[32m0.9866\u001b[0m | \u001b[32m0.4917\u001b[0m |     \u001b[32m0.4917\u001b[0m |       \u001b[32m0.4917\u001b[0m |  373.0000 | 1.00e-02 |    8.9733\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.14it/s]\n",
      "INFO:nlstruct:  110 |         \u001b[31m0.0235\u001b[0m |   \u001b[32m0.9880\u001b[0m | \u001b[31m0.4623\u001b[0m |     \u001b[31m0.4623\u001b[0m |       \u001b[31m0.4623\u001b[0m |  379.0000 | 1.00e-02 |    9.0183\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.14it/s]\n",
      "INFO:nlstruct:  111 |         \u001b[31m0.0177\u001b[0m |   \u001b[31m0.9785\u001b[0m | \u001b[31m0.4154\u001b[0m |     \u001b[31m0.4154\u001b[0m |       \u001b[31m0.4154\u001b[0m |  395.0000 | 1.00e-02 |    8.9351\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.17it/s]\n",
      "INFO:nlstruct:  112 |         \u001b[31m0.0488\u001b[0m |   \u001b[31m0.9765\u001b[0m | \u001b[31m0.4310\u001b[0m |     \u001b[31m0.4310\u001b[0m |       \u001b[31m0.4310\u001b[0m |  401.0000 | 1.00e-02 |    8.9105\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.40it/s]\n",
      "INFO:nlstruct:  113 |         \u001b[31m0.0440\u001b[0m |   \u001b[31m0.9704\u001b[0m | \u001b[31m0.4481\u001b[0m |     \u001b[31m0.4481\u001b[0m |       \u001b[31m0.4481\u001b[0m |  390.0000 | 1.00e-02 |    8.5594\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.40it/s]\n",
      "INFO:nlstruct:  114 |         \u001b[31m0.0254\u001b[0m |   \u001b[31m0.9737\u001b[0m | \u001b[31m0.4692\u001b[0m |     \u001b[31m0.4692\u001b[0m |       \u001b[31m0.4692\u001b[0m |  398.0000 | 1.00e-02 |    8.5384\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.40it/s]\n",
      "INFO:nlstruct:  115 |         \u001b[31m0.0558\u001b[0m |   \u001b[31m0.9683\u001b[0m | \u001b[31m0.4377\u001b[0m |     \u001b[31m0.4377\u001b[0m |       \u001b[31m0.4377\u001b[0m |  381.0000 | 1.00e-02 |    8.3963\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.41it/s]\n",
      "INFO:nlstruct:  116 |         \u001b[31m0.0231\u001b[0m |   \u001b[31m0.9754\u001b[0m | \u001b[31m0.4093\u001b[0m |     \u001b[31m0.4093\u001b[0m |       \u001b[31m0.4093\u001b[0m |  388.0000 | 1.00e-02 |    8.4524\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.37it/s]\n",
      "INFO:nlstruct:  117 |         \u001b[31m0.0167\u001b[0m |   \u001b[31m0.9859\u001b[0m | \u001b[31m0.4781\u001b[0m |     \u001b[31m0.4781\u001b[0m |       \u001b[31m0.4781\u001b[0m |  390.0000 | 1.00e-02 |    8.4780\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.21it/s]\n",
      "INFO:nlstruct:  118 |         \u001b[32m0.0101\u001b[0m |   \u001b[31m0.9852\u001b[0m | \u001b[31m0.3538\u001b[0m |     \u001b[31m0.3538\u001b[0m |       \u001b[31m0.3538\u001b[0m |  372.0000 | 1.00e-02 |    8.8751\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.24it/s]\n",
      "INFO:nlstruct:  119 |         \u001b[31m0.0277\u001b[0m |   \u001b[32m0.9898\u001b[0m | \u001b[31m0.4450\u001b[0m |     \u001b[31m0.4450\u001b[0m |       \u001b[31m0.4450\u001b[0m |  393.0000 | 1.00e-02 |    8.8127\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.24it/s]\n",
      "INFO:nlstruct:  120 |         \u001b[31m0.0128\u001b[0m |   \u001b[31m0.9879\u001b[0m | \u001b[31m0.4303\u001b[0m |     \u001b[31m0.4303\u001b[0m |       \u001b[31m0.4303\u001b[0m |  372.0000 | 1.00e-02 |    8.8534\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.23it/s]\n",
      "INFO:nlstruct:  121 |         \u001b[31m0.0164\u001b[0m |   \u001b[31m0.9864\u001b[0m | \u001b[31m0.4567\u001b[0m |     \u001b[31m0.4567\u001b[0m |       \u001b[31m0.4567\u001b[0m |  370.0000 | 1.00e-02 |    8.7939\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.26it/s]\n",
      "INFO:nlstruct:  122 |         \u001b[31m0.0289\u001b[0m |   \u001b[31m0.9866\u001b[0m | \u001b[31m0.4252\u001b[0m |     \u001b[31m0.4252\u001b[0m |       \u001b[31m0.4252\u001b[0m |  376.0000 | 1.00e-02 |    8.7920\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.21it/s]\n",
      "INFO:nlstruct:  123 |         \u001b[31m0.1379\u001b[0m |   \u001b[31m0.9315\u001b[0m | \u001b[31m0.3548\u001b[0m |     \u001b[31m0.3548\u001b[0m |       \u001b[31m0.3548\u001b[0m |  386.0000 | 1.00e-02 |    8.7767\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.21it/s]\n",
      "INFO:nlstruct:  124 |         \u001b[31m0.1472\u001b[0m |   \u001b[31m0.9164\u001b[0m | \u001b[31m0.4208\u001b[0m |     \u001b[31m0.4208\u001b[0m |       \u001b[31m0.4208\u001b[0m |  386.0000 | 1.00e-02 |    8.7665\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.23it/s]\n",
      "INFO:nlstruct:  125 |         \u001b[31m0.0448\u001b[0m |   \u001b[31m0.9412\u001b[0m | \u001b[31m0.2632\u001b[0m |     \u001b[31m0.2632\u001b[0m |       \u001b[31m0.2632\u001b[0m |  364.0000 | 1.00e-02 |    8.9263\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.20it/s]\n",
      "INFO:nlstruct:  126 |         \u001b[31m0.0554\u001b[0m |   \u001b[31m0.9455\u001b[0m | \u001b[31m0.3753\u001b[0m |     \u001b[31m0.3753\u001b[0m |       \u001b[31m0.3753\u001b[0m |  369.0000 | 1.00e-02 |    9.0263\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.24it/s]\n",
      "INFO:nlstruct:  127 |         \u001b[31m0.0563\u001b[0m |   \u001b[31m0.9571\u001b[0m | \u001b[31m0.4038\u001b[0m |     \u001b[31m0.4038\u001b[0m |       \u001b[31m0.4038\u001b[0m |  409.0000 | 1.00e-02 |    8.8834\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.22it/s]\n",
      "INFO:nlstruct:  128 |         \u001b[31m0.0231\u001b[0m |   \u001b[31m0.9818\u001b[0m | \u001b[31m0.3925\u001b[0m |     \u001b[31m0.3925\u001b[0m |       \u001b[31m0.3925\u001b[0m |  358.0000 | 1.00e-02 |    8.8682\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.23it/s]\n",
      "INFO:nlstruct:  129 |         \u001b[31m0.0659\u001b[0m |   \u001b[31m0.9391\u001b[0m | \u001b[31m0.3205\u001b[0m |     \u001b[31m0.3205\u001b[0m |       \u001b[31m0.3205\u001b[0m |  359.0000 | 1.00e-02 |    8.8746\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.20it/s]\n",
      "INFO:nlstruct:  130 |         \u001b[31m0.1881\u001b[0m |   \u001b[31m0.9154\u001b[0m | \u001b[31m0.0503\u001b[0m |     \u001b[31m0.0503\u001b[0m |       \u001b[31m0.0503\u001b[0m |  401.0000 | 1.00e-02 |    9.5902\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.22it/s]\n",
      "INFO:nlstruct:  131 |         \u001b[31m1.1373\u001b[0m |   \u001b[31m0.7092\u001b[0m | \u001b[31m0.0027\u001b[0m |     \u001b[31m0.0027\u001b[0m |       \u001b[31m0.0027\u001b[0m |  388.0000 | 1.00e-02 |   15.4736\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.21it/s]\n",
      "INFO:nlstruct:  132 |         \u001b[31m0.3912\u001b[0m |   \u001b[31m0.7303\u001b[0m | \u001b[31m0.1655\u001b[0m |     \u001b[31m0.1655\u001b[0m |       \u001b[31m0.1655\u001b[0m |  365.0000 | 1.00e-02 |    9.2905\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.20it/s]\n",
      "INFO:nlstruct:  133 |         \u001b[31m0.2304\u001b[0m |   \u001b[31m0.8268\u001b[0m | \u001b[31m0.3405\u001b[0m |     \u001b[31m0.3405\u001b[0m |       \u001b[31m0.3405\u001b[0m |  384.0000 | 1.00e-02 |    8.8498\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.21it/s]\n",
      "INFO:nlstruct:  134 |         \u001b[31m0.1271\u001b[0m |   \u001b[31m0.8777\u001b[0m | \u001b[31m0.4066\u001b[0m |     \u001b[31m0.4066\u001b[0m |       \u001b[31m0.4066\u001b[0m |  373.0000 | 1.00e-02 |    8.7777\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.20it/s]\n",
      "INFO:nlstruct:  135 |         \u001b[31m0.0514\u001b[0m |   \u001b[31m0.9351\u001b[0m | \u001b[31m0.4658\u001b[0m |     \u001b[31m0.4658\u001b[0m |       \u001b[31m0.4658\u001b[0m |  383.0000 | 1.00e-02 |    8.8795\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.20it/s]\n",
      "INFO:nlstruct:  136 |         \u001b[31m0.0239\u001b[0m |   \u001b[31m0.9777\u001b[0m | \u001b[31m0.4000\u001b[0m |     \u001b[31m0.4000\u001b[0m |       \u001b[31m0.4000\u001b[0m |  384.0000 | 1.00e-02 |    8.8022\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.23it/s]\n",
      "INFO:nlstruct:  137 |         \u001b[31m0.0352\u001b[0m |   \u001b[31m0.9668\u001b[0m | \u001b[31m0.3155\u001b[0m |     \u001b[31m0.3155\u001b[0m |       \u001b[31m0.3155\u001b[0m |  396.0000 | 1.00e-02 |    8.7947\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.23it/s]\n",
      "INFO:nlstruct:  138 |         \u001b[31m0.0782\u001b[0m |   \u001b[31m0.9446\u001b[0m | \u001b[31m0.4293\u001b[0m |     \u001b[31m0.4293\u001b[0m |       \u001b[31m0.4293\u001b[0m |  383.0000 | 1.00e-02 |    8.8831\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.24it/s]\n",
      "INFO:nlstruct:  139 |         \u001b[31m0.0399\u001b[0m |   \u001b[31m0.9741\u001b[0m | \u001b[31m0.4065\u001b[0m |     \u001b[31m0.4065\u001b[0m |       \u001b[31m0.4065\u001b[0m |  368.0000 | 1.00e-02 |    8.7722\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.24it/s]\n",
      "INFO:nlstruct:  140 |         \u001b[31m0.0499\u001b[0m |   \u001b[31m0.9671\u001b[0m | \u001b[31m0.4415\u001b[0m |     \u001b[31m0.4415\u001b[0m |       \u001b[31m0.4415\u001b[0m |  352.0000 | 1.00e-02 |    8.7444\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.22it/s]\n",
      "INFO:nlstruct:  141 |         \u001b[31m0.0139\u001b[0m |   \u001b[32m0.9921\u001b[0m | \u001b[31m0.4658\u001b[0m |     \u001b[31m0.4658\u001b[0m |       \u001b[31m0.4658\u001b[0m |  379.0000 | 1.00e-02 |    8.8098\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.20it/s]\n",
      "INFO:nlstruct:  142 |         \u001b[31m0.0222\u001b[0m |   \u001b[31m0.9767\u001b[0m | \u001b[31m0.4218\u001b[0m |     \u001b[31m0.4218\u001b[0m |       \u001b[31m0.4218\u001b[0m |  387.0000 | 1.00e-02 |    8.9579\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.20it/s]\n",
      "INFO:nlstruct:  143 |         \u001b[31m0.4041\u001b[0m |   \u001b[31m0.8698\u001b[0m | \u001b[31m0.3970\u001b[0m |     \u001b[31m0.3970\u001b[0m |       \u001b[31m0.3970\u001b[0m |  369.0000 | 1.00e-02 |    8.8382\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.23it/s]\n",
      "INFO:nlstruct:  144 |         \u001b[31m0.0260\u001b[0m |   \u001b[31m0.9775\u001b[0m | \u001b[31m0.4426\u001b[0m |     \u001b[31m0.4426\u001b[0m |       \u001b[31m0.4426\u001b[0m |  378.0000 | 1.00e-02 |    8.7753\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.24it/s]\n",
      "INFO:nlstruct:  145 |         \u001b[31m0.0280\u001b[0m |   \u001b[31m0.9791\u001b[0m | \u001b[31m0.3846\u001b[0m |     \u001b[31m0.3846\u001b[0m |       \u001b[31m0.3846\u001b[0m |  361.0000 | 1.00e-02 |    8.8274\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.23it/s]\n",
      "INFO:nlstruct:  146 |         \u001b[31m0.2302\u001b[0m |   \u001b[31m0.8952\u001b[0m | \u001b[31m0.4456\u001b[0m |     \u001b[31m0.4456\u001b[0m |       \u001b[31m0.4456\u001b[0m |  387.0000 | 1.00e-02 |    8.7915\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.13it/s]\n",
      "INFO:nlstruct:  147 |         \u001b[31m0.2103\u001b[0m |   \u001b[31m0.9170\u001b[0m | \u001b[31m0.2803\u001b[0m |     \u001b[31m0.2803\u001b[0m |       \u001b[31m0.2803\u001b[0m |  391.0000 | 1.00e-02 |    9.3711\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.18it/s]\n",
      "INFO:nlstruct:  148 |         \u001b[31m0.1042\u001b[0m |   \u001b[31m0.9339\u001b[0m | \u001b[31m0.4433\u001b[0m |     \u001b[31m0.4433\u001b[0m |       \u001b[31m0.4433\u001b[0m |  373.0000 | 1.00e-02 |    8.8760\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.15it/s]\n",
      "INFO:nlstruct:  149 |         \u001b[31m0.0771\u001b[0m |   \u001b[31m0.9433\u001b[0m | \u001b[31m0.4143\u001b[0m |     \u001b[31m0.4143\u001b[0m |       \u001b[31m0.4143\u001b[0m |  394.0000 | 1.00e-02 |    9.1989\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.19it/s]\n",
      "INFO:nlstruct:  150 |         \u001b[31m0.0314\u001b[0m |   \u001b[31m0.9651\u001b[0m | \u001b[31m0.4479\u001b[0m |     \u001b[31m0.4479\u001b[0m |       \u001b[31m0.4479\u001b[0m |  374.0000 | 1.00e-02 |    8.8391\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.15it/s]\n",
      "INFO:nlstruct:  151 |         \u001b[31m0.0709\u001b[0m |   \u001b[31m0.9464\u001b[0m | \u001b[31m0.3835\u001b[0m |     \u001b[31m0.3835\u001b[0m |       \u001b[31m0.3835\u001b[0m |  397.0000 | 1.00e-02 |    9.1415\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.16it/s]\n",
      "INFO:nlstruct:  152 |         \u001b[31m0.1078\u001b[0m |   \u001b[31m0.9314\u001b[0m | \u001b[31m0.3629\u001b[0m |     \u001b[31m0.3629\u001b[0m |       \u001b[31m0.3629\u001b[0m |  375.0000 | 1.00e-02 |    9.0408\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.23it/s]\n",
      "INFO:nlstruct:  153 |         \u001b[31m0.1224\u001b[0m |   \u001b[31m0.9424\u001b[0m | \u001b[31m0.4067\u001b[0m |     \u001b[31m0.4067\u001b[0m |       \u001b[31m0.4067\u001b[0m |  400.0000 | 1.00e-02 |    8.7986\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.17it/s]\n",
      "INFO:nlstruct:  154 |         \u001b[31m0.0719\u001b[0m |   \u001b[31m0.9495\u001b[0m | \u001b[31m0.3967\u001b[0m |     \u001b[31m0.3967\u001b[0m |       \u001b[31m0.3967\u001b[0m |  389.0000 | 1.00e-02 |    8.9540\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.15it/s]\n",
      "INFO:nlstruct:  155 |         \u001b[31m0.0355\u001b[0m |   \u001b[31m0.9711\u001b[0m | \u001b[31m0.3733\u001b[0m |     \u001b[31m0.3733\u001b[0m |       \u001b[31m0.3733\u001b[0m |  383.0000 | 1.00e-02 |    8.8957\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.18it/s]\n",
      "INFO:nlstruct:  156 |         \u001b[31m0.0884\u001b[0m |   \u001b[31m0.9402\u001b[0m | \u001b[31m0.4821\u001b[0m |     \u001b[31m0.4821\u001b[0m |       \u001b[31m0.4821\u001b[0m |  375.0000 | 1.00e-02 |    8.8559\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.23it/s]\n",
      "INFO:nlstruct:  157 |         \u001b[31m0.0492\u001b[0m |   \u001b[31m0.9749\u001b[0m | \u001b[31m0.4286\u001b[0m |     \u001b[31m0.4286\u001b[0m |       \u001b[31m0.4286\u001b[0m |  378.0000 | 1.00e-02 |    8.8563\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.21it/s]\n",
      "INFO:nlstruct:  158 |         \u001b[31m0.0412\u001b[0m |   \u001b[31m0.9574\u001b[0m | \u001b[31m0.4818\u001b[0m |     \u001b[31m0.4818\u001b[0m |       \u001b[31m0.4818\u001b[0m |  378.0000 | 1.00e-02 |    8.8368\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.19it/s]\n",
      "INFO:nlstruct:  159 |         \u001b[31m0.0425\u001b[0m |   \u001b[31m0.9605\u001b[0m | \u001b[31m0.4504\u001b[0m |     \u001b[31m0.4504\u001b[0m |       \u001b[31m0.4504\u001b[0m |  356.0000 | 1.00e-02 |    8.9566\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.21it/s]\n",
      "INFO:nlstruct:  160 |         \u001b[31m0.0157\u001b[0m |   \u001b[31m0.9825\u001b[0m | \u001b[31m0.4450\u001b[0m |     \u001b[31m0.4450\u001b[0m |       \u001b[31m0.4450\u001b[0m |  399.0000 | 1.00e-02 |    8.8681\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.18it/s]\n",
      "INFO:nlstruct:  161 |         \u001b[32m0.0083\u001b[0m |   \u001b[32m0.9949\u001b[0m | \u001b[31m0.4738\u001b[0m |     \u001b[31m0.4738\u001b[0m |       \u001b[31m0.4738\u001b[0m |  394.0000 | 1.00e-02 |    8.9437\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.18it/s]\n",
      "INFO:nlstruct:  162 |         \u001b[31m0.0102\u001b[0m |   \u001b[31m0.9866\u001b[0m | \u001b[31m0.4755\u001b[0m |     \u001b[31m0.4755\u001b[0m |       \u001b[31m0.4755\u001b[0m |  374.0000 | 1.00e-02 |    8.9004\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.14it/s]\n",
      "INFO:nlstruct:  163 |         \u001b[31m0.0169\u001b[0m |   \u001b[31m0.9917\u001b[0m | \u001b[31m0.4600\u001b[0m |     \u001b[31m0.4600\u001b[0m |       \u001b[31m0.4600\u001b[0m |  362.0000 | 1.00e-02 |    9.0108\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.14it/s]\n",
      "INFO:nlstruct:  164 |         \u001b[31m0.0160\u001b[0m |   \u001b[31m0.9894\u001b[0m | \u001b[31m0.4812\u001b[0m |     \u001b[31m0.4812\u001b[0m |       \u001b[31m0.4812\u001b[0m |  380.0000 | 1.00e-02 |    9.0412\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.15it/s]\n",
      "INFO:nlstruct:  165 |         \u001b[31m0.0197\u001b[0m |   \u001b[31m0.9878\u001b[0m | \u001b[31m0.4071\u001b[0m |     \u001b[31m0.4071\u001b[0m |       \u001b[31m0.4071\u001b[0m |  409.0000 | 1.00e-02 |    8.8847\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.15it/s]\n",
      "INFO:nlstruct:  166 |         \u001b[31m0.0120\u001b[0m |   \u001b[31m0.9896\u001b[0m | \u001b[31m0.4798\u001b[0m |     \u001b[31m0.4798\u001b[0m |       \u001b[31m0.4798\u001b[0m |  387.0000 | 1.00e-02 |    8.9783\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.14it/s]\n",
      "INFO:nlstruct:  167 |         \u001b[31m0.0431\u001b[0m |   \u001b[31m0.9782\u001b[0m | \u001b[31m0.4752\u001b[0m |     \u001b[31m0.4752\u001b[0m |       \u001b[31m0.4752\u001b[0m |  391.0000 | 1.00e-02 |    9.0378\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.12it/s]\n",
      "INFO:nlstruct:  168 |         \u001b[32m0.0055\u001b[0m |   \u001b[32m0.9973\u001b[0m | \u001b[31m0.4790\u001b[0m |     \u001b[31m0.4790\u001b[0m |       \u001b[31m0.4790\u001b[0m |  373.0000 | 1.00e-02 |    9.0767\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.15it/s]\n",
      "INFO:nlstruct:  169 |         \u001b[32m0.0047\u001b[0m |   \u001b[31m0.9937\u001b[0m | \u001b[32m0.5150\u001b[0m |     \u001b[32m0.5150\u001b[0m |       \u001b[32m0.5150\u001b[0m |  395.0000 | 1.00e-02 |    9.0124\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.14it/s]\n",
      "INFO:nlstruct:  170 |         \u001b[31m0.0129\u001b[0m |   \u001b[31m0.9880\u001b[0m | \u001b[31m0.4612\u001b[0m |     \u001b[31m0.4612\u001b[0m |       \u001b[31m0.4612\u001b[0m |  375.0000 | 1.00e-02 |    9.0109\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.16it/s]\n",
      "INFO:nlstruct:  171 |         \u001b[31m0.0160\u001b[0m |   \u001b[31m0.9949\u001b[0m | \u001b[31m0.4384\u001b[0m |     \u001b[31m0.4384\u001b[0m |       \u001b[31m0.4384\u001b[0m |  396.0000 | 1.00e-02 |    8.8805\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.16it/s]\n",
      "INFO:nlstruct:  172 |         \u001b[31m0.0175\u001b[0m |   \u001b[31m0.9918\u001b[0m | \u001b[31m0.4751\u001b[0m |     \u001b[31m0.4751\u001b[0m |       \u001b[31m0.4751\u001b[0m |  367.0000 | 1.00e-02 |    8.9830\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.13it/s]\n",
      "INFO:nlstruct:  173 |         \u001b[31m0.0144\u001b[0m |   \u001b[31m0.9840\u001b[0m | \u001b[31m0.4903\u001b[0m |     \u001b[31m0.4903\u001b[0m |       \u001b[31m0.4903\u001b[0m |  377.0000 | 1.00e-02 |    9.0568\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.14it/s]\n",
      "INFO:nlstruct:  174 |         \u001b[32m0.0037\u001b[0m |   \u001b[31m0.9959\u001b[0m | \u001b[31m0.4987\u001b[0m |     \u001b[31m0.4987\u001b[0m |       \u001b[31m0.4987\u001b[0m |  364.0000 | 1.00e-02 |    8.9761\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.16it/s]\n",
      "INFO:nlstruct:  175 |         \u001b[31m0.0043\u001b[0m |   \u001b[32m0.9973\u001b[0m | \u001b[31m0.4757\u001b[0m |     \u001b[31m0.4757\u001b[0m |       \u001b[31m0.4757\u001b[0m |  373.0000 | 1.00e-02 |    8.9547\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.16it/s]\n",
      "INFO:nlstruct:  176 |         \u001b[31m0.0095\u001b[0m |   \u001b[31m0.9951\u001b[0m | \u001b[31m0.3925\u001b[0m |     \u001b[31m0.3925\u001b[0m |       \u001b[31m0.3925\u001b[0m |  408.0000 | 1.00e-02 |    9.1149\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.20it/s]\n",
      "INFO:nlstruct:  177 |         \u001b[31m0.0452\u001b[0m |   \u001b[31m0.9766\u001b[0m | \u001b[31m0.3302\u001b[0m |     \u001b[31m0.3302\u001b[0m |       \u001b[31m0.3302\u001b[0m |  383.0000 | 1.00e-02 |    8.7912\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.19it/s]\n",
      "INFO:nlstruct:  178 |         \u001b[31m0.0415\u001b[0m |   \u001b[31m0.9542\u001b[0m | \u001b[31m0.1388\u001b[0m |     \u001b[31m0.1388\u001b[0m |       \u001b[31m0.1388\u001b[0m |  369.0000 | 1.00e-02 |    9.5284\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.15it/s]\n",
      "INFO:nlstruct:  179 |         \u001b[31m0.9446\u001b[0m |   \u001b[31m0.7967\u001b[0m | \u001b[31m0.4336\u001b[0m |     \u001b[31m0.4336\u001b[0m |       \u001b[31m0.4336\u001b[0m |  388.0000 | 1.00e-02 |    9.1129\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.15it/s]\n",
      "INFO:nlstruct:  180 |         \u001b[31m0.1001\u001b[0m |   \u001b[31m0.9443\u001b[0m | \u001b[31m0.4012\u001b[0m |     \u001b[31m0.4012\u001b[0m |       \u001b[31m0.4012\u001b[0m |  396.0000 | 1.00e-02 |    8.8636\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.19it/s]\n",
      "INFO:nlstruct:  181 |         \u001b[31m0.0648\u001b[0m |   \u001b[31m0.9380\u001b[0m | \u001b[31m0.4098\u001b[0m |     \u001b[31m0.4098\u001b[0m |       \u001b[31m0.4098\u001b[0m |  372.0000 | 1.00e-02 |    8.9833\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.19it/s]\n",
      "INFO:nlstruct:  182 |         \u001b[31m0.0513\u001b[0m |   \u001b[31m0.9583\u001b[0m | \u001b[31m0.4104\u001b[0m |     \u001b[31m0.4104\u001b[0m |       \u001b[31m0.4104\u001b[0m |  385.0000 | 1.00e-02 |    8.8400\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.16it/s]\n",
      "INFO:nlstruct:  183 |         \u001b[31m0.0143\u001b[0m |   \u001b[31m0.9838\u001b[0m | \u001b[31m0.4742\u001b[0m |     \u001b[31m0.4742\u001b[0m |       \u001b[31m0.4742\u001b[0m |  370.0000 | 1.00e-02 |    8.9968\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.16it/s]\n",
      "INFO:nlstruct:  184 |         \u001b[31m0.0316\u001b[0m |   \u001b[31m0.9791\u001b[0m | \u001b[31m0.4491\u001b[0m |     \u001b[31m0.4491\u001b[0m |       \u001b[31m0.4491\u001b[0m |  384.0000 | 1.00e-02 |    8.9265\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.14it/s]\n",
      "INFO:nlstruct:  185 |         \u001b[31m0.0242\u001b[0m |   \u001b[31m0.9870\u001b[0m | \u001b[31m0.4730\u001b[0m |     \u001b[31m0.4730\u001b[0m |       \u001b[31m0.4730\u001b[0m |  386.0000 | 1.00e-02 |    9.0030\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.16it/s]\n",
      "INFO:nlstruct:  186 |         \u001b[31m0.0093\u001b[0m |   \u001b[31m0.9935\u001b[0m | \u001b[31m0.4296\u001b[0m |     \u001b[31m0.4296\u001b[0m |       \u001b[31m0.4296\u001b[0m |  387.0000 | 1.00e-02 |    8.9881\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.15it/s]\n",
      "INFO:nlstruct:  187 |         \u001b[31m0.0149\u001b[0m |   \u001b[31m0.9860\u001b[0m | \u001b[31m0.4083\u001b[0m |     \u001b[31m0.4083\u001b[0m |       \u001b[31m0.4083\u001b[0m |  393.0000 | 1.00e-02 |    8.9717\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.15it/s]\n",
      "INFO:nlstruct:  188 |         \u001b[31m0.0213\u001b[0m |   \u001b[31m0.9895\u001b[0m | \u001b[31m0.4511\u001b[0m |     \u001b[31m0.4511\u001b[0m |       \u001b[31m0.4511\u001b[0m |  381.0000 | 1.00e-02 |    8.9091\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.16it/s]\n",
      "INFO:nlstruct:  189 |         \u001b[31m0.0773\u001b[0m |   \u001b[31m0.9529\u001b[0m | \u001b[31m0.3267\u001b[0m |     \u001b[31m0.3267\u001b[0m |       \u001b[31m0.3267\u001b[0m |  372.0000 | 1.00e-02 |    9.0433\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.14it/s]\n",
      "INFO:nlstruct:  190 |         \u001b[31m0.0493\u001b[0m |   \u001b[31m0.9578\u001b[0m | \u001b[31m0.3165\u001b[0m |     \u001b[31m0.3165\u001b[0m |       \u001b[31m0.3165\u001b[0m |  377.0000 | 1.00e-02 |    8.8436\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.18it/s]\n",
      "INFO:nlstruct:  191 |         \u001b[31m0.0541\u001b[0m |   \u001b[31m0.9520\u001b[0m | \u001b[31m0.3595\u001b[0m |     \u001b[31m0.3595\u001b[0m |       \u001b[31m0.3595\u001b[0m |  380.0000 | 1.00e-02 |    8.8533\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.19it/s]\n",
      "INFO:nlstruct:  192 |         \u001b[31m0.0229\u001b[0m |   \u001b[31m0.9763\u001b[0m | \u001b[31m0.3398\u001b[0m |     \u001b[31m0.3398\u001b[0m |       \u001b[31m0.3398\u001b[0m |  402.0000 | 1.00e-02 |    8.9391\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.17it/s]\n",
      "INFO:nlstruct:  193 |         \u001b[31m0.0252\u001b[0m |   \u001b[31m0.9856\u001b[0m | \u001b[31m0.4246\u001b[0m |     \u001b[31m0.4246\u001b[0m |       \u001b[31m0.4246\u001b[0m |  384.0000 | 1.00e-02 |    8.9923\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.19it/s]\n",
      "INFO:nlstruct:  194 |         \u001b[31m0.0134\u001b[0m |   \u001b[31m0.9858\u001b[0m | \u001b[31m0.3832\u001b[0m |     \u001b[31m0.3832\u001b[0m |       \u001b[31m0.3832\u001b[0m |  386.0000 | 1.00e-02 |    8.9875\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.22it/s]\n",
      "INFO:nlstruct:  195 |         \u001b[31m0.0271\u001b[0m |   \u001b[31m0.9841\u001b[0m | \u001b[31m0.3214\u001b[0m |     \u001b[31m0.3214\u001b[0m |       \u001b[31m0.3214\u001b[0m |  409.0000 | 1.00e-02 |    8.9585\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.39it/s]\n",
      "INFO:nlstruct:  196 |         \u001b[31m0.0212\u001b[0m |   \u001b[31m0.9806\u001b[0m | \u001b[31m0.4271\u001b[0m |     \u001b[31m0.4271\u001b[0m |       \u001b[31m0.4271\u001b[0m |  389.0000 | 1.00e-02 |    8.6554\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.22it/s]\n",
      "INFO:nlstruct:  197 |         \u001b[31m0.0173\u001b[0m |   \u001b[31m0.9935\u001b[0m | \u001b[31m0.4519\u001b[0m |     \u001b[31m0.4519\u001b[0m |       \u001b[31m0.4519\u001b[0m |  383.0000 | 1.00e-02 |    8.9759\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.39it/s]\n",
      "INFO:nlstruct:  198 |         \u001b[31m0.0257\u001b[0m |   \u001b[31m0.9807\u001b[0m | \u001b[31m0.3544\u001b[0m |     \u001b[31m0.3544\u001b[0m |       \u001b[31m0.3544\u001b[0m |  390.0000 | 1.00e-02 |    8.3204\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.23it/s]\n",
      "INFO:nlstruct:  199 |         \u001b[31m0.0301\u001b[0m |   \u001b[31m0.9821\u001b[0m | \u001b[31m0.4552\u001b[0m |     \u001b[31m0.4552\u001b[0m |       \u001b[31m0.4552\u001b[0m |  391.0000 | 1.00e-02 |    8.7448\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.23it/s]\n",
      "INFO:nlstruct:  200 |         \u001b[31m0.0235\u001b[0m |   \u001b[31m0.9739\u001b[0m | \u001b[31m0.4298\u001b[0m |     \u001b[31m0.4298\u001b[0m |       \u001b[31m0.4298\u001b[0m |  386.0000 | 1.00e-02 |    8.7024\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "from tqdm import tqdm\n",
    "\n",
    "from custom_bert import CustomBertModel\n",
    "from transformers import AdamW, BertModel\n",
    "\n",
    "from tqdm import tqdm\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from nlstruct.environment import get_cache\n",
    "from nlstruct.utils import evaluating, torch_global as tg, freeze\n",
    "from nlstruct.scoring import compute_metrics, merge_pred_and_gold\n",
    "from nlstruct.train import make_optimizer_and_schedules, run_optimization, seed_all\n",
    "from nlstruct.train.schedule import ScaleOnPlateauSchedule, LinearSchedule, ConstantSchedule\n",
    "    \n",
    "device = torch.device('cuda:0')\n",
    "tg.set_device(device)\n",
    "all_preds = []\n",
    "histories = []\n",
    "\n",
    "# To release gpu memory before allocating new parameters for a new model\n",
    "# A better idea would be to run xp in a function, so that all variables are released when exiting the fn\n",
    "# but this way we can debug after this cell if something goes wrong\n",
    "if \"all_nets\" in globals(): del all_nets\n",
    "if \"optim\" in globals(): del optim, \n",
    "if \"schedules\" in globals(): del schedules\n",
    "if \"final_schedule\" in globals(): del final_schedule\n",
    "if \"state\" in globals(): del state\n",
    "    \n",
    "# Hyperparameter search\n",
    "for layer, hidden_dim, scheme, seed, lr, bert_lr, n_schedules, dropout in [\n",
    "    (3, 1024 if \"large\" in bert_name else 768, \"bioul\", 12,  1e-2, 4e-5, 1, 0.1),\n",
    "]:\n",
    "    print(layer, hidden_dim, scheme, seed, lr, bert_lr, n_schedules, dropout)\n",
    "    #seed = 123456\n",
    "    seed_all(seed) # /!\\ Super important to enable reproducibility\n",
    "\n",
    "    tag_dim = 1024 if \"large\" in bert_name else 768#768\n",
    "    max_grad_norm = 5.\n",
    "    #lr = 1e-3\n",
    "    #bert_lr = 6e-5\n",
    "    tags_lr = bert_lr\n",
    "    bert_weight_decay = 0.0000\n",
    "    batch_size = 128\n",
    "    random_perm=True\n",
    "    observed_zone_sizes=None\n",
    "    n_per_zone = \"uniform\"\n",
    "    n_freeze = layer + 2 #4\n",
    "    custom_embeds_layer_index = 19 if \"large\" in bert_name else 11  #layer#2\n",
    "    #hidden_dim = 256\n",
    "    bert_dropout = 0.1\n",
    "    top_dropout = dropout\n",
    "\n",
    "    ner_net = NERNet(\n",
    "            n_tokens=len(vocs[\"token\"]),\n",
    "            token_dim=1024 if \"large\" in bert_name else 768,#768,\n",
    "            n_labels=len(vocs[\"ner_label\"]),\n",
    "            embeddings=CustomBertModel.from_pretrained(bert_name, custom_embeds_layer_index=custom_embeds_layer_index),\n",
    "\n",
    "            dropout=top_dropout,\n",
    "            hidden_dim=hidden_dim,\n",
    "            tag_scheme=scheme,\n",
    "            metric='linear') # cosine might be better but looks less stable, oddly,\n",
    "    all_nets = torch.nn.ModuleDict({\n",
    "        \"ner_net\": ner_net,\n",
    "        \"tag_embeddings\": torch.nn.Embedding(ner_net.crf.num_tags - 1, tag_dim),\n",
    "    }).to(device=tg.device)\n",
    "    del ner_net\n",
    "\n",
    "    for module in all_nets[\"ner_net\"].embeddings.modules():\n",
    "        if isinstance(module, torch.nn.Dropout):\n",
    "            module.p = bert_dropout\n",
    "    all_nets.train()\n",
    "\n",
    "    # Define the optimizer, maybe multiple learning rate / schedules per parameters groups\n",
    "    optim, schedules = make_optimizer_and_schedules(all_nets, AdamW, {\n",
    "        \"lr\": [\n",
    "                               (lr,    bert_lr,    bert_lr,    tags_lr),\n",
    "            (ConstantSchedule, (lr,    bert_lr,    bert_lr,    tags_lr),    15),\n",
    "            (ConstantSchedule, (lr/4,  bert_lr/4,  bert_lr/4,  tags_lr/4),  15),\n",
    "            (ConstantSchedule, (lr/16, bert_lr/16, bert_lr/16, tags_lr/16), 10),\n",
    "            (ConstantSchedule, (lr/64, bert_lr/64, bert_lr/64, tags_lr/64), 10),\n",
    "        ][:n_schedules+1],\n",
    "    }, [\n",
    "        \"(?!ner_net\\.embeddings\\.|tag_embeddings\\.).*\",\n",
    "        \"ner_net\\.embeddings\\..*(bias|LayerNorm\\.weight)\",\n",
    "        \"ner_net\\.embeddings\\..*(?!bias|LayerNorm\\.weight)\",\n",
    "        \"tag_embeddings\\..*\",\n",
    "    ], num_iter_per_epoch=(len(train_batcher) + 1) / batch_size)\n",
    "    final_schedule = ScaleOnPlateauSchedule('lr', optim, patience=4, factor=0.25, verbose=True, mode='max')\n",
    "\n",
    "    # Freeze some bert layers \n",
    "    # - n_freeze = 0 to freeze nothing\n",
    "    # - n_freeze = 1 to freeze word embeddings / position embeddings / ...\n",
    "    # - n_freeze = 2..13 to freeze the first, second ... 12th layer of bert\n",
    "    for name, param in all_nets.named_parameters():\n",
    "        match = re.search(\"\\.(\\d+)\\.\", name)\n",
    "        if match and int(match.group(1)) < n_freeze - 1:\n",
    "            freeze([param])\n",
    "    if n_freeze > 0:\n",
    "        if hasattr(all_nets['ner_net'].embeddings, 'embeddings'):\n",
    "            freeze(all_nets['ner_net'].embeddings.embeddings)\n",
    "        else:\n",
    "            freeze(all_nets['ner_net'].embeddings)\n",
    "\n",
    "    with_tqdm = True\n",
    "    state = {\"all_nets\": all_nets, \"optim\": optim, \"schedules\": schedules, \"final_schedule\": final_schedule}  # all we need to restart the training from a given epoch\n",
    "\n",
    "    def run_epoch():\n",
    "        pred_batches = []\n",
    "        gold_batches = []\n",
    "\n",
    "        total_train_ner_loss = 0\n",
    "        total_train_acc = 0\n",
    "        total_train_ner_size = 0\n",
    "\n",
    "        n_mentions = len(train_batcher[\"mention\"])\n",
    "        n_matched_mentions = 0\n",
    "        n_target_mentions = 0\n",
    "        n_observed_mentions = 0\n",
    "\n",
    "        with tqdm(train_batcher['sentence'].dataloader(batch_size=batch_size, shuffle=True, sparse_sort_on=\"token_mask\", device=device), disable=not with_tqdm) as bar:\n",
    "            for batch_i, batch in enumerate(bar):\n",
    "                optim.zero_grad()\n",
    "\n",
    "                # Shuffle and split mentions in each zone between observed and target\n",
    "                target_mentions, observed_mentions, zone_target_mentions, target_mask = split_zone_mentions(\n",
    "                    batch,\n",
    "                    random_perm=random_perm,\n",
    "                    observed_zone_sizes=observed_zone_sizes,\n",
    "                )\n",
    "                n_target_mentions += len(target_mentions)\n",
    "                n_observed_mentions += len(observed_mentions)\n",
    "\n",
    "                # Compute the tokens label tag embeddings of the observed (maybe overlapping) mentions\n",
    "                feature_tags = all_nets[\"ner_net\"].crf.spans_to_tags(\n",
    "                    torch.arange(len(observed_mentions), device=observed_mentions.device),\n",
    "                    batch[\"mention\", \"begin\"][observed_mentions], \n",
    "                    batch[\"mention\", \"end\"][observed_mentions], \n",
    "                    batch[\"mention\", \"ner_label\"][observed_mentions], \n",
    "                    n_tokens=batch[\"sentence\", \"token\"].shape[1],\n",
    "                    n_samples=len(observed_mentions),\n",
    "                )\n",
    "                tag_mention, tag_positions = feature_tags.nonzero(as_tuple=True)\n",
    "                tag_sentence = batch[\"zone\", \"@sentence_id\"][batch[\"mention\", \"@zone_id\"]][observed_mentions][tag_mention]\n",
    "                tag_values = feature_tags[tag_mention, tag_positions]\n",
    "                tag_embeds = torch.zeros(*batch[\"sentence\", \"token\"].shape[:2], tag_dim, device=tg.device).view(-1, tag_dim).index_add_(\n",
    "                    dim=0,\n",
    "                    index=tag_sentence * batch[\"sentence\", \"token\"].shape[1] + tag_positions, \n",
    "                    source=all_nets[\"tag_embeddings\"].weight[tag_values-1]).view(*batch[\"sentence\", \"token\"].shape[:2], tag_dim)\n",
    "\n",
    "                ##################################\n",
    "                #       RUN THE NER MODEL        #\n",
    "                ##################################\n",
    "                # Run the model argmax here, we compute tag scores and embeddings\n",
    "                mask = batch[\"token_mask\"]\n",
    "                ner_res = all_nets[\"ner_net\"](\n",
    "                    tokens = batch[\"token\"],\n",
    "                    mask = mask,\n",
    "                    tag_embeds = tag_embeds,\n",
    "                    return_embeddings=True,\n",
    "                )\n",
    "                scores = ner_res[\"scores\"]\n",
    "                embeds = ner_res[\"embeddings\"]\n",
    "\n",
    "                # Run the linear CRF Viterbi algorithm to compute the most likely sequence\n",
    "                spans = all_nets[\"ner_net\"].crf.tags_to_spans(all_nets[\"ner_net\"].crf.decode(scores, mask), mask)\n",
    "\n",
    "                # Save predicted mentions\n",
    "                pred_batch = Batcher({\n",
    "                    \"mention\": {\n",
    "                        \"mention_id\": torch.arange(n_mentions, n_mentions+len(spans[\"span_doc_id\"]), device=device),\n",
    "                        \"begin\": spans[\"span_begin\"],\n",
    "                        \"end\": spans[\"span_end\"],\n",
    "                        \"ner_label\": spans[\"span_label\"],\n",
    "                        \"@sentence_id\": spans[\"span_doc_id\"],\n",
    "                    },\n",
    "                    \"sentence\": dict(batch[\"sentence\", [\"sentence_id\", \"doc_id\"]]),\n",
    "                    \"doc\": dict(batch[\"doc\"])}, \n",
    "                    check=False)\n",
    "                pred_batches.append(pred_batch)\n",
    "                n_mentions += len(spans[\"span_doc_id\"])\n",
    "\n",
    "                ##################################\n",
    "                #      NER LOSS COMPUTATION      #\n",
    "                ##################################\n",
    "                matched_mentions = select_closest_non_overlapping_gold_mentions(\n",
    "                    gold_ids=target_mentions,\n",
    "                    gold_sentence_ids=batch[\"zone\", \"@sentence_id\"][batch[\"mention\", \"@zone_id\"]][target_mentions],\n",
    "                    gold_begins=batch[\"mention\", \"begin\"][target_mentions],\n",
    "                    gold_ends=batch[\"mention\", \"end\"][target_mentions],\n",
    "\n",
    "                    pred_sentence_ids=spans[\"span_doc_id\"],\n",
    "                    pred_begins=spans[\"span_begin\"],\n",
    "                    pred_ends=spans[\"span_end\"],\n",
    "\n",
    "                    zone_mention_id=batch[\"zone\", \"@mention_id\"],\n",
    "                    zone_mask=batch[\"zone\", \"mention_mask\"],\n",
    "\n",
    "                    gold_conflicts=batch[\"mention\", \"@conflict_mention_id\"],\n",
    "                    gold_conflicts_mask=batch[\"mention\", \"conflict_mask\"],\n",
    "                )\n",
    "                n_matched_mentions += len(matched_mentions)\n",
    "                gold_batches.append(batch[\"mention\", matched_mentions].sparsify())\n",
    "\n",
    "                # Compute the tokens label tag of the selected non-overlapping gold mentions to infer from the model\n",
    "                target_tags = all_nets[\"ner_net\"].crf.spans_to_tags(\n",
    "                    batch[\"zone\", \"@sentence_id\"][batch[\"mention\", \"@zone_id\"][matched_mentions]],\n",
    "                    batch[\"mention\", \"begin\"][matched_mentions], \n",
    "                    batch[\"mention\", \"end\"][matched_mentions], \n",
    "                    batch[\"mention\", \"ner_label\"][matched_mentions], \n",
    "                    n_tokens=batch[\"sentence\", \"token\"].shape[1],\n",
    "                    n_samples=batch[\"sentence\", \"token\"].shape[0],\n",
    "                )\n",
    "                # Run the linear CRF forward algorithm on the tokens to compute the loglikelihood of the targets\n",
    "                ner_loss = -all_nets[\"ner_net\"].crf(scores, mask, target_tags, reduction=\"mean\")\n",
    "                total_train_ner_loss += float(ner_loss) * len(batch[\"sentence\"])\n",
    "                total_train_ner_size += len(batch[\"sentence\"])\n",
    "\n",
    "                loss = ner_loss\n",
    "\n",
    "                # Perform optimization step\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(all_nets.parameters(), max_grad_norm)\n",
    "                optim.step()\n",
    "                for schedule_name, schedule in schedules.items():\n",
    "                    schedule.step()\n",
    "\n",
    "        # Compute precision, recall and f1 on train set\n",
    "        ner_pred = Batcher.concat(pred_batches)\n",
    "        ner_gold = Batcher.concat(gold_batches)\n",
    "\n",
    "        train_metrics    = compute_scores(ner_pred, ner_gold, prefix='train_')\n",
    "        val_metrics     = compute_scores(extract_mentions(val_batcher, all_nets=all_nets), val_batcher, prefix='val_',\n",
    "            queries={\n",
    "                \"3.1\": \"ner_label in ['NEG']\",\n",
    "                #\"3.2\": \"ner_label in ['anatomie', 'dose', 'examen', 'mode', 'moment', 'substance', 'traitement', 'valeur']\",\n",
    "            }\n",
    "                                        )\n",
    "        # final_schedule.step(val_f1, state[\"epoch\"])\n",
    "\n",
    "        return \\\n",
    "        {\n",
    "            \"train_ner_loss\": total_train_ner_loss / max(total_train_ner_size, 1),\n",
    "            **train_metrics,\n",
    "            # **val_metrics,\n",
    "            **val_metrics,\n",
    "            \"val_macro_f1\": val_metrics[\"val_3.1_f1\"], #(val_metrics[\"val_3.1_f1\"] + val_metrics[\"val_3.2_f1\"]) / 2.,\n",
    "            \"n_matched\": n_matched_mentions,\n",
    "            \"lr\": schedules['lr'].get_val()[0],\n",
    "        }\n",
    "\n",
    "    try:\n",
    "        best, history = run_optimization(\n",
    "            main_score = \"val_f1\", # do not earlystop based on validation\n",
    "            metrics_info=metrics_info,\n",
    "            max_epoch=200,\n",
    "            patience=None,\n",
    "            state=state, \n",
    "            cache_policy=\"all\", # only store metrics, not checkpoints\n",
    "            cache=get_cache(\"daloux\", {\"seed\": seed, \"train_batcher\": train_batcher, \"val_batcher\": None, \"random_perm\": random_perm, \"observed_zone_sizes\": observed_zone_sizes, \"batch_size\": batch_size, \"max_grad_norm\": max_grad_norm, **state}, loader=torch.load, dumper=torch.save),  # where to store the model (main name + hashed parameters)\n",
    "            epoch_fn=run_epoch,\n",
    "            n_save_checkpoints=2,\n",
    "#             exit_on_score=0.92,\n",
    "        )\n",
    "        # histories.append({\"layer\": layer, \"hidden_dim\": hidden_dim, \"scheme\": scheme, \"seed\": seed, \"history\": history})\n",
    "    except Exception as e:\n",
    "        \n",
    "        # We catch any exception otherwise some variables (including torch parameters on the gpu) end up being stored globally in sys.last_value, leading to memory errors)\n",
    "        traceback.print_exc()\n",
    "        break\n",
    "    finally:\n",
    "        pass\n",
    "        #del optim, schedules, final_schedule, state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test \n",
    "(to be fair, avoid executing this part of the notebook to often, or use the training set instead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-d3de49966fc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbert_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"bert-large\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;31m#load_genia_ner()#load_from_brat(root.resource(\"deft_2020/t3-test\"), doc_attributes={\"source\": \"real\"})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m test_docs, test_sentences, test_zones, test_mentions, test_conflicts, test_tokens, test_deltas, _ = preprocess(\n\u001b[1;32m      4\u001b[0m     \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmax_sentence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "bert_name = \"bert-large\"\n",
    "test_dataset=test_dataset#load_genia_ner()#load_from_brat(root.resource(\"deft_2020/t3-test\"), doc_attributes={\"source\": \"real\"})\n",
    "test_docs, test_sentences, test_zones, test_mentions, test_conflicts, test_tokens, test_deltas, _ = preprocess(\n",
    "    dataset=test_dataset,\n",
    "    max_sentence_length=120,\n",
    "    ner_labels=list(vocs[\"ner_label\"]),\n",
    "    bert_name=bert_name,\n",
    "    unknown_labels=\"drop\",\n",
    "    vocabularies=vocs,\n",
    ")\n",
    "test_batcher, test_encoded, test_ids = make_batcher(test_docs, test_sentences, test_zones, test_mentions, test_conflicts, test_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the test mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_label       f1    prec  rec  \n",
      "---------------------------------\n",
      "pathologie      0.420 0.593 0.325\n",
      "sosy            0.524 0.530 0.518\n",
      "---------------------------------\n",
      "total           0.514 0.534 0.496\n"
     ]
    }
   ],
   "source": [
    "pred_batcher = extract_mentions(test_batcher, all_nets=all_nets)\n",
    "gold_batcher = test_batcher\n",
    "\n",
    "pred=pd.DataFrame(dict(pred_batcher[\"mention\", [\"sentence_id\", \"begin\", \"end\", \"ner_label\", \"mention_id\"]]))\n",
    "gold=pd.DataFrame(dict(gold_batcher[\"mention\", [\"@zone_id\", \"begin\", \"end\", \"ner_label\", \"mention_id\"]]))\n",
    "gold[\"sentence_id\"] = gold_batcher[\"zone\", \"sentence_id\"][gold[\"@zone_id\"]]\n",
    "all_preds.append(pred)\n",
    "\n",
    "print(\"{: <15} {: <5} {: <5} {: <5}\".format(\"ner_label\", \"f1\", \"prec\", \"rec\"))\n",
    "print(\"---------------------------------\")\n",
    "for ner_label_idx, ner_label in enumerate(vocs['ner_label']):\n",
    "    merged = merge_pred_and_gold(\n",
    "        pred.query(f'ner_label == {ner_label_idx}'), \n",
    "        gold.query(f'ner_label == {ner_label_idx}'), \n",
    "        span_policy='exact',  # only partially match spans with strict bounds, we could also eval with 'exact' or 'partial'\n",
    "        on=[\"sentence_id\", (\"begin\", \"end\"), \"ner_label\"], atom_gold_level=[\"mention_id\"], atom_pred_level=[\"mention_id\"])\n",
    "    precision = merged['tp'].sum() / merged['pred_count'].sum()\n",
    "    recall = merged['tp'].sum() / merged['gold_count'].sum()\n",
    "    f1 = 2/(1/precision + 1/recall)\n",
    "    f1, precision, recall\n",
    "    print(\"{: <15} {:.3f} {:.3f} {:.3f}\".format(str(ner_label), f1, precision, recall))\n",
    "agg = compute_metrics(merge_pred_and_gold(\n",
    "    pred,\n",
    "    gold,\n",
    "    span_policy='exact',  # only partially match spans with strict bounds, we could also eval with 'exact' or 'partial'\n",
    "    on=[\"sentence_id\", (\"begin\", \"end\"), \"ner_label\"], atom_gold_level=[\"mention_id\"], atom_pred_level=[\"mention_id\"]))\n",
    "print(\"---------------------------------\")\n",
    "print(\"{: <15} {:.3f} {:.3f} {:.3f}\".format(\"total\", agg[\"f1\"], agg[\"precision\"], agg[\"recall\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_mult_norm",
   "language": "python",
   "name": "deep_mult_norm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
