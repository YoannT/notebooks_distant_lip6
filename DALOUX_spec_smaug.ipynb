{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(\"nlstruct\")\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlstruct.text import huggingface_tokenize, regex_sentencize, partition_spans, encode_as_tag, split_into_spans, apply_substitutions, apply_deltas\n",
    "from nlstruct.dataloaders import load_from_brat, load_genia_ner\n",
    "from nlstruct.collections import Dataset, Batcher\n",
    "from nlstruct.utils import merge_with_spans, normalize_vocabularies, factorize_rows, df_to_csr, factorize, torch_global as tg\n",
    "from nlstruct.modules.crf import BIODecoder, BIOULDecoder\n",
    "from nlstruct.environment import root, cached\n",
    "from nlstruct.train import seed_all\n",
    "from itertools import chain, repeat\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "def select_closest_non_overlapping_gold_mentions(\n",
    "    gold_ids,\n",
    "    gold_sentence_ids,\n",
    "    gold_begins,\n",
    "    gold_ends,\n",
    "    \n",
    "    pred_sentence_ids,\n",
    "    pred_begins,\n",
    "    pred_ends,\n",
    "    \n",
    "    zone_mention_id,\n",
    "    zone_mask,\n",
    "    gold_conflicts,\n",
    "    gold_conflicts_mask,\n",
    "):\n",
    "    \"\"\"\n",
    "    Select non overlapping gold mentions (in gold_ids) that are the closest to those found by the model\n",
    "    Gold mentions are described by gold_* tensors, predicted mentions are described by pred_* tensors\n",
    "    We select at most one gold mention per zone (zone_mention_id + zone_mask) and each time a gold mention\n",
    "    is selected, its overlaps are removed according to the gold_conflicts + gold_conflicts_mask tensors\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        Selected gold ids, included in \"gold_ids\"\n",
    "    \"\"\"\n",
    "\n",
    "    device = gold_begins.device\n",
    "    \n",
    "    if len(gold_ids) == 0:\n",
    "        return torch.as_tensor([], dtype=torch.long, device=device)\n",
    "\n",
    "    [rel], [remaining_mask], _ = factorize([zone_mention_id], [zone_mask], reference_values=gold_ids)\n",
    "    remaining_mentions = zone_mention_id[remaining_mask.any(1)]\n",
    "    rel = rel[remaining_mask.any(1)]\n",
    "    remaining_mask = remaining_mask[remaining_mask.any(1)]\n",
    "        \n",
    "    keep_mask = torch.zeros(gold_ids.max()+1, device=device, dtype=torch.bool)\n",
    "    zone_scores = torch.full(remaining_mask.shape, fill_value=-1, device=device, dtype=torch.float)\n",
    "    \n",
    "    if len(pred_begins):\n",
    "        PRED, GOLD = 0, 1\n",
    "        SENTENCE_ID, BEGIN, END = 0, 1, 2\n",
    "        p = torch.stack([pred_sentence_ids, pred_begins, pred_ends], dim=0).unsqueeze(GOLD+1)\n",
    "        g = torch.stack([gold_sentence_ids, gold_begins, gold_ends], dim=0).unsqueeze(PRED+1)\n",
    "\n",
    "        overlap = (torch.min(p[END], g[END]) - torch.max(p[BEGIN], g[BEGIN])).float().clamp(0)\n",
    "        overlap = overlap * 2 / (p[END] - p[BEGIN] + g[END] - g[BEGIN])\n",
    "        score = (p[SENTENCE_ID] == g[SENTENCE_ID]) * overlap\n",
    "        \n",
    "        zone_scores = score.max(0).values[rel]\n",
    "        zone_scores[~remaining_mask] = -1\n",
    "    else:\n",
    "        zone_scores[remaining_mask] = 0\n",
    "    while len(remaining_mask):\n",
    "        best_indexer = torch.arange(zone_scores.shape[0], device=device), zone_scores.argmax(1)\n",
    "        best_mentions = remaining_mentions[best_indexer]\n",
    "        conflicts = gold_conflicts[best_mentions][gold_conflicts_mask[best_mentions]]    \n",
    "        keep_mask[best_mentions] = True\n",
    "        remaining_mask[best_indexer] = False\n",
    "        remaining_mask &= ~(remaining_mentions.unsqueeze(-1) == conflicts).any(-1)\n",
    "        zone_scores[~remaining_mask] = -1\n",
    "        zone_scores = zone_scores[remaining_mask.any(1)]\n",
    "        remaining_mentions = remaining_mentions[remaining_mask.any(1)]\n",
    "        remaining_mask = remaining_mask[remaining_mask.any(1)]\n",
    "    return keep_mask.nonzero()[:, 0]\n",
    "\n",
    "def split_zone_mentions(batch, random_perm=True, observed_zone_sizes=None):\n",
    "    \"\"\"\n",
    "    In a batch, splits mentions between \n",
    "    - those that we will consider as being observed\n",
    "    - and those that we will ask the model to recover\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    random_perm: bool\n",
    "        Shuffle the mentions before splitting them\n",
    "    observed_zone_sizes: int\n",
    "        If not None, selects exactly this number of mentions per zone (=overlapping group of mentions)\n",
    "        Otherwise, any random number from 0 to the maximum of mentions can be observed in each group\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    (torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor)\n",
    "        - observed_mentions: flat observed mentions (@mention_id)\n",
    "        - target_mentions: flat target mentions (@mention_id)\n",
    "        - zone_target_mentions: mentions to recover, grouped by zone (n_zones * n_mentions_per_zone)\n",
    "        - target_mask: mask of zone_target_mentions, since every zone can have a different number of picked target mentions\n",
    "    \"\"\"\n",
    "    zone_mention_id = batch[\"zone\", \"@mention_id\"]\n",
    "    zone_mention_mask = batch[\"zone\", \"mention_mask\"]\n",
    "    n_sentences = len(batch[\"sentence\"])\n",
    "    device = zone_mention_id.device\n",
    "    if random_perm:\n",
    "        perm = torch.rand(zone_mention_id.shape, device=device)\n",
    "    else:\n",
    "        perm = torch.zeros(zone_mention_id.shape, device=device, dtype=torch.float)\n",
    "    perm[~zone_mention_mask] = 2\n",
    "    perm = perm.argsort(1)\n",
    "\n",
    "    if observed_zone_sizes is None:\n",
    "        observed_zone_size = ((zone_mention_mask.sum(-1) + 1) * torch.rand(zone_mention_mask.shape[0], dtype=torch.float, device=device)).long()\n",
    "    else:\n",
    "        observed_zone_size = torch.full((zone_mention_mask.shape[0],), fill_value=observed_zone_sizes, device=device, dtype=torch.long)\n",
    "\n",
    "    # Select mentions that will become features\n",
    "    zone_observed_mentions = zone_mention_id[torch.arange(perm.shape[0], device=device).unsqueeze(1), perm]\n",
    "    observed_mask = (torch.arange(zone_mention_mask.shape[1], device=device).unsqueeze(0) < observed_zone_size.unsqueeze(1)) & zone_mention_mask\n",
    "    observed_mentions = zone_observed_mentions[observed_mask]\n",
    "\n",
    "    # Select mentions that will be hidden from the model (ie to recover)\n",
    "    zone_target_mentions = zone_mention_id[torch.arange(perm.shape[0], device=device).unsqueeze(1), perm]\n",
    "    target_mask = (torch.arange(zone_mention_mask.shape[1], device=device).unsqueeze(0) >= observed_zone_size.unsqueeze(1)) & zone_mention_mask\n",
    "    zone_target_mentions = zone_target_mentions[target_mask.any(1)]\n",
    "    target_mask = target_mask[target_mask.any(1)]\n",
    "    target_mentions = zone_target_mentions[target_mask]\n",
    "    return target_mentions, observed_mentions, zone_target_mentions, target_mask\n",
    "\n",
    "def compute_scores(pred_batcher, gold_batcher, queries={}, prefix='val_', verbose=0):\n",
    "    pred=pd.DataFrame(dict(pred_batcher[\"mention\", [\"sentence_id\", \"begin\", \"end\", \"ner_label\", \"mention_id\"]]))\n",
    "    gold=pd.DataFrame(dict(gold_batcher[\"mention\", [\"@zone_id\", \"begin\", \"end\", \"ner_label\", \"mention_id\"]]))\n",
    "    gold[\"sentence_id\"] = gold_batcher[\"zone\", \"sentence_id\"][gold[\"@zone_id\"]]\n",
    "\n",
    "    # Merge on spans and ner_label\n",
    "    merged = merge_pred_and_gold(\n",
    "        pred, gold, span_policy='exact',  # only partially match spans with strict bounds, we could also eval with 'exact' or 'partial'\n",
    "        on=[\"sentence_id\", (\"begin\", \"end\"), \"ner_label\"], atom_gold_level=[\"mention_id\"], atom_pred_level=[\"mention_id\"])\n",
    "    \n",
    "    merged[\"ner_label\"] = np.asarray(vocs[\"ner_label\"])[merged[\"ner_label\"]].astype(str)\n",
    "    metrics = {\n",
    "        **compute_metrics(merged, prefix=prefix),\n",
    "        #**compute_metrics(merged.query(\"ner_label == {}\".format(list(vocs[\"ner_label\"]).index(c[\"sosy\"]))), prefix=prefix+\"sosy_\"),\n",
    "        #**compute_metrics(merged.query(\"ner_label == {}\".format(list(vocs[\"ner_label\"]).index(c[\"pathologie\"]))), prefix=prefix+\"pathologie_\"),\n",
    "    }\n",
    "    for name, query in queries.items():\n",
    "        metrics.update(compute_metrics(merged.query(query), prefix=prefix+name+\"_\"))\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To debug the training, we can just comment the \"def run_epoch()\" and execute the function body manually without changing anything to it\n",
    "def extract_mentions(batcher, all_nets, max_depth=10):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    batcher: Batcher \n",
    "        The batcher containing the text from which we want to extract the mentions (and maybe the gold mentions)\n",
    "    ner_net: torch.nn.Module\n",
    "    max_depth: int\n",
    "        Max number of times we run the model per sample\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Batcher\n",
    "    \"\"\"\n",
    "    pred_batches = []\n",
    "    n_mentions = 0\n",
    "    ner_net = all_nets[\"ner_net\"]\n",
    "    tag_embeddings = all_nets[\"tag_embeddings\"]\n",
    "    with evaluating(all_nets):\n",
    "        with torch.no_grad():\n",
    "            for batch_i, batch in enumerate(batcher['sentence'].dataloader(batch_size=batch_size, shuffle=False, sparse_sort_on=\"token_mask\", device=tg.device)):\n",
    "\n",
    "                tag_embeds = torch.zeros(*batch[\"sentence\", \"token\"].shape[:2], tag_dim, device=tg.device)\n",
    "                current_sentences_idx = torch.arange(len(batch), device=tg.device)\n",
    "                mask = batch[\"token_mask\"]\n",
    "                tokens = batch[\"token\"]\n",
    "\n",
    "                for i in range(max_depth):\n",
    "                    # Run the model argmax here\n",
    "                    ner_res = ner_net(\n",
    "                        tokens = tokens,\n",
    "                        mask = mask,\n",
    "                        tag_embeds = tag_embeds,\n",
    "                        return_embeddings=True\n",
    "                    )\n",
    "\n",
    "                    # Run the linear CRF Viterbi algorithm to compute the most likely sequence\n",
    "                    pred_tags = ner_net.crf.decode(ner_res[\"scores\"], mask)\n",
    "                    spans = ner_net.crf.tags_to_spans(pred_tags, mask)\n",
    "\n",
    "                    # Save predicted mentions\n",
    "                    pred_batch = Batcher({\n",
    "                        \"mention\": {\n",
    "                            \"mention_id\": torch.arange(n_mentions, n_mentions+len(spans[\"span_doc_id\"]), device=tg.device),\n",
    "                            \"begin\": spans[\"span_begin\"],\n",
    "                            \"end\": spans[\"span_end\"],\n",
    "                            \"ner_label\": spans[\"span_label\"],\n",
    "                            \"@sentence_id\": current_sentences_idx[spans[\"span_doc_id\"]],\n",
    "                            \"depth\": torch.full_like(spans[\"span_begin\"], fill_value=i),\n",
    "                        },\n",
    "                        \"sentence\": dict(batch[\"sentence\", [\"sentence_id\", \"doc_id\"]]),\n",
    "                        \"doc\": dict(batch[\"doc\"])}, \n",
    "                        check=False).sparsify()\n",
    "                    pred_batches.append(pred_batch)\n",
    "                    n_mentions += len(spans[\"span_doc_id\"])\n",
    "\n",
    "                    non_empty_sentences = torch.unique(spans[\"span_doc_id\"])\n",
    "\n",
    "                    if len(non_empty_sentences) == 0:\n",
    "                        break\n",
    "\n",
    "                    # Convert the predicted spans to tags using the same encoding scheme as the one used to decode predicted tags\n",
    "                    # (We could use a different one: BIODecoder/BIOULDecoder.spans_to_tags is a static function)\n",
    "                    feature_tags = ner_net.crf.spans_to_tags(\n",
    "                        torch.arange(len(spans[\"span_begin\"]), device=spans[\"span_begin\"].device),\n",
    "                        spans[\"span_begin\"], \n",
    "                        spans[\"span_end\"],\n",
    "                        spans[\"span_label\"], \n",
    "                        n_tokens=batch[\"sentence\", \"token\"].shape[1],\n",
    "                        n_samples=len(spans[\"span_begin\"]),\n",
    "                    )\n",
    "                    tag_mention, tag_positions = feature_tags.nonzero(as_tuple=True)\n",
    "                    tag_sentence = spans[\"span_doc_id\"][tag_mention]\n",
    "                    tag_values = feature_tags[tag_mention, tag_positions]\n",
    "\n",
    "                    tag_embeds = tag_embeds.view(-1, tag_dim).index_add_(\n",
    "                        dim=0,\n",
    "                        index=tag_sentence * batch[\"sentence\", \"token\"].shape[1] + tag_positions, \n",
    "                        source=tag_embeddings.weight[tag_values-1]).view(len(current_sentences_idx), batch[\"sentence\", \"token\"].shape[1], tag_dim)[non_empty_sentences]\n",
    "\n",
    "                    # Compute the tokens label tag embeddings of the observed (maybe overlapping) mentions\n",
    "                    tokens = tokens[non_empty_sentences]\n",
    "                    mask = mask[non_empty_sentences]\n",
    "                    current_sentences_idx = current_sentences_idx[non_empty_sentences]\n",
    "    return Batcher.concat(pred_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Define the training metrics\n",
    "metrics_info = defaultdict(lambda: False)\n",
    "flt_format = (5, \"{:.4f}\".format)\n",
    "metrics_info.update({\n",
    "    \"train_loss\": {\"goal\": 0, \"format\": flt_format},\n",
    "    \"train_ner_loss\": {\"goal\": 0, \"format\": flt_format},\n",
    "    #\"train_recall\": {\"goal\": 1, \"format\": flt_format, \"name\": \"train_rec\"},\n",
    "    #\"train_precision\": {\"goal\": 1, \"format\": flt_format, \"name\": \"train_prec\"},\n",
    "    \"train_f1\": {\"goal\": 1, \"format\": flt_format, \"name\": \"train_f1\"},\n",
    "    \n",
    "    \"val_loss\": {\"goal\": 0, \"format\": flt_format},\n",
    "    \"val_ner_loss\": {\"goal\": 0, \"format\": flt_format},\n",
    "    \"val_label_loss\": {\"goal\": 0, \"format\": flt_format},\n",
    "    \n",
    "    \"val_f1\": {\"goal\": 1, \"format\": flt_format, \"name\": \"val_f1\"},\n",
    "    \"val_3.1_f1\": {\"goal\": 1, \"format\": flt_format, \"name\": \"val_3.1_f1\"},\n",
    "    \"val_3.2_f1\": {\"goal\": 1, \"format\": flt_format, \"name\": \"val_3.2_f1\"},\n",
    "    \"val_macro_f1\": {\"goal\": 1, \"format\": flt_format, \"name\": \"val_macro_f1\"},\n",
    "    \"val_sosy_f1\": {\"goal\": 1, \"format\": flt_format, \"name\": \"val_sosy_f1\"},\n",
    "    \"val_pathologie_f1\": {\"goal\": 1, \"format\": flt_format, \"name\": \"val_patho_f1\"},\n",
    "    \n",
    "    \"duration\": {\"format\": flt_format, \"name\": \"   dur(s)\"},\n",
    "    \"rescale\": {\"format\": flt_format},\n",
    "    \"n_depth\": {\"format\": flt_format},\n",
    "    \"n_matched\": {\"format\": flt_format},\n",
    "    \"n_targets\": {\"format\": flt_format},\n",
    "    \"n_observed\": {\"format\": flt_format},\n",
    "    \"total_score_sum\": {\"format\": flt_format},\n",
    "    \"lr\": {\"format\": (5, \"{:.2e}\".format)},\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batcher(docs, sentences, zones, mentions, conflicts, tokens):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    ----------\n",
    "    docs: pd.DataFrame\n",
    "    sentences: pd.DataFrame\n",
    "    zones: pd.DataFrame\n",
    "    mentions: pd.DataFrame\n",
    "    conflicts: pd.DataFrame\n",
    "    tokens: pd.DataFrame\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Batcher\n",
    "    \"\"\"\n",
    "    docs = docs.copy()\n",
    "    sentences = sentences.copy()\n",
    "    zones = zones.copy()\n",
    "    mentions = mentions.copy()\n",
    "    conflicts = conflicts.copy()\n",
    "    tokens = tokens.copy()\n",
    "    \n",
    "    [tokens[\"token_id\"]], unique_token_id = factorize_rows([tokens[\"token_id\"]])\n",
    "    [mentions[\"mention_id\"], conflicts[\"mention_id\"], conflicts[\"mention_id_other\"]], unique_mention_ids = factorize_rows(\n",
    "        [mentions[[\"doc_id\", \"sentence_id\", \"mention_id\"]], conflicts[[\"doc_id\", \"sentence_id\", \"mention_id\"]], conflicts[[\"doc_id\", \"sentence_id\", \"mention_id_other\"]]])\n",
    "    [zones[\"zone_id\"], mentions[\"zone_id\"]], unique_zone_ids = factorize_rows(\n",
    "        [zones[[\"doc_id\", \"sentence_id\", \"zone_id\"]], mentions[[\"doc_id\", \"sentence_id\", \"zone_id\"]]])\n",
    "    [sentences[\"sentence_id\"], zones[\"sentence_id\"], mentions[\"sentence_id\"], tokens[\"sentence_id\"],], unique_sentence_ids = factorize_rows(\n",
    "        [sentences[[\"doc_id\", \"sentence_id\"]], zones[[\"doc_id\", \"sentence_id\"]], mentions[[\"doc_id\", \"sentence_id\"]], tokens[[\"doc_id\", \"sentence_id\"]]])\n",
    "    [docs[\"doc_id\"], sentences[\"doc_id\"], zones[\"doc_id\"], mentions[\"doc_id\"], tokens[\"doc_id\"]], unique_doc_ids = factorize_rows(\n",
    "        [docs[\"doc_id\"], sentences[\"doc_id\"], zones[\"doc_id\"], mentions[\"doc_id\"], tokens[\"doc_id\"]])\n",
    "    \n",
    "    batcher = Batcher({\n",
    "        \"mention\": {\n",
    "            \"mention_id\": mentions[\"mention_id\"],\n",
    "            \"zone_id\": mentions[\"zone_id\"],\n",
    "            \"sentence_id\": mentions[\"sentence_id\"],\n",
    "            \"doc_id\": mentions[\"doc_id\"],\n",
    "            \"begin\": mentions[\"begin\"],\n",
    "            \"end\": mentions[\"end\"],\n",
    "            \"ner_label\": mentions[\"ner_label\"].cat.codes,\n",
    "            \"conflict_mention_id\": df_to_csr(conflicts[\"mention_id\"], conflicts[\"conflict_idx\"], conflicts[\"mention_id_other\"], n_rows=len(unique_mention_ids)),\n",
    "            \"conflict_mask\": df_to_csr(conflicts[\"mention_id\"], conflicts[\"conflict_idx\"], n_rows=len(unique_mention_ids)),\n",
    "        },\n",
    "        \"zone\": {\n",
    "            \"zone_id\": zones[\"zone_id\"],\n",
    "            \"sentence_id\": zones[\"sentence_id\"],\n",
    "            \"doc_id\": zones[\"doc_id\"],\n",
    "            \"mention_id\": df_to_csr(mentions[\"zone_id\"], mentions[\"zone_mention_idx\"], mentions[\"mention_id\"], n_rows=len(unique_zone_ids)),\n",
    "            \"mention_mask\": df_to_csr(mentions[\"zone_id\"], mentions[\"zone_mention_idx\"], n_rows=len(unique_zone_ids)),\n",
    "        },\n",
    "        \"sentence\": {\n",
    "            \"sentence_id\": sentences[\"sentence_id\"],\n",
    "            \"doc_id\": sentences[\"doc_id\"],\n",
    "            \"mention_id\": df_to_csr(mentions[\"sentence_id\"], mentions[\"mention_idx\"], mentions[\"mention_id\"], n_rows=len(unique_sentence_ids)),\n",
    "            \"mention_mask\": df_to_csr(mentions[\"sentence_id\"], mentions[\"mention_idx\"], n_rows=len(unique_sentence_ids)),\n",
    "            \"token\": df_to_csr(tokens[\"sentence_id\"], tokens[\"token_idx\"], tokens[\"token\"].cat.codes, n_rows=len(unique_sentence_ids)),\n",
    "            \"token_mask\": df_to_csr(tokens[\"sentence_id\"], tokens[\"token_idx\"], n_rows=len(unique_sentence_ids)),\n",
    "            \"zone_id\": df_to_csr(zones[\"sentence_id\"], zones[\"zone_idx\"], zones[\"zone_id\"], n_rows=len(unique_sentence_ids)),\n",
    "            \"zone_mask\": df_to_csr(zones[\"sentence_id\"], zones[\"zone_idx\"], n_rows=len(unique_sentence_ids)),\n",
    "        },\n",
    "        \"doc\": {\n",
    "            \"doc_id\": np.arange(len(unique_doc_ids)),\n",
    "            \"sentence_id\": df_to_csr(sentences[\"doc_id\"], sentences[\"sentence_idx\"], sentences[\"sentence_id\"], n_rows=len(unique_doc_ids)),\n",
    "            \"sentence_mask\": df_to_csr(sentences[\"doc_id\"], sentences[\"sentence_idx\"], n_rows=len(unique_doc_ids)),\n",
    "            \"split\": docs[\"split\"].cat.codes,\n",
    "        }},\n",
    "        masks={\"sentence\": {\"token\": \"token_mask\", \"zone_id\": \"zone_mask\", \"mention_id\": \"mention_mask\"}, \n",
    "               \"mention\": {\"conflict_mention_id\": \"conflict_mask\"},\n",
    "               \"zone\": {\"mention_id\": \"mention_mask\"}, \n",
    "               \"doc\": {\"sentence_id\": \"sentence_mask\"}}\n",
    "    )\n",
    "    return (\n",
    "        batcher, \n",
    "        dict(docs=docs, sentences=sentences, zones=zones, mentions=mentions, tokens=tokens),\n",
    "        dict(token_id=unique_token_id, mention_id=unique_mention_ids, zone_id=unique_zone_ids, sentence_id=unique_sentence_ids, doc_id=unique_doc_ids)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERNet(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_labels,\n",
    "                 hidden_dim,\n",
    "                 dropout,\n",
    "                 n_tokens=None,\n",
    "                 token_dim=None,\n",
    "                 embeddings=None,\n",
    "                 tag_scheme=\"bio\",\n",
    "                 metric='linear',\n",
    "                 metric_fc_kwargs=None,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        if embeddings is not None:\n",
    "            self.embeddings = embeddings\n",
    "            if n_tokens is None or token_dim is None:\n",
    "                if hasattr(embeddings, 'weight'):\n",
    "                    n_tokens, token_dim = embeddings.weight.shape\n",
    "                else:\n",
    "                    n_tokens, token_dim = embeddings.embeddings.weight.shape\n",
    "        else:\n",
    "            self.embeddings = torch.nn.Embedding(n_tokens, token_dim) if n_tokens > 0 else None\n",
    "        assert token_dim is not None, \"Provide token_dim or embeddings\"\n",
    "        assert self.embeddings is not None\n",
    "\n",
    "        dim = (token_dim if n_tokens > 0 else 0)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        if tag_scheme == \"bio\":\n",
    "            self.crf = BIODecoder(n_labels)\n",
    "        elif tag_scheme == \"bioul\":\n",
    "            self.crf = BIOULDecoder(n_labels)\n",
    "        else:\n",
    "            raise Exception()\n",
    "        if hidden_dim is None:\n",
    "            hidden_dim = dim\n",
    "        self.linear = torch.nn.Linear(dim, hidden_dim)\n",
    "        self.batch_norm = torch.nn.BatchNorm1d(dim)\n",
    "\n",
    "        n_tags = self.crf.num_tags\n",
    "        metric_fc_kwargs = metric_fc_kwargs if metric_fc_kwargs is not None else {}\n",
    "        if metric == \"linear\":\n",
    "            self.metric_fc = torch.nn.Linear(dim, n_tags)\n",
    "        elif metric == \"cosine\":\n",
    "            self.metric_fc = CosineSimilarity(dim, n_tags, rescale=rescale, **metric_fc_kwargs)\n",
    "        elif metric == \"ema_cosine\":\n",
    "            self.metric_fc = EMACosineSimilarity(dim, n_tags, rescale=rescale, **metric_fc_kwargs)\n",
    "        else:\n",
    "            raise Exception()\n",
    "    \n",
    "    def extended_embeddings(self, tokens, mask, **kwargs):\n",
    "        # Default case here, size <= 512\n",
    "        # Small ugly check to see if self.embeddings is Bert-like, then we need to pass a mask\n",
    "        if hasattr(self.embeddings, 'encoder') or hasattr(self.embeddings, 'transformer'):\n",
    "            return self.embeddings(tokens, mask, **kwargs)[0]\n",
    "        else:\n",
    "            return self.embeddings(tokens)\n",
    "\n",
    "    def forward(self, tokens, mask, tag_embeds=None, return_embeddings=False):\n",
    "        # Embed the tokens\n",
    "        scores = None\n",
    "        # shape: n_batch * sequence * 768\n",
    "        embeds = self.extended_embeddings(tokens, mask, custom_embeds=tag_embeds)\n",
    "        state = embeds.masked_fill(~mask.unsqueeze(-1), 0)\n",
    "        state = torch.relu(self.linear(self.dropout(state)))# + state\n",
    "        state = self.batch_norm(state.view(-1, state.shape[-1])).view(state.shape)\n",
    "        scores = self.metric_fc(state)\n",
    "        return {\n",
    "            \"scores\": scores,\n",
    "            \"embeddings\": embeds if return_embeddings else None,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMNERNet(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_labels,\n",
    "                 hidden_dim,\n",
    "                 dropout,\n",
    "                 n_tokens=None,\n",
    "                 token_dim=None,\n",
    "                 embeddings=None,\n",
    "                 tag_scheme=\"bio\",\n",
    "                 metric='linear',\n",
    "                 metric_fc_kwargs=None,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        if embeddings is not None:\n",
    "            self.embeddings = embeddings\n",
    "            if n_tokens is None or token_dim is None:\n",
    "                if hasattr(embeddings, 'weight'):\n",
    "                    n_tokens, token_dim = embeddings.weight.shape\n",
    "                else:\n",
    "                    n_tokens, token_dim = embeddings.embeddings.weight.shape\n",
    "        else:\n",
    "            self.embeddings = torch.nn.Embedding(n_tokens, token_dim) if n_tokens > 0 else None\n",
    "        assert token_dim is not None, \"Provide token_dim or embeddings\"\n",
    "        assert self.embeddings is not None\n",
    "\n",
    "        dim = (token_dim if n_tokens > 0 else 0)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        if tag_scheme == \"bio\":\n",
    "            self.crf = BIODecoder(n_labels)\n",
    "        elif tag_scheme == \"bioul\":\n",
    "            self.crf = BIOULDecoder(n_labels)\n",
    "        else:\n",
    "            raise Exception()\n",
    "        if hidden_dim is None:\n",
    "            hidden_dim = dim\n",
    "        self.linear = torch.nn.Linear(dim, hidden_dim)\n",
    "        self.batch_norm = torch.nn.BatchNorm1d(dim)\n",
    "        self.lstm = torch.nn.LSTM(hidden_dim, \n",
    "                                  hidden_dim, dropout=dropout, batch_first=True, num_layers=2, bidirectional=True)\n",
    "            \n",
    "\n",
    "        n_tags = self.crf.num_tags\n",
    "        metric_fc_kwargs = metric_fc_kwargs if metric_fc_kwargs is not None else {}\n",
    "        if metric == \"linear\":\n",
    "            self.metric_fc = torch.nn.Linear(hidden_dim*2, n_tags)\n",
    "        elif metric == \"cosine\":\n",
    "            self.metric_fc = CosineSimilarity(dim, n_tags, rescale=rescale, **metric_fc_kwargs)\n",
    "        elif metric == \"ema_cosine\":\n",
    "            self.metric_fc = EMACosineSimilarity(dim, n_tags, rescale=rescale, **metric_fc_kwargs)\n",
    "        else:\n",
    "            raise Exception()\n",
    "    \n",
    "    def extended_embeddings(self, tokens, mask, **kwargs):\n",
    "        # Default case here, size <= 512\n",
    "        # Small ugly check to see if self.embeddings is Bert-like, then we need to pass a mask\n",
    "        if hasattr(self.embeddings, 'encoder') or hasattr(self.embeddings, 'transformer'):\n",
    "            return self.embeddings(tokens, mask, **kwargs)[0]\n",
    "        else:\n",
    "            return self.embeddings(tokens)\n",
    "\n",
    "    def forward(self, tokens, mask, tag_embeds=None, return_embeddings=False):\n",
    "        # Embed the tokens\n",
    "        scores = None\n",
    "        # shape: n_batch * sequence * 768\n",
    "        embeds = self.extended_embeddings(tokens, mask, custom_embeds=tag_embeds)\n",
    "        state = embeds.masked_fill(~mask.unsqueeze(-1), 0)\n",
    "        state = torch.relu(self.linear(self.dropout(state)))# + state\n",
    "        state = self.batch_norm(state.view(-1, state.shape[-1])).view(state.shape)\n",
    "        \n",
    "        lstm_state = self.lstm(self.dropout(state))[0]\n",
    "        state = torch.relu(lstm_state)\n",
    "        scores = self.metric_fc(state)\n",
    "        return {\n",
    "            \"scores\": scores,\n",
    "            \"embeddings\": embeds if return_embeddings else None,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@cached\n",
    "def preprocess(\n",
    "    dataset,\n",
    "    max_sentence_length,\n",
    "    bert_name,\n",
    "    ner_labels=None,\n",
    "    unknown_labels=\"drop\",\n",
    "    vocabularies=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "        dataset: Dataset\n",
    "        max_sentence_length: int\n",
    "            Max number of \"words\" as defined by the regex in regex_sentencize (so this is not the nb of wordpieces)\n",
    "        bert_name: str\n",
    "            bert path/name\n",
    "        ner_labels: list of str \n",
    "            allowed ner labels (to be dropped or filtered)\n",
    "        unknown_labels: str\n",
    "            \"drop\" or \"raise\"\n",
    "        vocabularies: dict[str; np.ndarray or list]\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    (pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame, dict[str; np.ndarray or list])\n",
    "        docs:      ('split', 'text', 'doc_id')\n",
    "        sentences: ('split', 'doc_id', 'sentence_idx', 'begin', 'end', 'text', 'sentence_id')\n",
    "        zones:     ('doc_id', 'sentence_id', 'zone_id', 'zone_idx')\n",
    "        mentions:  ('ner_label', 'doc_id', 'sentence_id', 'mention_id', 'depth', 'zone_id', 'text', 'mention_idx', 'begin', 'end', 'zone_mention_idx')\n",
    "        conflicts: ('doc_id', 'sentence_id', 'mention_id', 'mention_id_other', 'conflict_idx')\n",
    "        tokens:    ('split', 'token', 'sentence_id', 'token_id', 'token_idx', 'begin', 'end', 'doc_id', 'sentence_idx')\n",
    "        deltas:    ('doc_id', 'begin', 'end', 'delta')\n",
    "        vocs: vocabularies to be reused later for encoding more data or decoding predictions\n",
    "    \"\"\"\n",
    "    print(\"Dataset:\", dataset)\n",
    "\n",
    "    mentions = dataset[\"mentions\"].rename({\"label\": \"ner_label\"}, axis=1)\n",
    "\n",
    "    \n",
    "    if ner_labels is not None:\n",
    "        len_before = len(mentions)\n",
    "        unknown_ner_labels = list(mentions[~mentions[\"ner_label\"].isin(ner_labels)][\"ner_label\"].drop_duplicates())\n",
    "        mentions = mentions[mentions[\"ner_label\"].isin(ner_labels)]\n",
    "        \n",
    "        if len(unknown_ner_labels) and unknown_labels == \"raise\":\n",
    "            raise Exception(f\"Unkown labels in {len_before-len(mentions)} mentions: \", unknown_ner_labels)\n",
    "\n",
    "    # Check that there is no mention overlap\n",
    "    mentions = mentions.merge(dataset[\"fragments\"].groupby([\"doc_id\", \"mention_id\"], as_index=False, observed=True).agg({\"begin\": \"min\", \"end\": \"max\"}))\n",
    "\n",
    "    \n",
    "    print(\"Transform texts...\", end=\" \")\n",
    "    transformed_docs, deltas = apply_substitutions(\n",
    "        dataset[\"docs\"], *zip(\n",
    "            (r\"(?<=[{}\\\\])(?![ ])\".format(string.punctuation), r\" \"),\n",
    "            (r\"(?<![ ])(?=[{}\\\\])\".format(string.punctuation), r\" \"),\n",
    "            (\"(?<=[a-zA-Z])(?=[0-9])\", r\" \"),\n",
    "            (\"(?<=[0-9])(?=[A-Za-z])\", r\" \"),\n",
    "        ), apply_unidecode=True)\n",
    "    transformed_docs = transformed_docs.astype({\"text\": str})\n",
    "    transformed_mentions = apply_deltas(mentions, deltas, on=['doc_id'])\n",
    "    print(\"done\")\n",
    "    \n",
    "    print(\"Splitting into sentences...\", end=\" \")\n",
    "    sentences = regex_sentencize(\n",
    "        transformed_docs, \n",
    "        reg_split=r\"((?:\\s*\\n\\s*\\n)+\\s*|(?:(?<=[a-z0-9)]\\n)|(?<=[a-z0-9)][ ](?:\\.|\\n))|(?<=[a-z0-9)][ ][ ](?:\\.|\\n)))\\s*(?=[A-Z]))\",\n",
    "        min_sentence_length=0, max_sentence_length=max_sentence_length,\n",
    "        # balance_parentheses=True, # default is True\n",
    "    )\n",
    "    \n",
    "    [sentence_mentions], sentences, sentence_to_docs = partition_spans([transformed_mentions], sentences, new_id_name=\"sentence_id\", overlap_policy=False)\n",
    "#     n_sentences_per_mention = sentence_mentions.assign(count=1).groupby([\"doc_id\", \"mention_id\"], as_index=False).agg({\"count\": \"sum\", \"text\": \"first\", \"sentence_id\": \"last\"})\n",
    "#     if n_sentences_per_mention[\"count\"].max() > 1:\n",
    "#         display(n_sentences_per_mention.query(\"count > 1\"))\n",
    "#         display(sentences[sentences[\"sentence_id\"].isin(n_sentences_per_mention.query(\"count > 1\")[\"sentence_id\"])][\"text\"].tolist())\n",
    "#         raise Exception(\"Some mentions could be mapped to more than 1 sentences ({})\".format(n_sentences_per_mention[\"count\"].max()))\n",
    "    if sentence_to_docs is not None:\n",
    "        sentence_mentions = sentence_mentions.merge(sentence_to_docs)\n",
    "        \n",
    "    sentence_mentions = sentence_mentions.assign(mention_idx=0).nlstruct.groupby_assign([\"doc_id\", \"sentence_id\"], {\"mention_idx\": lambda x: tuple(range(len(x)))})\n",
    "    print(\"done\")\n",
    "    \n",
    "    print(\"Tokenizing...\", end=\" \")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(bert_name)\n",
    "    sentences[\"text\"] = sentences[\"text\"].str.lower()\n",
    "    \n",
    "    tokens = huggingface_tokenize(sentences, tokenizer, doc_id_col=\"sentence_id\")\n",
    "    sentence_mentions = split_into_spans(sentence_mentions, tokens, pos_col=\"token_idx\", overlap_policy=False)\n",
    "    print(\"done\")\n",
    "    \n",
    "    print(\"Processing zones (overlapping areas)...\", end=\" \")\n",
    "    # Extract overlapping spans\n",
    "    conflicts = (\n",
    "        merge_with_spans(sentence_mentions, sentence_mentions, on=[\"doc_id\", \"sentence_id\", (\"begin\", \"end\")], how=\"outer\", suffixes=(\"\", \"_other\"))\n",
    "    )\n",
    "\n",
    "    # ids1, and ids2 make the edges of the overlapping mentions of the same type (see the \"ner_label\")\n",
    "    [ids1, ids2], unique_ids = factorize_rows(\n",
    "        [conflicts[[\"doc_id\", \"sentence_id\", \"mention_id\"]], \n",
    "         conflicts[[\"doc_id\", \"sentence_id\", \"mention_id_other\"]]],\n",
    "        sentence_mentions.eval(\"size=(end-begin)\").sort_values(\"size\")[[\"doc_id\", \"sentence_id\", \"mention_id\"]]\n",
    "    )\n",
    "    g = nx.from_scipy_sparse_matrix(df_to_csr(ids1, ids2, n_rows=len(unique_ids), n_cols=len(unique_ids)))\n",
    "    colored_nodes = np.asarray(list(nx.coloring.greedy_color(g, strategy=keep_order).items()))\n",
    "    unique_ids['depth'] = colored_nodes[:, 1][colored_nodes[:, 0].argsort()]\n",
    "    zone_indices, mention_indices = zip(*chain.from_iterable(zip(repeat(zone_idx), zone) for zone_idx, zone in enumerate(nx.connected_components(g))))\n",
    "    conflicts = conflicts[[\"doc_id\", \"sentence_id\", \"mention_id\", \"mention_id_other\"]].assign(conflict_idx=0).nlstruct.groupby_assign([\"doc_id\", \"sentence_id\", \"mention_id\"], {\"conflict_idx\": lambda x: tuple(range(len(x)))})\n",
    "\n",
    "    zone_mentions = pd.DataFrame({\n",
    "        **unique_ids.iloc[list(mention_indices)],\n",
    "        \"zone_id\": zone_indices,\n",
    "    }).merge(sentence_mentions, on=[\"doc_id\", \"sentence_id\", \"mention_id\"]).sort_values([\"doc_id\", \"sentence_id\", \"zone_id\", \"mention_id\"])\n",
    "    zone_mentions = zone_mentions.assign(zone_mention_idx=0).nlstruct.groupby_assign(['doc_id', 'sentence_id', 'zone_id'], {\"zone_mention_idx\": lambda vec: tuple(np.arange(len(vec)))})\n",
    "    sentence_zones = zone_mentions[[\"doc_id\", \"sentence_id\", \"zone_id\"]].drop_duplicates()\n",
    "    sentence_zones = sentence_zones.assign(zone_idx=0).nlstruct.groupby_assign(['doc_id', 'sentence_id'], {\"zone_idx\": lambda vec: tuple(np.arange(len(vec)))})\n",
    "    sentence_mentions = sentence_mentions.merge(zone_mentions.drop_duplicates([\"doc_id\", \"sentence_id\", \"mention_id\", \"depth\"]))\n",
    "    print(\"done\")\n",
    "\n",
    "    print(\"Computing vocabularies...\")\n",
    "    [transformed_docs, sentences, sentence_zones, zone_mentions, tokens], vocs = normalize_vocabularies(\n",
    "        [transformed_docs, sentences, sentence_zones, zone_mentions, tokens], \n",
    "        vocabularies={\"split\": [\"train\", \"val\", \"test\"]} if vocabularies is None else vocabularies,\n",
    "        train_vocabularies={\"source\": False, \"text\": False} if vocabularies is None else False,\n",
    "        verbose=True)\n",
    "    print(\"done\")\n",
    "    return transformed_docs, sentences, sentence_zones, zone_mentions, conflicts, tokens, deltas, vocs\n",
    "\n",
    "def keep_order(G, colors):\n",
    "    \"\"\"Returns a list of the nodes of ``G`` in ordered identically to their id in the graph\n",
    "    ``G`` is a NetworkX graph. ``colors`` is ignored.\n",
    "    This is to assign a depth using the nx.coloring.greedy_color function\n",
    "    \"\"\"\n",
    "    return sorted(list(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Dataset(\n",
      "  (docs):       6547 * ('doc_id', 'text', 'split')\n",
      "  (mentions):    734 * ('doc_id', 'mention_id', 'label', 'text')\n",
      "  (fragments):   734 * ('doc_id', 'mention_id', 'fragment_id', 'begin', 'end')\n",
      "  (attributes):    0 * ('doc_id', 'mention_id', 'attribute_id', 'label', 'value')\n",
      "  (relations):     0 * ('doc_id', 'relation_id', 'relation_label', 'from_mention_id', 'to_mention_id')\n",
      "  (comments):      0 * ('doc_id', 'comment_id', 'mention_id', 'comment')\n",
      ")\n",
      "Transform texts... done\n",
      "Splitting into sentences... done\n",
      "Tokenizing... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ytaille/.conda/envs/deep_mult_norm/lib/python3.7/site-packages/transformers/tokenization_utils.py:831: FutureWarning: Parameter max_len is deprecated and will be removed in a future release. Use model_max_length instead.\n",
      "  category=FutureWarning,\n",
      "/home/ytaille/.conda/envs/deep_mult_norm/lib/python3.7/site-packages/nlstruct/text/chunking/huggingface.py:11: FutureWarning: doc_id_col is not used anymore in the huggingface_tokenize function\n",
      "  warnings.warn(\"doc_id_col is not used anymore in the huggingface_tokenize function\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "Processing zones (overlapping areas)... done\n",
      "Computing vocabularies...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "bert_name = \"camembert-base\"\n",
    "dataset = load_from_brat('/home/ytaille/data/resources/corpus_dalloux/ESSAI_spec_brat')#load_genia_ner()\n",
    "\n",
    "NEG_ONLY = False\n",
    "\n",
    "if NEG_ONLY:\n",
    "    neg_doc_ids = dataset['mentions']['doc_id'].unique()\n",
    "    neg_docs = dataset['docs'][dataset['docs']['doc_id'].isin(neg_doc_ids)]\n",
    "    neg_mentions = dataset['mentions'][dataset['mentions']['doc_id'].isin(neg_doc_ids)]\n",
    "    neg_fragments = dataset['fragments'][dataset['fragments']['doc_id'].isin(neg_doc_ids)]\n",
    "    \n",
    "    dataset = Dataset(\n",
    "        docs=neg_docs,\n",
    "        mentions=neg_mentions,\n",
    "        fragments=neg_fragments,\n",
    "        attributes=dataset['attributes'],\n",
    "        relations=dataset['relations'],\n",
    "        comments=dataset['comments'],\n",
    "    )\n",
    "\n",
    "docs, sentences, zones, mentions, conflicts, tokens, deltas, vocs = preprocess(\n",
    "    dataset=dataset,\n",
    "    max_sentence_length=140,\n",
    "    bert_name=bert_name,\n",
    "    ner_labels= ['SPEC'],\n",
    "    unknown_labels=\"drop\",\n",
    ")\n",
    "batcher, encoded, ids = make_batcher(docs, sentences, zones, mentions, conflicts, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity (L2 dist) between train and val frequencies: 0.0\n",
      "Frequebncies\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>SPEC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>val</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  SPEC\n",
       "0  train   1.0\n",
       "1    val   1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#all_test_doc_ids = []\n",
    "#sims = {}\n",
    "#for i in range(200):\n",
    "seed_all(1234567+137)\n",
    "\n",
    "train_batcher = batcher['doc'][batcher['doc']['split']==0]['sentence']\n",
    "val_batcher = batcher['doc'][batcher['doc']['split']==1]['sentence']\n",
    "# test_batcher = batcher['doc'][batcher['doc']['split']==2]['sentence']\n",
    "\n",
    "# splits = np.zeros(len(train_batcher['doc']), dtype=int)\n",
    "\n",
    "# val_perc = 0.1\n",
    "# splits[np.random.choice(np.arange(len(splits)), size=int(val_perc * len(splits)))] = 1\n",
    "\n",
    "# val_batcher = batcher['sentence'][splits == 1]\n",
    "\n",
    "# train_val_split = np.random.permutation(len(train_batcher))\n",
    "# test_batcher = train_batcher[train_val_split[:int(0.1*len(train_val_split))]]['sentence']\n",
    "# train_batcher = train_batcher[train_val_split[int(0.1*len(train_val_split)):]]['sentence']\n",
    "sim = ((np.bincount(val_batcher['mention', 'ner_label'], minlength=len(vocs[\"ner_label\"]))/len(val_batcher['mention']) -\n",
    "np.bincount(train_batcher['mention', 'ner_label'], minlength=len(vocs[\"ner_label\"]))/len(train_batcher['mention']))**2).sum()\n",
    "print(\"Similarity (L2 dist) between train and val frequencies:\", sim)\n",
    "print(\"Frequebncies\")\n",
    "#all_test_doc_ids.append((test_doc_ids, sim))\n",
    "display(pd.DataFrame([\n",
    "    {\"index\": \"train\", **dict(zip(vocs[\"ner_label\"], np.bincount(train_batcher['mention', 'ner_label'], minlength=len(vocs[\"ner_label\"]))/len(train_batcher['mention'])))},\n",
    "    {\"index\": \"val\", **dict(zip(vocs[\"ner_label\"], np.bincount(val_batcher['mention', 'ner_label'], minlength=len(vocs[\"ner_label\"]))/len(val_batcher['mention'])))},\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install /home/yoann/these/DEFT/nlstruct/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 768 bioul 12 0.01 4e-05 1 0.1\n",
      "before layer norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ytaille/.conda/envs/deep_mult_norm/lib/python3.7/site-packages/nlstruct/train/helpers.py:141: UserWarning: Entry 'schedules' in the state seems to be mutable but has no load_state_dict/state_dict methods. This could lead to unpredictable behaviors.\n",
      "  warn(f\"Entry '{key}' in the state seems to be mutable but has no load_state_dict/state_dict methods. This could lead to unpredictable behaviors.\")\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.47it/s]\n",
      "INFO:nlstruct:epoch | train_ner_loss | train_f1 | \u001b[31mval_f1\u001b[0m | val_3.1_f1 | val_macro_f1 | n_matched |       lr |    dur(s)\n",
      "INFO:nlstruct:    1 |         \u001b[32m6.7924\u001b[0m |   \u001b[32m0.0000\u001b[0m | \u001b[32m0.0000\u001b[0m |        \u001b[32mnan\u001b[0m |          \u001b[32mnan\u001b[0m |  286.0000 | 1.00e-02 |   13.5945\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.43it/s]\n",
      "INFO:nlstruct:    2 |         \u001b[32m4.2111\u001b[0m |   \u001b[31m0.0000\u001b[0m | \u001b[31m0.0000\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  305.0000 | 1.00e-02 |   13.7201\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.44it/s]\n",
      "INFO:nlstruct:    3 |         \u001b[32m2.4631\u001b[0m |   \u001b[31m0.0000\u001b[0m | \u001b[31m0.0000\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  281.0000 | 1.00e-02 |   13.6805\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.47it/s]\n",
      "INFO:nlstruct:    4 |         \u001b[32m1.6242\u001b[0m |   \u001b[32m0.0063\u001b[0m | \u001b[31m0.0000\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  293.0000 | 1.00e-02 |   13.7006\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.44it/s]\n",
      "INFO:nlstruct:    5 |         \u001b[32m1.4905\u001b[0m |   \u001b[32m0.0280\u001b[0m | \u001b[31m0.0000\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  290.0000 | 1.00e-02 |   13.7861\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.44it/s]\n",
      "INFO:nlstruct:    6 |         \u001b[32m1.1515\u001b[0m |   \u001b[32m0.0366\u001b[0m | \u001b[31m0.0000\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  293.0000 | 1.00e-02 |   13.8310\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.42it/s]\n",
      "INFO:nlstruct:    7 |         \u001b[32m1.1082\u001b[0m |   \u001b[31m0.0348\u001b[0m | \u001b[31m0.0000\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  276.0000 | 1.00e-02 |   13.8649\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.41it/s]\n",
      "INFO:nlstruct:    8 |         \u001b[32m0.6913\u001b[0m |   \u001b[32m0.0392\u001b[0m | \u001b[32m0.0699\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  275.0000 | 1.00e-02 |   14.5919\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.42it/s]\n",
      "INFO:nlstruct:    9 |         \u001b[31m1.5789\u001b[0m |   \u001b[32m0.0405\u001b[0m | \u001b[31m0.0000\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  280.0000 | 1.00e-02 |   13.7922\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.40it/s]\n",
      "INFO:nlstruct:   10 |         \u001b[31m0.8513\u001b[0m |   \u001b[32m0.0573\u001b[0m | \u001b[31m0.0230\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  281.0000 | 1.00e-02 |   14.0300\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.39it/s]\n",
      "INFO:nlstruct:   11 |         \u001b[32m0.5647\u001b[0m |   \u001b[32m0.0942\u001b[0m | \u001b[32m0.0823\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  285.0000 | 1.00e-02 |   14.2624\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.43it/s]\n",
      "INFO:nlstruct:   12 |         \u001b[31m0.5983\u001b[0m |   \u001b[32m0.1229\u001b[0m | \u001b[32m0.0913\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  291.0000 | 1.00e-02 |   14.3175\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.40it/s]\n",
      "INFO:nlstruct:   13 |         \u001b[32m0.5173\u001b[0m |   \u001b[32m0.1560\u001b[0m | \u001b[31m0.0000\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  305.0000 | 1.00e-02 |   13.8797\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.41it/s]\n",
      "INFO:nlstruct:   14 |         \u001b[31m0.7143\u001b[0m |   \u001b[31m0.1419\u001b[0m | \u001b[31m0.0000\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  287.0000 | 1.00e-02 |   13.8219\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.43it/s]\n",
      "INFO:nlstruct:   15 |         \u001b[31m0.7112\u001b[0m |   \u001b[31m0.1467\u001b[0m | \u001b[31m0.0268\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  320.0000 | 1.00e-02 |   13.8618\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.42it/s]\n",
      "INFO:nlstruct:   16 |         \u001b[32m0.4436\u001b[0m |   \u001b[32m0.1692\u001b[0m | \u001b[32m0.1579\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  308.0000 | 1.00e-02 |   13.9744\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.40it/s]\n",
      "INFO:nlstruct:   17 |         \u001b[31m0.7771\u001b[0m |   \u001b[32m0.2153\u001b[0m | \u001b[31m0.1379\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  305.0000 | 1.00e-02 |   14.0555\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.43it/s]\n",
      "INFO:nlstruct:   18 |         \u001b[31m0.6894\u001b[0m |   \u001b[32m0.2166\u001b[0m | \u001b[31m0.0000\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  271.0000 | 1.00e-02 |   13.7574\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.43it/s]\n",
      "INFO:nlstruct:   19 |         \u001b[31m0.4891\u001b[0m |   \u001b[31m0.1938\u001b[0m | \u001b[32m0.1910\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  291.0000 | 1.00e-02 |   14.3219\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.43it/s]\n",
      "INFO:nlstruct:   20 |         \u001b[31m0.4707\u001b[0m |   \u001b[32m0.2516\u001b[0m | \u001b[32m0.2364\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  277.0000 | 1.00e-02 |   13.9699\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.44it/s]\n",
      "INFO:nlstruct:   21 |         \u001b[32m0.3347\u001b[0m |   \u001b[32m0.2609\u001b[0m | \u001b[31m0.2054\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  298.0000 | 1.00e-02 |   13.8993\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.45it/s]\n",
      "INFO:nlstruct:   22 |         \u001b[31m0.3437\u001b[0m |   \u001b[32m0.3326\u001b[0m | \u001b[31m0.0344\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  275.0000 | 1.00e-02 |   14.7949\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.44it/s]\n",
      "INFO:nlstruct:   23 |         \u001b[32m0.2711\u001b[0m |   \u001b[32m0.3658\u001b[0m | \u001b[31m0.2318\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  304.0000 | 1.00e-02 |   14.1188\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.44it/s]\n",
      "INFO:nlstruct:   24 |         \u001b[31m0.2797\u001b[0m |   \u001b[32m0.3933\u001b[0m | \u001b[31m0.2240\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  275.0000 | 1.00e-02 |   14.1123\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.45it/s]\n",
      "INFO:nlstruct:   25 |         \u001b[31m0.2801\u001b[0m |   \u001b[31m0.3498\u001b[0m | \u001b[31m0.0278\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  301.0000 | 1.00e-02 |   13.8661\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.43it/s]\n",
      "INFO:nlstruct:   26 |         \u001b[31m0.5863\u001b[0m |   \u001b[31m0.2777\u001b[0m | \u001b[31m0.1333\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  294.0000 | 1.00e-02 |   13.9221\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.45it/s]\n",
      "INFO:nlstruct:   27 |         \u001b[31m0.3202\u001b[0m |   \u001b[32m0.4252\u001b[0m | \u001b[31m0.2203\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  273.0000 | 1.00e-02 |   13.9461\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.42it/s]\n",
      "INFO:nlstruct:   28 |         \u001b[32m0.2232\u001b[0m |   \u001b[32m0.4659\u001b[0m | \u001b[31m0.1262\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  305.0000 | 1.00e-02 |   13.9917\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.46it/s]\n",
      "INFO:nlstruct:   29 |         \u001b[31m0.2388\u001b[0m |   \u001b[32m0.4667\u001b[0m | \u001b[31m0.1700\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  287.0000 | 1.00e-02 |   13.8547\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.49it/s]\n",
      "INFO:nlstruct:   30 |         \u001b[31m0.2570\u001b[0m |   \u001b[31m0.4495\u001b[0m | \u001b[31m0.1989\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  298.0000 | 1.00e-02 |   13.7350\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.45it/s]\n",
      "INFO:nlstruct:   31 |         \u001b[32m0.1641\u001b[0m |   \u001b[32m0.5693\u001b[0m | \u001b[31m0.1700\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  286.0000 | 1.00e-02 |   13.8808\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.45it/s]\n",
      "INFO:nlstruct:   32 |         \u001b[31m0.1769\u001b[0m |   \u001b[32m0.5830\u001b[0m | \u001b[32m0.2500\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  299.0000 | 1.00e-02 |   13.9459\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.47it/s]\n",
      "INFO:nlstruct:   33 |         \u001b[32m0.1096\u001b[0m |   \u001b[32m0.7002\u001b[0m | \u001b[31m0.1373\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  275.0000 | 1.00e-02 |   13.8073\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.46it/s]\n",
      "INFO:nlstruct:   34 |         \u001b[31m0.1221\u001b[0m |   \u001b[31m0.6318\u001b[0m | \u001b[31m0.1891\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  266.0000 | 1.00e-02 |   13.8485\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.47it/s]\n",
      "INFO:nlstruct:   35 |         \u001b[32m0.0945\u001b[0m |   \u001b[32m0.7358\u001b[0m | \u001b[32m0.2975\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  305.0000 | 1.00e-02 |   13.8919\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.47it/s]\n",
      "INFO:nlstruct:   36 |         \u001b[31m0.1076\u001b[0m |   \u001b[32m0.7481\u001b[0m | \u001b[31m0.2694\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  283.0000 | 1.00e-02 |   13.8443\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.45it/s]\n",
      "INFO:nlstruct:   37 |         \u001b[32m0.0779\u001b[0m |   \u001b[32m0.8118\u001b[0m | \u001b[31m0.2615\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  297.0000 | 1.00e-02 |   14.0339\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.41it/s]\n",
      "INFO:nlstruct:   38 |         \u001b[32m0.0727\u001b[0m |   \u001b[31m0.7985\u001b[0m | \u001b[31m0.1964\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  279.0000 | 1.00e-02 |   14.0452\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.39it/s]\n",
      "INFO:nlstruct:   39 |         \u001b[32m0.0557\u001b[0m |   \u001b[32m0.8547\u001b[0m | \u001b[31m0.2643\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  295.0000 | 1.00e-02 |   14.2626\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.39it/s]\n",
      "INFO:nlstruct:   40 |         \u001b[32m0.0501\u001b[0m |   \u001b[32m0.8602\u001b[0m | \u001b[31m0.1608\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  290.0000 | 1.00e-02 |   14.0808\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.40it/s]\n",
      "INFO:nlstruct:   41 |         \u001b[31m0.0600\u001b[0m |   \u001b[32m0.8642\u001b[0m | \u001b[31m0.2185\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  291.0000 | 1.00e-02 |   14.3120\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.42it/s]\n",
      "INFO:nlstruct:   42 |         \u001b[31m0.0547\u001b[0m |   \u001b[31m0.8103\u001b[0m | \u001b[31m0.1967\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  281.0000 | 1.00e-02 |   14.0629\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.41it/s]\n",
      "INFO:nlstruct:   43 |         \u001b[32m0.0344\u001b[0m |   \u001b[32m0.8677\u001b[0m | \u001b[31m0.2197\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  267.0000 | 1.00e-02 |   14.1559\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.41it/s]\n",
      "INFO:nlstruct:   44 |         \u001b[31m0.0686\u001b[0m |   \u001b[31m0.8370\u001b[0m | \u001b[31m0.2460\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  303.0000 | 1.00e-02 |   14.0543\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.41it/s]\n",
      "INFO:nlstruct:   45 |         \u001b[31m0.0379\u001b[0m |   \u001b[32m0.9104\u001b[0m | \u001b[31m0.2090\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  274.0000 | 1.00e-02 |   14.0366\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.41it/s]\n",
      "INFO:nlstruct:   46 |         \u001b[31m0.0496\u001b[0m |   \u001b[32m0.9144\u001b[0m | \u001b[31m0.1489\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  282.0000 | 1.00e-02 |   14.9500\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.43it/s]\n",
      "INFO:nlstruct:   47 |         \u001b[31m0.0645\u001b[0m |   \u001b[31m0.8650\u001b[0m | \u001b[31m0.2123\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  279.0000 | 1.00e-02 |   14.0360\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.44it/s]\n",
      "INFO:nlstruct:   48 |         \u001b[31m0.0736\u001b[0m |   \u001b[31m0.8531\u001b[0m | \u001b[31m0.2661\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  286.0000 | 1.00e-02 |   14.0269\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.42it/s]\n",
      "INFO:nlstruct:   49 |         \u001b[31m0.0586\u001b[0m |   \u001b[31m0.8869\u001b[0m | \u001b[31m0.1039\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  279.0000 | 1.00e-02 |   14.0176\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.43it/s]\n",
      "INFO:nlstruct:   50 |         \u001b[31m0.0590\u001b[0m |   \u001b[31m0.8183\u001b[0m | \u001b[31m0.1884\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  298.0000 | 1.00e-02 |   14.1598\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.43it/s]\n",
      "INFO:nlstruct:   51 |         \u001b[31m0.0368\u001b[0m |   \u001b[31m0.8997\u001b[0m | \u001b[31m0.1796\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  292.0000 | 1.00e-02 |   13.9818\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.44it/s]\n",
      "INFO:nlstruct:   52 |         \u001b[31m0.0527\u001b[0m |   \u001b[31m0.8849\u001b[0m | \u001b[31m0.2449\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  284.0000 | 1.00e-02 |   13.9044\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.43it/s]\n",
      "INFO:nlstruct:   53 |         \u001b[31m0.0450\u001b[0m |   \u001b[31m0.8973\u001b[0m | \u001b[31m0.2371\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  282.0000 | 1.00e-02 |   13.9265\n",
      "100%|██████████| 42/42 [00:12<00:00,  3.45it/s]\n",
      "INFO:nlstruct:   54 |         \u001b[31m0.0431\u001b[0m |   \u001b[31m0.8885\u001b[0m | \u001b[31m0.2583\u001b[0m |        \u001b[31mnan\u001b[0m |          \u001b[31mnan\u001b[0m |  283.0000 | 1.00e-02 |   13.9611\n",
      " 24%|██▍       | 10/42 [00:03<00:09,  3.25it/s]\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ytaille/.conda/envs/deep_mult_norm/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3417, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-16-ff58aafe1246>\", line 263, in <module>\n",
      "    n_save_checkpoints=2,\n",
      "  File \"/home/ytaille/.conda/envs/deep_mult_norm/lib/python3.7/site-packages/nlstruct/train/helpers.py\", line 332, in run_optimization\n",
      "    epoch_scores = epoch_fn()\n",
      "  File \"<ipython-input-16-ff58aafe1246>\", line 167, in run_epoch\n",
      "    spans = all_nets[\"ner_net\"].crf.tags_to_spans(all_nets[\"ner_net\"].crf.decode(scores, mask), mask)\n",
      "  File \"/home/ytaille/.conda/envs/deep_mult_norm/lib/python3.7/site-packages/nlstruct/modules/crf.py\", line 61, in decode\n",
      "    _, _, backtrack = self.recurse_forward(emissions, mask, ring_op_name=\"max\", use_constraints=True)\n",
      "  File \"/home/ytaille/.conda/envs/deep_mult_norm/lib/python3.7/site-packages/nlstruct/modules/crf.py\", line 167, in recurse_forward\n",
      "    log_probs = [(start_transitions + emissions[0]).unsqueeze(0).repeat_interleave(tags.shape[1] if tags is not None else 1, dim=0)]\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ytaille/.conda/envs/deep_mult_norm/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ytaille/.conda/envs/deep_mult_norm/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/ytaille/.conda/envs/deep_mult_norm/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/ytaille/.conda/envs/deep_mult_norm/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/ytaille/.conda/envs/deep_mult_norm/lib/python3.7/inspect.py\", line 1495, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/ytaille/.conda/envs/deep_mult_norm/lib/python3.7/inspect.py\", line 1453, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/ytaille/.conda/envs/deep_mult_norm/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/ytaille/.conda/envs/deep_mult_norm/lib/python3.7/inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/home/ytaille/.conda/envs/deep_mult_norm/lib/python3.7/inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/home/ytaille/.conda/envs/deep_mult_norm/lib/python3.7/inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/home/ytaille/.conda/envs/deep_mult_norm/lib/python3.7/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-ff58aafe1246>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    262\u001b[0m             \u001b[0mepoch_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m             \u001b[0mn_save_checkpoints\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;31m#             exit_on_score=0.92,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deep_mult_norm/lib/python3.7/site-packages/nlstruct/train/helpers.py\u001b[0m in \u001b[0;36mrun_optimization\u001b[0;34m(metrics_info, max_epoch, epoch_fn, main_score, patience_warmup, patience_rate, patience, state, n_save_checkpoints, exit_on_score, cache, cache_policy, with_writer, seed, mutable_state_policy, as_thread, _thread_should_stop)\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch_before\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mepoch_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m         \u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-ff58aafe1246>\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m()\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;31m# Run the linear CRF Viterbi algorithm to compute the most likely sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m                 \u001b[0mspans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_nets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ner_net\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtags_to_spans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_nets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ner_net\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deep_mult_norm/lib/python3.7/site-packages/nlstruct/modules/crf.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, emissions, mask)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbacktrack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurse_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memissions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mring_op_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"max\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_constraints\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbacktrack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deep_mult_norm/lib/python3.7/site-packages/nlstruct/modules/crf.py\u001b[0m in \u001b[0;36mrecurse_forward\u001b[0;34m(self, emissions, mask, tags, ring_op_name, use_constraints)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mlog_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_transitions\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0memissions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat_interleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtags\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/deep_mult_norm/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2043\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2044\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deep_mult_norm/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2046\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 2047\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   2048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2049\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deep_mult_norm/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1436\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deep_mult_norm/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1334\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1336\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m             )\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deep_mult_norm/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1193\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deep_mult_norm/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deep_mult_norm/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "from tqdm import tqdm\n",
    "\n",
    "from custom_bert import CustomBertModel\n",
    "from transformers import AdamW, BertModel\n",
    "\n",
    "from tqdm import tqdm\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from nlstruct.environment import get_cache\n",
    "from nlstruct.utils import evaluating, torch_global as tg, freeze\n",
    "from nlstruct.scoring import compute_metrics, merge_pred_and_gold\n",
    "from nlstruct.train import make_optimizer_and_schedules, run_optimization, seed_all\n",
    "from nlstruct.train.schedule import ScaleOnPlateauSchedule, LinearSchedule, ConstantSchedule\n",
    "    \n",
    "device = torch.device('cuda:0')\n",
    "tg.set_device(device)\n",
    "all_preds = []\n",
    "histories = []\n",
    "\n",
    "# To release gpu memory before allocating new parameters for a new model\n",
    "# A better idea would be to run xp in a function, so that all variables are released when exiting the fn\n",
    "# but this way we can debug after this cell if something goes wrong\n",
    "if \"all_nets\" in globals(): del all_nets\n",
    "if \"optim\" in globals(): del optim, \n",
    "if \"schedules\" in globals(): del schedules\n",
    "if \"final_schedule\" in globals(): del final_schedule\n",
    "if \"state\" in globals(): del state\n",
    "    \n",
    "# Hyperparameter search\n",
    "for layer, hidden_dim, scheme, seed, lr, bert_lr, n_schedules, dropout in [\n",
    "    (3, 1024 if \"large\" in bert_name else 768, \"bioul\", 12,  1e-2, 4e-5, 1, 0.1),\n",
    "]:\n",
    "    print(layer, hidden_dim, scheme, seed, lr, bert_lr, n_schedules, dropout)\n",
    "    #seed = 123456\n",
    "    seed_all(seed) # /!\\ Super important to enable reproducibility\n",
    "\n",
    "    tag_dim = 1024 if \"large\" in bert_name else 768#768\n",
    "    max_grad_norm = 5.\n",
    "    #lr = 1e-3\n",
    "    #bert_lr = 6e-5\n",
    "    tags_lr = bert_lr\n",
    "    bert_weight_decay = 0.0000\n",
    "    batch_size = 128\n",
    "    random_perm=True\n",
    "    observed_zone_sizes=None\n",
    "    n_per_zone = \"uniform\"\n",
    "    n_freeze = layer + 2 #4\n",
    "    custom_embeds_layer_index = 19 if \"large\" in bert_name else 11  #layer#2\n",
    "    #hidden_dim = 256\n",
    "    bert_dropout = 0.1\n",
    "    top_dropout = dropout\n",
    "\n",
    "    ner_net = NERNet(\n",
    "            n_tokens=len(vocs[\"token\"]),\n",
    "            token_dim=1024 if \"large\" in bert_name else 768,#768,\n",
    "            n_labels=len(vocs[\"ner_label\"]),\n",
    "            embeddings=CustomBertModel.from_pretrained(bert_name, custom_embeds_layer_index=custom_embeds_layer_index),\n",
    "\n",
    "            dropout=top_dropout,\n",
    "            hidden_dim=hidden_dim,\n",
    "            tag_scheme=scheme,\n",
    "            metric='linear') # cosine might be better but looks less stable, oddly,\n",
    "    all_nets = torch.nn.ModuleDict({\n",
    "        \"ner_net\": ner_net,\n",
    "        \"tag_embeddings\": torch.nn.Embedding(ner_net.crf.num_tags - 1, tag_dim),\n",
    "    }).to(device=tg.device)\n",
    "    del ner_net\n",
    "\n",
    "    for module in all_nets[\"ner_net\"].embeddings.modules():\n",
    "        if isinstance(module, torch.nn.Dropout):\n",
    "            module.p = bert_dropout\n",
    "    all_nets.train()\n",
    "\n",
    "    # Define the optimizer, maybe multiple learning rate / schedules per parameters groups\n",
    "    optim, schedules = make_optimizer_and_schedules(all_nets, AdamW, {\n",
    "        \"lr\": [\n",
    "                               (lr,    bert_lr,    bert_lr,    tags_lr),\n",
    "            (ConstantSchedule, (lr,    bert_lr,    bert_lr,    tags_lr),    15),\n",
    "            (ConstantSchedule, (lr/4,  bert_lr/4,  bert_lr/4,  tags_lr/4),  15),\n",
    "            (ConstantSchedule, (lr/16, bert_lr/16, bert_lr/16, tags_lr/16), 10),\n",
    "            (ConstantSchedule, (lr/64, bert_lr/64, bert_lr/64, tags_lr/64), 10),\n",
    "        ][:n_schedules+1],\n",
    "    }, [\n",
    "        \"(?!ner_net\\.embeddings\\.|tag_embeddings\\.).*\",\n",
    "        \"ner_net\\.embeddings\\..*(bias|LayerNorm\\.weight)\",\n",
    "        \"ner_net\\.embeddings\\..*(?!bias|LayerNorm\\.weight)\",\n",
    "        \"tag_embeddings\\..*\",\n",
    "    ], num_iter_per_epoch=(len(train_batcher) + 1) / batch_size)\n",
    "    final_schedule = ScaleOnPlateauSchedule('lr', optim, patience=4, factor=0.25, verbose=True, mode='max')\n",
    "\n",
    "    # Freeze some bert layers \n",
    "    # - n_freeze = 0 to freeze nothing\n",
    "    # - n_freeze = 1 to freeze word embeddings / position embeddings / ...\n",
    "    # - n_freeze = 2..13 to freeze the first, second ... 12th layer of bert\n",
    "    for name, param in all_nets.named_parameters():\n",
    "        match = re.search(\"\\.(\\d+)\\.\", name)\n",
    "        if match and int(match.group(1)) < n_freeze - 1:\n",
    "            freeze([param])\n",
    "    if n_freeze > 0:\n",
    "        if hasattr(all_nets['ner_net'].embeddings, 'embeddings'):\n",
    "            freeze(all_nets['ner_net'].embeddings.embeddings)\n",
    "        else:\n",
    "            freeze(all_nets['ner_net'].embeddings)\n",
    "\n",
    "    with_tqdm = True\n",
    "    state = {\"all_nets\": all_nets, \"optim\": optim, \"schedules\": schedules, \"final_schedule\": final_schedule}  # all we need to restart the training from a given epoch\n",
    "\n",
    "    def run_epoch():\n",
    "        pred_batches = []\n",
    "        gold_batches = []\n",
    "\n",
    "        total_train_ner_loss = 0\n",
    "        total_train_acc = 0\n",
    "        total_train_ner_size = 0\n",
    "\n",
    "        n_mentions = len(train_batcher[\"mention\"])\n",
    "        n_matched_mentions = 0\n",
    "        n_target_mentions = 0\n",
    "        n_observed_mentions = 0\n",
    "\n",
    "        with tqdm(train_batcher['sentence'].dataloader(batch_size=batch_size, shuffle=True, sparse_sort_on=\"token_mask\", device=device), disable=not with_tqdm) as bar:\n",
    "            for batch_i, batch in enumerate(bar):\n",
    "                optim.zero_grad()\n",
    "\n",
    "                # Shuffle and split mentions in each zone between observed and target\n",
    "                target_mentions, observed_mentions, zone_target_mentions, target_mask = split_zone_mentions(\n",
    "                    batch,\n",
    "                    random_perm=random_perm,\n",
    "                    observed_zone_sizes=observed_zone_sizes,\n",
    "                )\n",
    "                n_target_mentions += len(target_mentions)\n",
    "                n_observed_mentions += len(observed_mentions)\n",
    "\n",
    "                # Compute the tokens label tag embeddings of the observed (maybe overlapping) mentions\n",
    "                feature_tags = all_nets[\"ner_net\"].crf.spans_to_tags(\n",
    "                    torch.arange(len(observed_mentions), device=observed_mentions.device),\n",
    "                    batch[\"mention\", \"begin\"][observed_mentions], \n",
    "                    batch[\"mention\", \"end\"][observed_mentions], \n",
    "                    batch[\"mention\", \"ner_label\"][observed_mentions], \n",
    "                    n_tokens=batch[\"sentence\", \"token\"].shape[1],\n",
    "                    n_samples=len(observed_mentions),\n",
    "                )\n",
    "                tag_mention, tag_positions = feature_tags.nonzero(as_tuple=True)\n",
    "                tag_sentence = batch[\"zone\", \"@sentence_id\"][batch[\"mention\", \"@zone_id\"]][observed_mentions][tag_mention]\n",
    "                tag_values = feature_tags[tag_mention, tag_positions]\n",
    "                tag_embeds = torch.zeros(*batch[\"sentence\", \"token\"].shape[:2], tag_dim, device=tg.device).view(-1, tag_dim).index_add_(\n",
    "                    dim=0,\n",
    "                    index=tag_sentence * batch[\"sentence\", \"token\"].shape[1] + tag_positions, \n",
    "                    source=all_nets[\"tag_embeddings\"].weight[tag_values-1]).view(*batch[\"sentence\", \"token\"].shape[:2], tag_dim)\n",
    "\n",
    "                ##################################\n",
    "                #       RUN THE NER MODEL        #\n",
    "                ##################################\n",
    "                # Run the model argmax here, we compute tag scores and embeddings\n",
    "                mask = batch[\"token_mask\"]\n",
    "                ner_res = all_nets[\"ner_net\"](\n",
    "                    tokens = batch[\"token\"],\n",
    "                    mask = mask,\n",
    "                    tag_embeds = tag_embeds,\n",
    "                    return_embeddings=True,\n",
    "                )\n",
    "                scores = ner_res[\"scores\"]\n",
    "                embeds = ner_res[\"embeddings\"]\n",
    "\n",
    "                # Run the linear CRF Viterbi algorithm to compute the most likely sequence\n",
    "                spans = all_nets[\"ner_net\"].crf.tags_to_spans(all_nets[\"ner_net\"].crf.decode(scores, mask), mask)\n",
    "\n",
    "                # Save predicted mentions\n",
    "                pred_batch = Batcher({\n",
    "                    \"mention\": {\n",
    "                        \"mention_id\": torch.arange(n_mentions, n_mentions+len(spans[\"span_doc_id\"]), device=device),\n",
    "                        \"begin\": spans[\"span_begin\"],\n",
    "                        \"end\": spans[\"span_end\"],\n",
    "                        \"ner_label\": spans[\"span_label\"],\n",
    "                        \"@sentence_id\": spans[\"span_doc_id\"],\n",
    "                    },\n",
    "                    \"sentence\": dict(batch[\"sentence\", [\"sentence_id\", \"doc_id\"]]),\n",
    "                    \"doc\": dict(batch[\"doc\"])}, \n",
    "                    check=False)\n",
    "                pred_batches.append(pred_batch)\n",
    "                n_mentions += len(spans[\"span_doc_id\"])\n",
    "\n",
    "                ##################################\n",
    "                #      NER LOSS COMPUTATION      #\n",
    "                ##################################\n",
    "                matched_mentions = select_closest_non_overlapping_gold_mentions(\n",
    "                    gold_ids=target_mentions,\n",
    "                    gold_sentence_ids=batch[\"zone\", \"@sentence_id\"][batch[\"mention\", \"@zone_id\"]][target_mentions],\n",
    "                    gold_begins=batch[\"mention\", \"begin\"][target_mentions],\n",
    "                    gold_ends=batch[\"mention\", \"end\"][target_mentions],\n",
    "\n",
    "                    pred_sentence_ids=spans[\"span_doc_id\"],\n",
    "                    pred_begins=spans[\"span_begin\"],\n",
    "                    pred_ends=spans[\"span_end\"],\n",
    "\n",
    "                    zone_mention_id=batch[\"zone\", \"@mention_id\"],\n",
    "                    zone_mask=batch[\"zone\", \"mention_mask\"],\n",
    "\n",
    "                    gold_conflicts=batch[\"mention\", \"@conflict_mention_id\"],\n",
    "                    gold_conflicts_mask=batch[\"mention\", \"conflict_mask\"],\n",
    "                )\n",
    "                n_matched_mentions += len(matched_mentions)\n",
    "                gold_batches.append(batch[\"mention\", matched_mentions].sparsify())\n",
    "\n",
    "                # Compute the tokens label tag of the selected non-overlapping gold mentions to infer from the model\n",
    "                target_tags = all_nets[\"ner_net\"].crf.spans_to_tags(\n",
    "                    batch[\"zone\", \"@sentence_id\"][batch[\"mention\", \"@zone_id\"][matched_mentions]],\n",
    "                    batch[\"mention\", \"begin\"][matched_mentions], \n",
    "                    batch[\"mention\", \"end\"][matched_mentions], \n",
    "                    batch[\"mention\", \"ner_label\"][matched_mentions], \n",
    "                    n_tokens=batch[\"sentence\", \"token\"].shape[1],\n",
    "                    n_samples=batch[\"sentence\", \"token\"].shape[0],\n",
    "                )\n",
    "                # Run the linear CRF forward algorithm on the tokens to compute the loglikelihood of the targets\n",
    "                ner_loss = -all_nets[\"ner_net\"].crf(scores, mask, target_tags, reduction=\"mean\")\n",
    "                total_train_ner_loss += float(ner_loss) * len(batch[\"sentence\"])\n",
    "                total_train_ner_size += len(batch[\"sentence\"])\n",
    "\n",
    "                loss = ner_loss\n",
    "\n",
    "                # Perform optimization step\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(all_nets.parameters(), max_grad_norm)\n",
    "                optim.step()\n",
    "                for schedule_name, schedule in schedules.items():\n",
    "                    schedule.step()\n",
    "\n",
    "        # Compute precision, recall and f1 on train set\n",
    "        ner_pred = Batcher.concat(pred_batches)\n",
    "        ner_gold = Batcher.concat(gold_batches)\n",
    "\n",
    "        train_metrics    = compute_scores(ner_pred, ner_gold, prefix='train_')\n",
    "        val_metrics     = compute_scores(extract_mentions(val_batcher, all_nets=all_nets), val_batcher, prefix='val_',\n",
    "            queries={\n",
    "                \"3.1\": \"ner_label in ['NEG']\",\n",
    "                #\"3.2\": \"ner_label in ['anatomie', 'dose', 'examen', 'mode', 'moment', 'substance', 'traitement', 'valeur']\",\n",
    "            }\n",
    "                                        )\n",
    "        # final_schedule.step(val_f1, state[\"epoch\"])\n",
    "\n",
    "        return \\\n",
    "        {\n",
    "            \"train_ner_loss\": total_train_ner_loss / max(total_train_ner_size, 1),\n",
    "            **train_metrics,\n",
    "            # **val_metrics,\n",
    "            **val_metrics,\n",
    "            \"val_macro_f1\": val_metrics[\"val_3.1_f1\"], #(val_metrics[\"val_3.1_f1\"] + val_metrics[\"val_3.2_f1\"]) / 2.,\n",
    "            \"n_matched\": n_matched_mentions,\n",
    "            \"lr\": schedules['lr'].get_val()[0],\n",
    "        }\n",
    "\n",
    "    try:\n",
    "        best, history = run_optimization(\n",
    "            main_score = \"val_f1\", # do not earlystop based on validation\n",
    "            metrics_info=metrics_info,\n",
    "            max_epoch=200,\n",
    "            patience=None,\n",
    "            state=state, \n",
    "            cache_policy=\"all\", # only store metrics, not checkpoints\n",
    "            cache=get_cache(\"daloux\", {\"seed\": seed, \"train_batcher\": train_batcher, \"val_batcher\": None, \"random_perm\": random_perm, \"observed_zone_sizes\": observed_zone_sizes, \"batch_size\": batch_size, \"max_grad_norm\": max_grad_norm, **state}, loader=torch.load, dumper=torch.save),  # where to store the model (main name + hashed parameters)\n",
    "            epoch_fn=run_epoch,\n",
    "            n_save_checkpoints=2,\n",
    "#             exit_on_score=0.92,\n",
    "        )\n",
    "        # histories.append({\"layer\": layer, \"hidden_dim\": hidden_dim, \"scheme\": scheme, \"seed\": seed, \"history\": history})\n",
    "    except Exception as e:\n",
    "        \n",
    "        # We catch any exception otherwise some variables (including torch parameters on the gpu) end up being stored globally in sys.last_value, leading to memory errors)\n",
    "        traceback.print_exc()\n",
    "        break\n",
    "    finally:\n",
    "        pass\n",
    "        #del optim, schedules, final_schedule, state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test \n",
    "(to be fair, avoid executing this part of the notebook to often, or use the training set instead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-d3de49966fc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbert_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"bert-large\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;31m#load_genia_ner()#load_from_brat(root.resource(\"deft_2020/t3-test\"), doc_attributes={\"source\": \"real\"})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m test_docs, test_sentences, test_zones, test_mentions, test_conflicts, test_tokens, test_deltas, _ = preprocess(\n\u001b[1;32m      4\u001b[0m     \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmax_sentence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "bert_name = \"bert-large\"\n",
    "test_dataset=test_dataset#load_genia_ner()#load_from_brat(root.resource(\"deft_2020/t3-test\"), doc_attributes={\"source\": \"real\"})\n",
    "test_docs, test_sentences, test_zones, test_mentions, test_conflicts, test_tokens, test_deltas, _ = preprocess(\n",
    "    dataset=test_dataset,\n",
    "    max_sentence_length=120,\n",
    "    ner_labels=list(vocs[\"ner_label\"]),\n",
    "    bert_name=bert_name,\n",
    "    unknown_labels=\"drop\",\n",
    "    vocabularies=vocs,\n",
    ")\n",
    "test_batcher, test_encoded, test_ids = make_batcher(test_docs, test_sentences, test_zones, test_mentions, test_conflicts, test_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the test mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_label       f1    prec  rec  \n",
      "---------------------------------\n",
      "pathologie      0.420 0.593 0.325\n",
      "sosy            0.524 0.530 0.518\n",
      "---------------------------------\n",
      "total           0.514 0.534 0.496\n"
     ]
    }
   ],
   "source": [
    "pred_batcher = extract_mentions(test_batcher, all_nets=all_nets)\n",
    "gold_batcher = test_batcher\n",
    "\n",
    "pred=pd.DataFrame(dict(pred_batcher[\"mention\", [\"sentence_id\", \"begin\", \"end\", \"ner_label\", \"mention_id\"]]))\n",
    "gold=pd.DataFrame(dict(gold_batcher[\"mention\", [\"@zone_id\", \"begin\", \"end\", \"ner_label\", \"mention_id\"]]))\n",
    "gold[\"sentence_id\"] = gold_batcher[\"zone\", \"sentence_id\"][gold[\"@zone_id\"]]\n",
    "all_preds.append(pred)\n",
    "\n",
    "print(\"{: <15} {: <5} {: <5} {: <5}\".format(\"ner_label\", \"f1\", \"prec\", \"rec\"))\n",
    "print(\"---------------------------------\")\n",
    "for ner_label_idx, ner_label in enumerate(vocs['ner_label']):\n",
    "    merged = merge_pred_and_gold(\n",
    "        pred.query(f'ner_label == {ner_label_idx}'), \n",
    "        gold.query(f'ner_label == {ner_label_idx}'), \n",
    "        span_policy='exact',  # only partially match spans with strict bounds, we could also eval with 'exact' or 'partial'\n",
    "        on=[\"sentence_id\", (\"begin\", \"end\"), \"ner_label\"], atom_gold_level=[\"mention_id\"], atom_pred_level=[\"mention_id\"])\n",
    "    precision = merged['tp'].sum() / merged['pred_count'].sum()\n",
    "    recall = merged['tp'].sum() / merged['gold_count'].sum()\n",
    "    f1 = 2/(1/precision + 1/recall)\n",
    "    f1, precision, recall\n",
    "    print(\"{: <15} {:.3f} {:.3f} {:.3f}\".format(str(ner_label), f1, precision, recall))\n",
    "agg = compute_metrics(merge_pred_and_gold(\n",
    "    pred,\n",
    "    gold,\n",
    "    span_policy='exact',  # only partially match spans with strict bounds, we could also eval with 'exact' or 'partial'\n",
    "    on=[\"sentence_id\", (\"begin\", \"end\"), \"ner_label\"], atom_gold_level=[\"mention_id\"], atom_pred_level=[\"mention_id\"]))\n",
    "print(\"---------------------------------\")\n",
    "print(\"{: <15} {:.3f} {:.3f} {:.3f}\".format(\"total\", agg[\"f1\"], agg[\"precision\"], agg[\"recall\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_mult_norm",
   "language": "python",
   "name": "deep_mult_norm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
